#+TITLE: Category Theory and Lambda Calculus
#+AUTHOR: Mario Román
#+OPTIONS: broken-links:mark toc:t tasks:nil num:3
#+SETUPFILE: ctlc.setup
#+LATEX_HEADER_EXTRA: \usepackage[conor]{agda}
#+LATEX_HEADER_EXTRA: \usepackage{catchfilebetweentags}
#+LATEX_HEADER_EXTRA: % \input{titlepage}


** Abstract
:PROPERTIES:
:UNNUMBERED: t
:END:

This is the abstract. It should not be written until the end.

** Acknowlegments                                                 :noexport:
This document has been written with Emacs26 and org-mode 8, using the
=org= file format and LaTeX as intermediate format. The document follows
the =classicthesis= [[http://www.latextemplates.com/templates/theses/2/thesis_2.pdf][template]] by André Miede. The =minted= package
has been used for code listings.

* Category theory
** Categories
*** Definition of category
#+begin_definition
A *category* ${\cal C}$, as defined in cite:maclane78, is given by

 * ${\cal C}_0$, a collection[fn:collection] whose elements are called *objets*, and
 * ${\cal C}_1$, a collection whose elements are called *morphisms*.

Every morphism $f \in {\cal C}_1$ has two objects assigned: a
*domain*, written as $\mathrm{dom}(f) \in {\cal C}_0$, and a
*codominio*, written as $\mathrm{cod}(f) \in {\cal C}_0$; a common
notation for such morphism is

\[
f \colon \mathrm{dom}(f) \to \mathrm{cod}(f).
\]

Given two morphisms $f \colon A \to B$ and $g \colon B \to C$ there
exists a *composition morphism*, written as $g \circ f \colon A \to C$. 
Morphism composition is a binary associative operation with
identity elements $\mathrm{id}_{A}\colon A \to A$, that is

\[
h \circ (g \circ f) = (h \circ g) \circ f
\quad\text{ and }\quad
f \circ \mathrm{id}_A = f = \mathrm{id}_B \circ f.
\]
#+end_definition

[fn:collection]: We use the term /collection/ to denote
some unspecified formal notion of compilation of "things" that could
be given by sets or proper classes. We will want to define categories
whose objects are all the possible sets and we will need the objects
to form a proper class.
* Lambda calculus
** Untyped \lambda-calculus
The *\lambda-calculus* is a collection of formal systems, all of them based
on the lambda notation discovered by Alonzo Church in the 1930s while trying
to develop a foundational notion of function on mathematics.

The *untyped* or *pure lambda calculus* is, syntactically, the simplest of those
formal systems. This presentation of the untyped lambda calculus will follow
cite:Hindley08 and cite:selinger13.

*** Definition
#+begin_definition
The *\lambda-terms* are defined inductively as

  * every /variable/, taken from an infinite and numerable set ${\cal V}$ of
    variables, and usually written as lowercase single letters
    (x,y,z,...), is a \lambda-term.

  * given two \lambda-terms $M,N$; its /application/, $MN$ is a \lambda-term.

  * given a \lambda-term $M$ and a variable $x$, its /abstraction/, $\lambda x.M$
    is a lambda term.

They can be also defined by the following BNF
\[ \mathtt{Exp} ::= x \mid (\mathtt{Exp}\ \mathtt{Exp}) \mid (\lambda x.\mathtt{Exp})
\]
where $x \in {\cal V}$ is any variable.
#+end_definition

By convention, we omit outermost parentheses and assume
left-associativity, i.e., $MNP$ will mean $(MN)P$. Multiple
\lambda-abstractions can be also contracted to a single multivariate
abstraction; thus $\lambda x.\lambda y.M$ can become $\lambda x,y.M$.

*** Free and bound variables, substitution
Any ocurrence of a variable $x$ inside the /scope/ of a lambda is said to be
bound; and any not bound variable is said to be free. We can define formally
the set of free variables as follows.

#+begin_definition
The *set of free variables* of a term $M$ is defined inductively as

\[\begin{aligned}
FV(x) &= \{x\}, \\
FV(MN) &= FV(M) \cup FV(N), \\
FV(\lambda x.M) &= FV(M) \setminus \{x\}.
\end{aligned}\]
#+end_definition

A free ocurrence of a variable can be substituted by a term. This should
be done avoiding the unintended bounding of free variables which happens
when a variable is substituted inside of the scope of a binder with the
same name, as in the following example, where we substitute $y$ by $(\lambda z.xz)$
on $(\lambda x.yx)$ and the second free variable $x$ gets bounded by the first binder

\[ (\lambda x.yx) \overset{y \mapsto (\lambda z.xz)}\longrightarrow (\lambda x.(\lambda z.xz)x).
\]

To avoid this, the $x$ should be renamed before the substitution.

#+begin_definition
The *substitution* of a variable $x$ by a term $N$ on $M$ is defined
inductively as

\[\begin{aligned}
x[N/x] &\equiv N,\\
y[N/x] &\equiv y,\\
(MP)[N/x] &\equiv (M[N/x])(P[N/x]),\\
(\lambda x.P)[N/x] &\equiv \lambda x.P,\\
(\lambda y.P)[N/x] &\equiv \lambda y.P[N/x] & \text{ if } y \notin FV(N), \\
(\lambda y.P)[N/x] &\equiv \lambda z.P[z/y][N/x] & \text{ if } y \in FV(N);
\end{aligned}\]

where, in the last clause, $z$ is a fresh unused variable.
#+end_definition

We could define a criterion for choosing exactly what this new
variable should be, or simply accept that our definition will not be
well-defined, but well-defined up to a change on the name of the
variables. This equivalence relation will be defined formally on the
next section. In practice, it is common to follow the 
/Barendregt's variable convention/ which simply assumes that bound 
variables have been renamed to be distinct.

*** \alpha-equivalence
#+begin_definition
*\alpha-equivalence* is the smallest relation $=_{\alpha}$ on
\lambda-terms which is an equivalence relation, i.e.,

  * it is /reflexive/, $M =_{\alpha} M$;
  * it is /symmetric/, if $M =_{\alpha} N$, then $N =_{\alpha} M$;
  * and it is /transitive/, if $M=_{\alpha}N$ and $N=_{\alpha}P$, then $M=_{\alpha}P$;

and it is compatible with the structure of lambda terms,

  * if $M =_{\alpha} M'$ and $N =_{\alpha} N'$, then $MN =_{\alpha}M'N'$;
  * if $M=_{\alpha}M'$, then $\lambda x.M =_{\alpha} \lambda x.M'$;
  * if $y$ does not appear on $M$, $\lambda x.M =_{\alpha} \lambda y.M[y/x]$.
#+end_definition

\alpha-equivalence formally captures the fact that the name of a bound
variable can be changed without changing the properties of the term. This
idea appears recurrently on mathematics; the renaming of the variable of
integration is an example of \alpha-equivalence.

\[
\int_0^1 x^2\ dx = \int_0^1 y^2\ dy
\]

*** \beta-reduction
The core idea of evaluation in \lambda-calculus is captured by the notion
of \beta-reduction.

#+begin_definition
The *single-step \beta-reduction* is the smallest relation on terms
capturing the notion of evaluation 
\[(\lambda x.M)N \to_{\beta}M[N/x]\]

and some congruence rules that preserve the structure of
\lambda-terms, such as

  * $M \to_{\beta} M'$ implies $MN \to M'N$ and $MN \to MN'$;
  * $M \to_{\beta}M'$ implies $\lambda x.M \to_{\beta} \lambda x.M'$.

The reflexive transitive closure of $\to_{\beta}$ is written as $\twoheadrightarrow_{\beta}$. The symmetric
closure of $\twoheadrightarrow_{\beta}$ is called *\beta-equivalence* and written as $=_{\beta}$.
#+end_definition


*** TODO DeBruijn notation                                       :noexport:
*** TODO Church encoding                                         :noexport:
*** TODO SKI combinators                                         :noexport:
** Simply typed lambda calculus
We will give now a presentation of the *simply-typed lambda calculus*
based on cite:selinger13.

*** TODO Types and sets
# From the Hott book

*** Simple types
# Are basic types necessary?

We start assuming that a set of *basic types* exists. Those basic
types would correspond, in a programming language interpretation, with
things like the type of strings or the type of integers. We will also
assume that a *unit* type, $1$ exists; the unit type will have only
one inhabitant.

#+begin_definition
The set of *simple types* is given by the following Backus-Naur form
\[\mathtt{Type} ::= 
1 \mid
\iota \mid 
\mathtt{Type} \to \mathtt{Type} \mid
\mathtt{Type} \times \mathtt{Type} \]

where $1$ is a one-element type and $\iota$ is any /basic type/.
#+end_definition

That is to say that, for every two types $A,B$, there exist a *function type*
$A \to B$ and a *pair type* $A \times B$.

*** Raw typed lambda terms
We will now define the terms of the typed lambda calculus. 

#+begin_definition
The set of *typed lambda terms* is given by the BNF
\[ \mathtt{Term} ::=
\ast \mid
x \mid
\mathtt{Term}\mathtt{Term} \mid
\lambda x^{\mathtt{Type}}. \mathtt{Term} \mid
\left\langle \mathtt{Term},\mathtt{Term} \right\rangle \mid
\pi_1 \mathtt{Term} \mid
\pi_2\mathtt{Term}
\]
#+end_definition

Besides the previously considered term application and a special
element $\ast$ which will be the unique inhabitant of the type $1$; we
now introduce a typed lambda abstraction and an explicit construction
of the pair element with its projections.

*** Typing rules for the simply-typed lambda calculus
The set of raw typed lambda terms contains some meaningless terms
under our type interpretation, such as $\pi_1(\lambda x^A.M)$. *Typing rules*
will give them the desired semantics; only a subset of these raw
lambda terms will be typeable.

#+begin_definition
A *typing context* is a sequence of typing assumptions
$x_1:A_1,\dots,x_n:A_n$, where no variable appears more than once.
#+end_definition

Every typing rule assumes a typing context, usually denoted by $\Gamma$ 
or by a concatenation of typing contexts written as $\Gamma,\Gamma'$; and 
a consequence from that context, separated by the $\vdash$ symbol.

 1) The type of $\ast$ is $1$, the rule $(\ast)$ builds this element.

   \begin{prooftree}
   \LeftLabel{($\ast$)}
   \AxiomC{}
   \UnaryInfC{$\Gamma \vdash \ast : 1$}
   \end{prooftree}

 2) The $(var)$ rule simply makes explicit the type of a variable from
    the context.

    \begin{prooftree}
    \LeftLabel{($var$)}
    \AxiomC{}
    \UnaryInfC{$\Gamma, x:A \vdash x:A$}
    \end{prooftree}

 3) The $(pair)$ rule allow us to build pairs by their components. It acts
   as a constructor of pairs.

   \begin{prooftree}
   \LeftLabel{$(pair)$}
   \AxiomC{$\Gamma \vdash a : A$}
   \AxiomC{$\Gamma \vdash b : B$}
   \BinaryInfC{$\Gamma \vdash \left\langle a,b \right\rangle : A \times B$}
   \end{prooftree}

 4) The $(\pi_1)$ and $(\pi_2)$ rules give the semantics of a product
    with two projections to the pair terms. If we have a pair $m : A \times B$, then
    $\pi_1m : A$ and $\pi_2m : B$. They act as two different destructors of pairs.

    \begin{prooftree}
    \LeftLabel{($\pi_1$)}
    \AxiomC{$\Gamma \vdash m : A \times B$}
    \UnaryInfC{$\Gamma \vdash \pi_1m : A$}
    \LeftLabel{($\pi_2$)}
    \AxiomC{$\Gamma \vdash m : A \times B$}
    \UnaryInfC{$\Gamma \vdash \pi_2m : B$}
    \noLine\BinaryInfC{}
    \end{prooftree}

 5) The $(abs)$ introduces a well-typed lambda abstraction. If we have a
    $h : B$ term depending on $x : A$, we can create a lambda abstraction
    from this term. It acts as a constructor of function terms.

    \begin{prooftree}
    \LeftLabel{($abs$)}
    \AxiomC{$\Gamma, x : A \vdash h : B$}
    \UnaryInfC{$\Gamma \vdash \lambda x^A.h : A \to B$}
    \end{prooftree}

 6) The $(app)$ rule gives the type of a well-typed application of a
    lambda term. A term $f : A \to B$ applied to a term $a : A$ is a term
    of type $B$. It acts as a destructor of function terms.

    \begin{prooftree}
    \LeftLabel{$(app)$}
    \AxiomC{$\Gamma \vdash f : A \to B$}
    \AxiomC{$\Gamma \vdash a : A$}
    \BinaryInfC{$\Gamma \vdash f a : B$}
    \end{prooftree}

#+begin_definition
A term is *typable* if we can assign types to all its variables in
such a way that a typing judgment for the type is derivable.
#+end_definition

# Examples of typable and non-typable terms.

# It is easy to check if a term is typable because there is only
# one way to type it.

# If we want to derive term bottom-up, there is only one possible
# choice at each step. Has this to do with the natural deduction
# properties?

*** TODO Natural deduction
# Every derivation in natural deduction is exactly a lambda term.

** TODO Hindley-Milner
** TODO System F
* Mikrokosmos (abstract)                                             :ignore:
#+LATEX: \ctparttext{\color{black}\begin{center}
We have developed *Mikrokosmos*, a lambda calculus interpreter
written in the purely functional programming language Haskell cite:hudak07_haskell.
It aims to provide students with a tool to learn and understand lambda calculus.
#+LATEX: \end{center}}

* Mikrokosmos
** Haskell                                                        :noexport:
** Parsing
*** Monadic parser combinators
A common approach to building parsers in functional programming is to
model parsers as functions. Higher-order functions on parsers act as
/combinators/, which are used to implement complex parsers in a
modular way from a set of primitive ones. In this setting, parsers
exhibit a monad algebraic structure, which can be used to simplify
the combination of parsers. A technical report on *monadic parser combinators*
can be found on cite:hutton96.

The use of monads for parsing is discussed firstly in cite:Wadler85,
and later in cite:Wadler90 and cite:hutton98. The parser type is
defined as a function taking a =String= and returning a list of pairs,
representing a successful parse each. The first component of the pair
is the parsed value and the second component is the remaining
input. The Haskell code for this definition is

#+BEGIN_SRC haskell
newtype Parser a = Parser (String -> [(a,String)])

parse :: Parser a -> String -> [(a,String)]
parse (Parser p) = p

instance Monad Parser where
  return x = Parser (\s -> [(x,s)])
  p >>= q  = Parser (\s -> 
               concat [parse (q x) s' | (x,s') <- parse p s ])
#+END_SRC

where the monadic structure is defined by =bind= and =return=. Given a
value, the =return= function creates a monad that consumes no input
and simply returns the given value. The =>>== function acts as a sequencing
operator for parsers. It takes two parsers and applies the second one
over the remaining inputs of the first one, using the parsed values on
the first parsing as arguments.

An example of primitive *parser* is the =item= parser, which consumes a
character from a non-empty string. It is written in Haskell code as

#+BEGIN_SRC haskell
item :: Parser Char
item = Parser (\s -> case s of 
                       "" -> []
                       (c:s') -> [(c,s')])
#+END_SRC

and an example of *parser combinator* is the =many= function, which
allows one or more applications of the parser given as an argument

#+BEGIN_SRC haskell
many :: Paser a -> Parser [a]
many p = do
  a  <- p
  as <- many p
  return (a:as)
#+END_SRC

in this example =many item= would be a parser consuming all characters
from the input string.

*** Parsec
*Parsec* is a monadic parser combinator Haskell library described in
cite:leijen2001. We have chosen to use it due to its simplicity and
extensive documentation. As we expect to use it to parse user live
input, which will tend to be short, performance is not a critical
concern. A high-performace library supporting incremental parsing,
such as *Attoparsec* cite:attoparsec, would be suitable otherwise.
 
** Usage
*** Mikrokosmos interpreter :noexport:
*** Jupyter kernel
The *Jupyter Project* cite:jupyter is an open source project providing
support for interactive scientific computing. Specifically, the
Jupyter Notebook provides a web application for creating interactive
documents with live code and visualizations. 

We have developed a Mikrokosmos kernel for the Jupyter Notebook,
allowing the user to write and execute arbitrary Mikrokosmos code
on this web application.

# Image of the mikrokosmos jupyter notebook

*** CodeMirror lexer
* Type theory                                                     
** Intuitionistic logic
*** Constructive mathematics
*** The double negation of LEM is provable
In intuitionistic logic, the double negation of the LEM holds for every
proposition, that is,

\[
\forall A\colon \neg \neg (A \vee \neg A)
\]

**** Proof
Suppose $\neg (A \vee \neg A)$. We firstly are going to prove that, under this
specific assumption, $\neg A$ holds. If $A$ were true, $A \vee \neg A$ would be true and we
would arrive to a contradition, so $\neg A$. But then, if we have $\neg A$ we also have
$A \vee \neg A$ and we arrive to a contradiction with the assumption. We should conclude
that $\neg \neg (A \vee \neg A)$.

**** Machine proof
#+latex: \ExecuteMetaData[latex/Ctlc.tex]{id}

** TODO Propositions as types
** TODO Martin-Löf Type Theory
** TODO Type theory as a foundation of mathematics
** TODO Constructive mathematics
*** TODO Proof by contradiction and proof of a negation
# They are fundamentally different
#
# [[https://www.youtube.com/watch?v=21qPOReu4FI][Five stages of accepting constructive mathematics]]
*** TODO Axiom of choice implies excluded middle
# In Agda or Coq!?
** TODO Homotopy Type Theory
* Conclusions
bibliographystyle:alpha
bibliography:Bibliography.bib
