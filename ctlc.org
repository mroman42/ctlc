#+Title: Category Theory and Lambda Calculus
#+Author: Mario Román
#+Options: broken-links:ignore toc:t tasks:nil num:3
#+Todo: TODO(t) OLD(o) | DONE(d)

\clearpage\null\newpage 

** Hidden: To-do list                                                                    :noexport:
*** TODO [#A] Agda exportado a HTML. Enlazar código o apéndices
*** TODO [#A] Escribir sinopsis y abstract con el número pedido de palabras
*** TODO [#A] Añadir lista de referencias principales
  - Selinger
  - MacLane, Categories for the working mathematician
  - Homotopy type theory book
  - nLab
*** TODO [#A] Escribir conclusiones
*** TODO [#B] Repasar todo sustituyendo definiciones de entorno por negrita
*** TODO [#C] Añadir paradoja de Escardó para motivar topología y computación
*** TODO [#C] Añadir ejemplo topológico de nudo que no se cierra
*** TODO [#C] Repasar coloreado de reglas del cálculo lambda simplemente tipado
Especialmente en la parte de deducción natural, evitarlo en otros
puntos o usarlo consistentemente.

*** TODO [#C] Considerar sólo un caso de límites con su dual, en lugar de dos.
*** TODO [#C] Citas en cada capítulo
** Hidden: Macros and libraries                                                            :ignore:
#+latex_class: report-noparts
#+latex_class_options: [titlepage,a4paper,11pt]
#+latex_header_extra: \input{titlepage}\usepackage{wallpaper}\ThisULCornerWallPaper{1}{ugrA4.pdf}

*** Setup                                                                                 :ignore:
#+latex_header_extra: \usepackage[T1]{fontenc}

#+latex_header_extra: \setcounter{secnumdepth}{0}
#+latex_header_extra: \usepackage{enumitem}
#+latex_header_extra: \setitemize{noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt}
#+latex_header_extra: \setlist[enumerate]{topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex}
#+latex_header_extra: \usepackage[top=1in, bottom=1.5in, left=1in, right=1.1in]{geometry}
#+latex_header_extra: \setlength\itemsep{0em}
#+latex_header_extra: % \setlength{\parindent}{0pt}
#+latex_header_extra: \usepackage{parskip}

#+latex_header_extra: \usepackage{minted} \usemintedstyle{colorful}
#+latex_header_extra: \setminted{fontsize=\small}
#+latex_header_extra: \setminted[haskell]{linenos=false,fontsize=\small}
#+latex_header_extra: \renewcommand{\theFancyVerbLine}{\sffamily\textcolor[rgb]{0.5,0.5,1.0}{\oldstylenums{\arabic{FancyVerbLine}}}}

#+latex_header_extra: \usepackage{tcolorbox}
#+latex_header_extra: \tcbuselibrary{theorems}
#+latex_header_extra: \newtcbtheorem[number within=section]{examplebox}{Example}{colback=cyan!2,colframe=cyan!10!black!40,fonttitle=\bfseries}{th}

#+latex_header_extra: \usepackage[conor]{agda}
#+latex_header_extra: \usepackage{catchfilebetweentags}

*** Fonts                                                                                 :ignore:
#+latex_header_extra: % \usepackage{libertineRoman} \usepackage{eulervm}
#+latex_header_extra: % \usepackage{libertine}
#+latex_header_extra: % \usepackage{libertinust1math}
#+latex_header_extra: \usepackage{inconsolata}
#+latex_header_extra: % \usepackage[scale=MatchLowercase]{FiraMono}
#+latex_header_extra: % \usepackage[scale=0.85,nomap]{FiraMono}
#+latex_header_extra: \usepackage[T1]{fontenc}
#+latex_header_extra: \usepackage{multicol}

*** Colors                                                                                :ignore:
#+latex_header: \definecolor{ugrColor}{HTML}{c6474b} % Title
#+latex_header: \definecolor{ugrColor2}{HTML}{c6474b} % Sections
#+latex_header: \definecolor{redPRL}{HTML}{ad2231}
#+latex_header: \definecolor{bluePRL}{HTML}{07608f}
#+latex_header: \definecolor{greenPRL}{HTML}{078f60}

#+latex_header: \colorlet{myred}{redPRL}
#+latex_header: \colorlet{myblue}{bluePRL}
#+latex_header: \newcommand{\red}[1]{{\color{myred}{{#1}}}}
#+latex_header: \newcommand{\blue}[1]{{\color{myblue}{{#1}}}}
#+latex_header: \newcommand{\ctypes}[1]{\color{bluePRL}{#1}}
#+latex_header: \newcommand{\cterms}[1]{\color{redPRL}{\texttt{#1}}}

*** Hyperreferences                                                                       :ignore:
#+latex_header_extra: \hypersetup{colorlinks=true, linktocpage=true, pdfstartpage=3, pdfstartview=FitV,breaklinks=true, pdfpagemode=UseNone, pageanchor=true, pdfpagemode=UseOutlines,plainpages=false, bookmarksnumbered, bookmarksopen=true, bookmarksopenlevel=1,hypertexnames=true, pdfhighlight=/O,urlcolor=greenPRL,linkcolor=greenPRL,citecolor=greenPRL}

*** Libraries                                                                             :ignore:
#+latex_header: \usepackage{amsthm}
#+latex_header: \usepackage{amsmath}
#+latex_header: \usepackage{tikz}
#+latex_header: \usepackage{tikz-cd}
#+latex_header: \usetikzlibrary{shapes,fit,graph,tikzmark}
#+latex_header: \usepackage{bussproofs}
#+latex_header: \EnableBpAbbreviations{}
#+latex_header: \usepackage{mathtools}
#+latex_header: \usepackage{scalerel}
#+latex_header: \usepackage{stmaryrd}

#+latex_header: \BeforeBeginEnvironment{minted}{\vspace{-0.3cm}}
#+latex_header: \AfterEndEnvironment{minted}{\vspace{0cm}}

#+latex_header: \newenvironment{tightcenter}{\setlength\topsep{0pt}\setlength\bottomsep{0pt}\setlength\parskip{0pt}\begin{center}}{\end{center}}

*** Theorem styles                                                                        :ignore:
#+latex_header_extra: \theoremstyle{plain}
#+latex_header_extra: \newtheorem{theorem}{Theorem}[chapter]
#+latex_header_extra: \newtheorem{proposition}[theorem]{Proposition}
#+latex_header_extra: \newtheorem{lemma}[theorem]{Lemma}
#+latex_header_extra: \newtheorem{corollary}[theorem]{Corollary}
#+latex_header_extra: \theoremstyle{definition}
#+latex_header_extra: \newtheorem{definition}[theorem]{Definition}
#+latex_header_extra: \newtheorem{axiom}[theorem]{Axiom}
#+latex_header_extra: \newtheorem{proofs}{Proof}
#+latex_header_extra: \theoremstyle{remark}
#+latex_header_extra: \newtheorem{remark}[theorem]{Remark}
#+latex_header_extra: \newtheorem{exampleth}[theorem]{Example}
#+latex_header_extra: \begingroup\makeatletter\@for\theoremstyle:=definition,remark,plain\do{\expandafter\g@addto@macro\csname th@\theoremstyle\endcsname{\addtolength\thm@preskip\parskip}}\endgroup

*** Math symbols and Unicode support                                                      :ignore:
#+latex_header: \usepackage{amssymb}
#+latex_header: \usepackage{bbm}
#+latex_header: \usepackage[greek,english]{babel}
#+latex_header: \DeclareUnicodeCharacter{22A5}{\ensuremath{\scaleobj{0.8}{\boldsymbol{\bot}}}}
#+latex_header: \DeclareUnicodeCharacter{22A4}{\ensuremath{\scaleobj{0.8}{\boldsymbol{\top}}}}
#+latex_header: \DeclareUnicodeCharacter{2192}{\ensuremath{\scaleobj{0.7}{\boldsymbol{\to}}}}
#+latex_header: \DeclareUnicodeCharacter{2200}{\ensuremath{\scaleobj{0.9}{\boldsymbol{\forall}}}}
#+latex_header: \DeclareUnicodeCharacter{2203}{\ensuremath{\scaleobj{0.85}{\boldsymbol{\exists}}}}
#+latex_header: \DeclareUnicodeCharacter{21D2}{\ensuremath{\scaleobj{0.7}{\boldsymbol{\Rightarrow}}}}
#+latex_header: \DeclareUnicodeCharacter{2115}{\ensuremath{\scaleobj{0.8}{\boldsymbol{\mathbb{N}}}}}
#+latex_header: \DeclareUnicodeCharacter{211D}{\ensuremath{\scaleobj{0.8}{\boldsymbol{\mathbb{R}}}}}
#+latex_header: \DeclareUnicodeCharacter{2124}{\ensuremath{\scaleobj{0.8}{\boldsymbol{\mathbb{Z}}}}}
#+latex_header: \DeclareUnicodeCharacter{2217}{\ensuremath{\scaleobj{0.8}{\boldsymbol{\ast}}}}
#+latex_header: \DeclareUnicodeCharacter{2218}{\ensuremath{\scaleobj{0.9}{\boldsymbol{\circ}}}}
#+latex_header: \DeclareUnicodeCharacter{2243}{\ensuremath{\scaleobj{0.8}{\boldsymbol{\simeq}}}}
#+latex_header: \DeclareUnicodeCharacter{2208}{\ensuremath{\scaleobj{0.8}{\boldsymbol{\in}}}}
#+latex_header: \DeclareUnicodeCharacter{207A}{\ensuremath{\scaleobj{0.8}{\boldsymbol{^{+}}}}}
#+latex_header: \DeclareUnicodeCharacter{03B1}{\ensuremath{\scaleobj{0.9}{\boldsymbol{\alpha}}}}
#+latex_header: \DeclareUnicodeCharacter{03B2}{\ensuremath{\scaleobj{0.9}{\boldsymbol{\beta}}}}
#+latex_header: \DeclareUnicodeCharacter{03B3}{\ensuremath{\scaleobj{0.9}{\boldsymbol{\gamma}}}}
#+latex_header: \DeclareUnicodeCharacter{03B4}{\ensuremath{\scaleobj{0.9}{\boldsymbol{\delta}}}}
#+latex_header: \DeclareUnicodeCharacter{03A3}{\ensuremath{\scaleobj{0.9}{\boldsymbol{\Sigma}}}}
#+latex_header: \DeclareUnicodeCharacter{03A9}{\ensuremath{\scaleobj{0.8}{\boldsymbol{\Omega}}}}
#+latex_header: \DeclareUnicodeCharacter{2209}{\ensuremath{\scaleobj{0.8}{\boldsymbol{\notin}}}}
#+latex_header: \DeclareUnicodeCharacter{2261}{\ensuremath{\scaleobj{0.8}{\boldsymbol{\equiv}}}}
#+latex_header: \DeclareUnicodeCharacter{2262}{\ensuremath{\scaleobj{0.8}{\boldsymbol{\not\equiv}}}}
#+latex_header: \DeclareUnicodeCharacter{2228}{\ensuremath{\scaleobj{0.8}{\boldsymbol{\vee}}}}
#+latex_header: \DeclareUnicodeCharacter{2225}{\ensuremath{\scaleobj{0.8}{\boldsymbol{\|}}}}
#+latex_header: % \mathchardef\mhyphen="2D % define a math hyphen

#+latex_header: \newcommand{\impl}{\Rightarrow} % Implication
#+latex_header: \DeclarePairedDelimiter\pair{\langle}{\rangle} % Pair notation
#+latex_header: \DeclarePairedDelimiter\intr{\llbracket}{\rrbracket} % Interpretation brackets
#+latex_header: % \DeclarePairedDelimiter\intl{\llbracket}{\rrbracket} % Internal language brackets

*** Categories                                                     :ignore:
#+latex_header: % \newcommand\hom{\mathrm{hom}}
#+latex_header: \newcommand\id{\mathrm{id}}
#+latex_header: \newcommand\Id{\mathrm{Id}}
#+latex_header: \newcommand\tonat{\Rightarrow}
#+latex_header: \newcommand\todot{\xrightarrow{.}}
#+latex_header: \newcommand\toddot{\xrightarrow{..}}
#+latex_header: \newcommand\Set{\mathsf{Set}}
#+latex_header: \newcommand\Cats{\mathsf{Cat}}
#+latex_header: \newcommand\Sets{\mathsf{Set}}
#+latex_header: \newcommand\sSets{\mathsf{sSets}}
#+latex_header: \newcommand\Nat{\operatorname{Nat}}
#+latex_header: \newcommand\Limit{\varprojlim}
#+latex_header: \newcommand\Colimit{\operatorname{colim}}

#+latex_header: \newcommand\Mod{\mathrm{Mod}}
#+latex_header: \newcommand\Top{\mathsf{Top}}
#+latex_header: \newcommand\lThr{\lambda\mathsf{Thr}}
#+latex_header: \newcommand\Ccc{\mathsf{Ccc}}

# Corner quotes from: http://www.logicmatters.net/latex-for-logicians/symbols/corner-quotes-for-godel-numbers/
#+latex_header: \newbox\gnBoxA\newdimen\gnCornerHgt\setbox\gnBoxA=\hbox{$\ulcorner$}
#+latex_header: \global\gnCornerHgt=\ht\gnBoxA\newdimen\gnArgHgt\def\intl #1{%
#+latex_header: \setbox\gnBoxA=\hbox{$#1$}%
#+latex_header: \gnArgHgt=\ht\gnBoxA%
#+latex_header: \ifnum \gnArgHgt<\gnCornerHgt \gnArgHgt=0pt%
#+latex_header: \else \advance \gnArgHgt by -\gnCornerHgt\fi \raise\gnArgHgt\hbox{$\ulcorner$} \box\gnBoxA %
#+latex_header: \raise\gnArgHgt\hbox{$\urcorner$}}

*** Topos                                                          :ignore:
#+latex_header: \newcommand\Sub{\operatorname{Sub}}
#+latex_header: \newcommand\FinSet{\mathsf{FinSet}}

*** Type systems                                                   :ignore:
#+latex_header: \newcommand{\lcred}{red!90!black}
#+latex_header: \newcommand{\stlc}{\lambda_{\to}}
#+latex_header: \newcommand{\systemf}{\lambda{2}}
#+latex_header: \newcommand{\systemfo}{\lambda\omega}
#+latex_header: \newcommand{\systemlp}{\lambda\Pi}
#+latex_header: \newcommand{\systemfp}{\lambda{\Pi}2}
#+latex_header: \newcommand{\systemlpo}{\lambda\Pi\underline{\omega}}
#+latex_header: \newcommand{\systemo}{\lambda\underline{\omega}}
#+latex_header: \newcommand{\systemcoc}{\lambda\Pi\omega}
#+latex_header: \newcommand{\lcubett}[1]{\color{cyan!70}{\text{\scriptsize{#1}}}}

*** Lambda calculus                                                :ignore:
#+latex_header: \newcommand\skiabs{\mathfrak{H}} % SKI abstraction
#+latex_header: \newcommand\lambdatrans{\mathfrak{L}} % Lambda transformation
#+latex_header: \newcommand\tto{\twoheadrightarrow} % Reduction
#+latex_header: \newcommand\redu{\mathsf{Red}} % Reducibility
#+latex_header: \newcommand\fst{\mathtt{fst}} % first
#+latex_header: \newcommand\snd{\mathtt{snd}} % second
#+latex_header: \DeclareMathOperator{\freevars}{FV} % Free variables
#+latex_header: \newcommand\TypeTemp{\mathsf{TypeTemp}} % type templates
*** Type theory                                                    :ignore:
#+latex_header: \newcommand{\wtype}{\mathop{\vphantom{\sum}\mathchoice{\vcenter{\hbox{\huge{\textsf{W}}}}}{\vcenter{\hbox{\Large\textsf{W}}}}{\textsf{W}}{\textsf{W}}}\displaylimits}
#+latex_header: \newcommand{\wt}{\textsf{W}}
#+latex_header: \newcommand{\proj}{\mathtt{pr}}
#+latex_header: \newcommand\refl{\mathsf{refl}}
#+latex_header: \newcommand\transport{\mathsf{transport}}
#+latex_header: \newcommand\ap{\mathsf{ap}}
#+latex_header: \newcommand\apd{\mathsf{apd}}
#+latex_header: \newcommand\J{\mathsf{J}}
#+latex_header: \usepackage{scalefnt}\DeclareMathOperator*\bigexists{\vphantom{\sum}\mathchoice{\vcenter{\hbox{\scalefont{2}$\exists$}}}{\vcenter{\hbox{\scalefont{1.4}$\exists$}}}{\vcenter{\hbox{\scalefont{1}$\exists$}}}{\vcenter{\hbox{\scalefont{0.75}$\exists$}}}}

** Abstract
:PROPERTIES:
:UNNUMBERED: t
:END:

# TODO: Resumen y palabras clave.  Breve resumen del trabajo realizado.  Se
# incluirán seguidamente al menos cinco palabras clave que definan el
# trabajo a criterio del autor

# There is no claim of originality (?)

*Chapter 1*: The \lambda-calculus is a collection of systems
formalizing the notion of functions. They can be seen as programming
languages and formal logics at the same time. We focus on the
properties of the untyped \lambda-calculus and simply typed
\lambda-calculus, and we study their logical interpretation.

*Chapter 2*: We have developed *Mikrokosmos*, an untyped and simply
typed \lambda-calculus interpreter written in the purely functional
programming language Haskell cite:hudak07_haskell.  It aims to provide
students with a tool to learn and understand \lambda-calculus and the
relation between logic and types. We show how to program and prove
statements of intuitionistic propositional logic with it.

*Chapter 3*: Categories will be the framework we will use to study the
fundamental notion of function composition inside mathematics. They
provide a useful language to talk about theories, mathematics and
logic. In particular, adjoint functors will be one of the key insights
we will use to understand and expand the connection between
computation and logic we have described so far.  This section is based
on cite:maclane78.

*Chapter 4*: The internal logic of categories is studied. In
particular, cartesian closed categories can be used to model lambda
calculus, and their structure serves as a basis for locally cartesian
closed categories and topoi, which provide a framework for
higher-order logics. Dependent type theory arises as the natural
language for these richer categories. This section is based on
the work by cite:maclane94 and cite:martinlof75.

*Chapter 5*: Type theory provides both a programming language and a
foundation of mathematics. The embedding of a category of sets and
some classical principles inside constructive logic are studied.  We
also present and formalize inside a programming language a first
result of Homotopy Type Theory. This section is based on cite:hottbook.

** Sinopsis
:PROPERTIES:
:UNNUMBERED: t
:END:

# Deberá estar escrito completamente en inglés y tener una longitud
# mínima de 1500 palabras. Igualmente aparecerán las palabras clave en inglés.

# TODO: Actualmente tiene 300 palabras

Empezamos exponiendo el cálculo lambda de Church como modelo de
computación, prestando especial interés a la relación de sus variantes
tipadas con la lógica proposicional intuicionista. Desarrollamos un
intérprete basado en estas ideas y utilidades para combinarlo con
Jupyter Notebook y con Javascript que lo hacen apto para la docencia.

La perspectiva de la teoría de categorías y en especial la noción de
Lawvere de las adjunciones como elemento fundacional nos permiten
primero formalizar la estructura lógica del cálculo lambda como el
lenguaje interno de las categorías cartesianas cerradas e,
inmediatamente después, enriquecer esta estructura en categorías
localmente cartesianas cerradas hacia la noción de tipos dependientes.
Los tipos dependientes nos proveen un marco lógico de orden superior
con una interpretación computacional natural. Categorías, lógica y
computación aparecen como tres manifestaciones de una misma noción.

La lógica interna de estas categorías es suficientemente rica como
para permitirnos desarrollar teorías matemáticas que además pueden
expresarse en un lenguaje de programación con un sistema de tipos
suficientemente fuerte que sirve como asistente de demostraciones.
Para demostrar el potencial de esta perspectiva, usamos el lenguaje de
programación Agda para formalizar los reales positivos con cortes de
Dedekind en teoría de tipos de Martin-Löf y proponemos un ejemplo de
topología sintética usando el axioma de Univalencia de Voevodsky.

Nuestras referencias principales son la exposición del cálculo lambda
de Selinger cite:selinger13 en la primera parte, los textos de teoría
de categorías de MacLane cite:maclane78 y Awodey cite:awodey10 en la
segunda, y el libro fundacional de la teoría homotópica de tipos
cite:hottbook en la parte final. El proyecto nLab cite:nlab ha sido útil para
encontrar la bibliografía relevante.

** TODO Declaración
** TODO Original

 * An implementation of the Dedekind real numbers in Agda.
 * An implementation in Agda of Diaconescu's theorem.
 * A proof, using lambda calculus, of Lawvere's diagonal theorem.

** Quote                                                                                   :ignore:
:PROPERTIES:
:UNNUMBERED: t
:END:

*** Quote: Lawvere                                                 :ignore:
#+latex: \newpage
#+latex: \vspace*{\fill}
#+begin_quote
\centering
\raggedleft
What is the primary tool for such summing up of \\
the essence of ongoing mathematics? Algebra! \\
Nodal points in the progress of this kind of \\
research occur when, as in the case with the \\
finite number of axioms for the metacategory \\
of categories, all that we know so far can be \\
expressed in a single sort of algebra.

  -- *F. William Lawvere*
#+end_quote
#+latex: \vspace*{\fill}

*** Quote: McBride                                               :noexport:
#+latex: \newpage
#+latex: \vspace*{\fill}
#+begin_quote
\centering
\raggedleft
Mathematics has serious cultural issues. \\
Too much fame for climbing mountains; \\
not enough for flattening them.

   -- *Conor McBride*, \\
#+end_quote
#+latex: \vspace*{\fill}

** TODO Preamble
# La introducción deberá:
# 
# • Contextualizar   el   trabajo   explicando   antecedentes   importantes   para   el   desarrollo
#   realizado y efectuando, en su caso, un estudio de los progresos recientes.
# • Describir el problema abordado, de forma que el lector tenga desde este momento
#   una  idea  clara  de  la  cuestión  a  resolver  o del  producto  a desarrollar  y una  visión
#   general de la solución alcanzada.
# • Exponer   con   claridad   las   técnicas   y  áreas   matemáticas,   así   como   los   conceptos   y
#   herramientas de la ingeniería informática que se han empleado.
# • Sintetizar el contenido de la memoria.
# • Citar las principales fuentes consultadas.
#

* Lambda calculus
** Untyped \lambda-calculus
<<sec-untypedlambda>>

**** Introduction                                                 :ignore:
When are two functions equal? Classically in mathematics, /functions are graphs/.
A function from a domain to a codomain, $f \colon X \to Y$, is seen as a subset 
of the product space: $f \subset X \times Y$.
Any two functions are identical if they map equal inputs to equal outputs;
and a function is completely determined by what its outputs are under
different inputs. This vision is called */extensional/*.

From a computational point of view, this perspective could seem
incomplete in some cases; we usually care not only about the result
but, crucially, about /how/ it can be computed.  Classically in
computer science, /functions are formulae/; and two functions mapping
equal inputs to equal outputs need not to be equal. For instance, two
sorting algorithms can have different efficiency or different memory
requisites, even if they output the same sorted list. This vision,
where two functions are equal if and only if they are given by
essentially the same formula, is called */intensional/* (see cite:selinger13,
where this difference is detailed).

The *\lambda-calculus* is a collection of formal systems, all of them
based on the lambda notation introduced by Alonzo Church in the 1930s
while trying to develop a foundational notion of functions /as formulae/
on mathematics. It is a logical theory of functions, where application and
abstraction are primitive notions, and at the same time it
is also one of the simplest programming languages, in which many other
full-fledged languages are based.

The *untyped* or *pure \lambda-calculus* is syntactically the
simplest of these formal systems. In it, a function does not need a
domain nor a codomain; every function is a formula that can be
directly applied to any expression. It even allows functions to be
applied to themselves, a notion that would be troublesome
in our usual set-theoretical foundations. In particular, if $f$ were a member of its own
domain, the infinite descending sequence
\[
f \ni \{f,f(f)\} \ni f \ni \{f,f(f)\} \ni \dots,
\]
would exist, thus contradicting the *regularity axiom* of Zermelo-Fraenkel
set theory (see, for example, cite:kunen11).
In constrast, untyped \lambda-calculus presents some problems that
would never appear in our usual foundations such as non-terminating
functions. An approach to solving these is presented in Section [[sec-simplytypedlambda]].

This presentation of the untyped lambda calculus will follow
cite:Hindley08 and cite:selinger13.

*** Untyped \lambda-calculus
**** As a formal language                                                                :ignore:
As a formal language, the untyped \lambda-calculus is given by a set of
equations between expressions called /\lambda-terms/, and equivalences
between them can be computed using some manipulation rules.
These \lambda-terms can stand for functions or arguments indistinctly:
they all use the same \lambda-notation in order to define function
abstractions and applications.

The *\lambda-notation* allows a function to be written and inlined as any other element
of the language, identifying it with the formula it represents and 
admitting a more succinct representation. For example, the polynomial function
$p(x) = x^2 + x$
is written in \lambda-calculus as
$\lambda x.\ x^2 + x$; and the particular evaluation $p(2)$ is written as $(\lambda x.\ x^2+x)(2)$.
In general, $\lambda x.M$ is a function taking $x$ as an argument and returning $M$,
which is a term where $x$ may appear as a symbolic variable.

The use of \lambda-notation also eases the writing of
*higher-order functions*, functions whose arguments or outputs are
functions themselves. For instance, $\lambda f.(\lambda y.f(f(y)))$
would be a function taking $f$ as an argument and returning $\lambda y.f(f(y))$,
which is itself a function; most commonly written as $f \circ f$. In particular,
the following expression
\[
\Big( \big( \lambda f.(\lambda y.f(f(y))) \big)
\big( \lambda x.x^2 + x \big) \Big) (1)
\]
evaluates to $6$. It can be read as applying the polynomial $x^2+x$ twice to
the initial argument $1$.

**** Lambda terms                                                                        :ignore:
#+begin_definition
<<def-lambdaterms>>
*\lambda-terms* are constructed using the following rules:

  * every */variable/*, taken from an infinite countable set of
    variables and usually written with a lowercase single letter
    $(x, y, z, \dots)$, is a \lambda-term;

  * for any two \lambda-terms $M,N$, their */application/*, written as $MN$,
    is a \lambda-term;

  * for any \lambda-term $M$ and for any variable $x$, their */abstraction/*,
    written as $\lambda x.M$, is a \lambda-term;

  * every possible \lambda-term can be constructed using these rules
    and no other \lambda-term exists.

Equivalently, they are given by the Backus-Naur form
$\mathsf{Term} ::= x \mid (\mathsf{Term}\ \mathsf{Term}) \mid (\lambda x.\mathsf{Term})$,
where $x$ represents any variable.
#+end_definition

By convention, we omit outermost parentheses and assume
left-associativity, for example, $MNP$ will always mean $(MN)P$. Note
that the application of \lambda-terms is not the same as
composition of functions, which is associative. We also
consider \lambda-abstraction as having the lowest precedence. For
example, $\lambda x. M N$ should be read as $\lambda x.(MN)$ instead
of $(\lambda x.M) N$.

*** Free and bound variables, substitution
<<sec-freeboundvars>>
In \lambda-calculus, the scope of a variable restricts to the \lambda-abstraction
where it appears, if any. Thus, the same variable can be used multiple
times on the same term independently. For example, in $(\lambda x.x)(\lambda x.x)$, the
variable $x$ appears twice with two different meanings.

#+attr_latex: :options [Free variables]
#+begin_definition
<<def-freevariables>>
Any ocurrence of a variable $x$ inside the /scope/ of a lambda is said
to be */bound/*; and any variable without bound ocurrences is said to be
*/free/*.  The *set of free variables* of a term $M$ is defined inductively
on the structure of lambda terms as
\[\begin{array}{ll}
\freevars(x) = \{x\}, & \mbox{ for any variable } x, \\
\freevars(MN) = \freevars(M) \cup \freevars(N), & \mbox{ for any two terms } M \mbox{ and } N, \\
\freevars(\lambda x.M) = \freevars(M) \setminus \{x\}, & \mbox{ for any variable } x \mbox{ abstracted over a term } M. \\
\end{array}\]
#+end_definition

Evaluation in \lambda-calculus relies in the notion of */substitution/*.
Any free ocurrence of a variable can be substituted by a term, as we do
when evaluating function applications. For instance, in the previous example, we
can evaluate $(\lambda x.\ x^2+x)(2)$ into $6$ by substituting $2$ in the place of $x$ inside $x^{2} + x$;
as in
\[\begin{tikzcd}
(\lambda x.\ x^2+x)(2) \rar{x \mapsto 2}
&
2^{2} + 2.
\end{tikzcd}\]
This, however, should be done avoiding the unintended binding which happens
when a variable is substituted inside the scope of a binder with the
same name, as in the following example: if we were to evaluate the expression
$(\lambda x.y x)(\lambda z.xz)$,
where $x$ appears two times (once bound and once free), we should substitute $y$ by $(\lambda z.xz)$
on $(\lambda x.yx)$ and $x$ (the free variable) would get tied to $x$ (the bounded variable)
\[\begin{tikzcd}
(\lambda y.\lambda x.yx)(\lambda z.xz)
\ar{rr}{y \mapsto (\lambda z.xz)} && 
(\lambda x.(\lambda z.xz)x).
\end{tikzcd}\]

To avoid this, the bounded $x$ must be given a new name before the
substitution, which must be carried as follows, keeping $x$ free,
\[\begin{tikzcd}
(\lambda y. \lambda u.y u)(\lambda z.\ xz) \ar{rr}{y \mapsto (\lambda z.xz)} & & (\lambda u.(\lambda z.xz)u).
\end{tikzcd}\]

#+begin_definition
The *substitution* of a variable $x$ by a term $N$ on $M$ is
written as $M[N/x]$ and defined inductively on the structure
of lambda terms as
\[\begin{aligned}
x[N/x] &\equiv N,\\
y[N/x] &\equiv y, & \text{ if } y \neq x,\\
(MP)[N/x] &\equiv (M[N/x])(P[N/x]),\\
(\lambda x.P)[N/x] &\equiv \lambda x.P,\\
(\lambda y.P)[N/x] &\equiv \lambda y.P[N/x] & \text{ if } y \notin \freevars(N), \\
(\lambda y.P)[N/x] &\equiv \lambda z.P[z/y][N/x] & \text{ if } y \in \freevars(N),
\end{aligned}\]

where, in the last clause, $z$ is a fresh variable that is not
used anywhere inside any of the other expressions.
#+end_definition

We could define a criterion for choosing exactly what this new
variable should be, or simply accept that this procedure is not
/well-defined/, but only /well-defined up to a change on the name of
the variables/.  This equivalence relation between terms with the same
structure but different variable names is defined formally on the
next section.  In practice, it is common to follow the /Barendregt's
variable convention/, which simply assumes that bound variables have
been renamed to be distinct.

*** Alpha equivalence
Variables are only placeholders; and its name, as we have
seen before, is not relevant. Two \lambda-terms whose only difference is
the naming of the variables are called /\alpha-equivalent/. For example,
$(\lambda x.\lambda y. x\ y)$ is \alpha-equivalent to $(\lambda f.\lambda x. f\ x)$.

The relation of *\alpha-equivalence* formally captures the fact that the name of a bound
variable can be changed without changing the meaning of the term.  This
idea appears repeatedly on mathematics; for example, the renaming of
variables of integration or the variable on a limit are a examples of
\alpha-equivalence.
\[
\int_0^1 x^2\ dx = \int_0^1 y^2\ dy;
\qquad
\lim_{x \to \infty} \frac{1}{x} = \lim_{y \to \infty} \frac{1}{y}.
\]

#+begin_definition
*\alpha-equivalence* is the smallest relation $=_{\alpha}$ on
\lambda-terms that is both an equivalence relation, that is,

  * it is /reflexive/, $M =_{\alpha} M$;
  * it is /symmetric/, if $M =_{\alpha} N$, then $N =_{\alpha} M$;
  * and it is /transitive/, if $M=_{\alpha}N$ and $N=_{\alpha}P$, then $M=_{\alpha}P$;

and compatible with the structure of lambda terms, that is,

  * if $M =_{\alpha} M'$ and $N =_{\alpha} N'$, then $MN =_{\alpha}M'N'$;
  * if $M=_{\alpha}M'$, then $\lambda x.M =_{\alpha} \lambda x.M'$;
  * if $y$ does not appear on $M$, $\lambda x.M =_{\alpha} \lambda y.M[y/x]$.

The last clause captures the idea of freely substituting unused
variables inside an expression.
#+end_definition

*** Beta reduction
The core notion of evaluation in \lambda-calculus is captured by the idea
of *\beta-reduction*. Until now, evaluation has been only informally
described; it is time to define it as a relation, $\tto_{\beta}$, going from the
initial term to any of its partial evaluations. We
consider first a /one-step reduction/ relationship, called
$\to_{\beta}$, and we extend it later by transitivity to $\tto_{\beta}$.

Ideally, we would like to define evaluation as a series of reductions
into a canonical form which could not be further reduced.
Unfortunately, as we will see later, it is not possible to find that
canonical form in general.

#+begin_definition
<<def-betared>>
*Single-step \beta-reduction* is the smallest relation on \lambda-terms
capturing the notion of evaluation and preserving the structure of \lambda-abstractions
and applications. That is, the smallest relation containing

  * $(\lambda x.M)N \to_{\beta}M[N/x]$ for any terms $M,N$ and any variable $x$,
  * $MN \to_{\beta} M'N$ and $NM \to_{\beta} NM'$ for any $M,M'$ such that $M \to_{\beta} M'$, and
  * $\lambda x.M \to_{\beta} \lambda x.M'$, for any $M,M'$ such that $M \to_{\beta} M'$.

The reflexive transitive closure of $\to_{\beta}$ is written as $\tto_{\beta}$. The symmetric
closure of $\tto_{\beta}$ is called *\beta-equivalence* and is written as $=_{\beta}$, or simply $=$.
#+end_definition

*** Eta reduction
Although we lost the extensional view of functions when we decided to
adopt the /functions as formulae/ perspective, some notion of
/function extensionality/ in \lambda-calculus can be partially recovered
by the notion of \eta-reduction: any term which simply applies a function to the
argument it takes can be reduced to that function. That is, given any term $M$, the
abstraction $\lambda x.M x$ can be reduced to $M$.

#+begin_definition
*\eta-reduction* is the smallest relation on \lambda-terms satisfiying 

 * $\lambda x.Mx \to_{\eta} M$, for any $x \notin \mathrm{FV}(M)$,
 * $MN \to_{\eta} M'N$ and $NM \to_{\eta} NM'$ for any $M,M'$ such that $M \to_{\eta} M'$, and
 * $\lambda x.M \to_{\eta} \lambda x.M'$, for any $M,M'$ such that $M \to_{\eta} M'$.

Note that, in the particular case where $M$ is itself a \lambda-abstraction,
\eta-reduction is simply a particular case of \beta-reduction.
We define single-step \beta\eta-reduction as the union of \beta-reduction
and \eta-reduction. This relation is written as $\to_{\beta\eta}$ and its reflexive transitive
closure is written as $\tto_{\beta\eta}$.
#+end_definition

# Comments in https://cstheory.stackexchange.com/a/8261/28986
# suggest a theorem in Urzyczyn, Sorensen which might be relevant.

*** Confluence
It is not possible in general to evaluate a \lambda-term into a
canonical, non-reducible term. We discuss many examples of this
phenomenon in the following sections. However, we will be able to
prove that, in the cases where it exists, it is unique. This property
is a consequence of a sightly more general one called */confluence/*,
which can be defined in any abstract rewriting system.

#+attr_latex: :options [Confluence]
#+begin_definition
A relation $\to$ on a set ${\cal S}$ is *confluent* if, given its reflexive
transitive closure $\tto$ and any terms $M,N,P \in {\cal S}$, the relations $M \tto N$
and $M \tto P$ imply the existence of some $Z \in {\cal S}$ such that $N \tto Z$ and $P \tto Z$.
#+end_definition

Given any binary relation $\to$ of which $\tto$ is its reflexive transitive
closure, we can consider three related properties:

  * the *confluence property* (also called /Church-Rosser property/) we have just defined;
  * the *quasidiamond property*, similar to the confluence property but assuming $M \to N$
    and $M \to P$ instead of the weaker hypothesis of $M \tto N$ and $M \tto P$;
  * and the *diamond property*, which is defined by substituting $\tto$ by $\to$ in
    the definition of confluence.

The three properties can be represented respectively as follows
(/left:/ confluence, /center:/ quasidiamond property, /right:/ diamond property).
\[\begin{tikzcd}[column sep=small]
& 
M \drar[two heads]\dlar[two heads] &&& 
M \drar\dlar &&& 
M \drar\dlar &\\
N \drar[dashed,two heads] && 
P \dlar[dashed,two heads] & 
N \drar[dashed,two heads] &&
P \dlar[dashed,two heads] &
N \drar[dashed] && 
P \dlar[dashed] \\& 
Z &&&
Z &&&
Z &\\
\end{tikzcd}\]
#+latex: \\[-30pt]
We can show that the diamond relation implies confluence; while the
quasidiamond does not. In fact, the following figure provides
a relation satisfying the quasidiamond property but not the
confluence property (from cite:selinger13). If we want to prove confluence for a given
relation, we must use the diamond property instead of the quasidiamond
property.
\[\begin{tikzcd}[column sep=tiny, row sep=tiny]
& & \bullet \drar\dlar & & & \\
& \bullet \dlar & & \bullet \dlar\drar & & \\
\bullet\drar & & \bullet \drar\dlar & & \bullet \drar & \\
 & \bullet\dlar & & \bullet \drar\dlar & & \bullet\dlar \\
\bullet\drar & & \bullet \drar\dlar & & \bullet \drar & \\
 & \bullet\dlar & & \bullet \drar\dlar & & \bullet\dlar \\
\makebox[0pt][l]{\dots}\phantom{\bullet} & & \makebox[0pt][l]{\dots}\phantom{\bullet} & & \makebox[0pt][l]{\dots}\phantom{\bullet} & \\
\end{tikzcd}\]

The statement of $\tto_{\beta}$ and $\tto_{\beta\eta}$ being confluent is what we
call the */Church-Rosser Theorem/*. The definition of a relation satisfying
the diamond property and whose reflexive transitive closure is $\tto_{\beta\eta}$ will
be the core of our proof.

*** The Church-Rosser theorem
The proof presented here is due to Tait and Per Martin-Löf; an earlier
but more convoluted proof was discovered by Alonzo Church and Barkley 
Rosser in 1935 (see cite:barendregt84 and cite:pollack95).
It is based on the idea of parallel one-step reduction.

**** Parallel one-step reduction                                                         :ignore:
#+begin_definition
We define the *parallel one-step reduction* relation on \lambda-terms, $\rhd$,
as the smallest relation satisfying that the following properties hold
for any variable ${x}$ and any terms ${N},{N'},{M},{M'}$ such that ${M}\rhd{M'}$
and ${N}\rhd{N'}$:

  * reflexivity for variables, ${x} \rhd {x}$;
  * parallel application, ${MN} \rhd {M'N'}$;
  * \lambda-abstraction congruence, ${\lambda x.N} \rhd {\lambda x.N'}$;
  * parallel substitution, ${(\lambda x.M)N} \rhd {M'[N'/x]}$;
  * and extensionality, ${\lambda x.M x} \rhd {M'}$, if ${x} \not\in \mathrm{FV}({M})$.

Using the first three rules, it is trivial to show inductively that
this relation is in fact reflexive.
#+end_definition

**** Transitive reflexive closure of parallel one-step reduction                         :ignore:
#+begin_lemma
<<lemma-transclosureparallel>>
The reflexive transitive closure of $\rhd$ is $\tto_{\beta\eta}$. In particular, given
any \lambda-terms ${P}$ and ${P'}$,

  1) if ${P} \to_{\beta\eta} {P'}$, then ${P} \rhd {P'}$;
  2) if ${P} \rhd {P'}$, then ${P} \tto_{\beta\eta} {P'}$.
#+end_lemma
#+begin_proof
In both cases, we apply induction on the structure of the derivation.

1. All possible ways in which we can arrive at $P \to_{\beta\eta} P'$ imply $P \rhd P'$.
   They are

     * $(\lambda x.M)N \to M[N/x]$; where we know that, by parallel substitution
       and reflexivity $(\lambda x.M)N \rhd M[N/x]$;

     * $MN \to M'N$ and $NM \to NM'$; where we know that, by
       induction $M \rhd M'$, and by parallel application and reflexivity, $MN \rhd M'N$
       and $NM \rhd NM'$;

     * congruence to \lambda-abstraction, which is a shared property between
       the two relations;

     * $\lambda x. Mx \to M$ with $x \not\in \mathrm{FV}(M)$; where we can apply
       extensionality for $\rhd$ and reflexivity.

2. All the possible ways in which we can deduce $M \rhd M'$ imply $M \to_{\beta\eta} M'$.
   They are
     
     * the trivial one, reflexivity;

     * parallel application $NM \rhd N'M'$, where, by induction, we have $M \tto M'$ 
       and $N \tto N'$. Using two steps, $NM \tto N'M \tto N'M'$ we prove $NM \tto N'M'$;

     * congruence to \lambda-abstraction $\lambda x.N \rhd \lambda x.N'$, where, by induction,
       we know that $N \tto N'$, so $\lambda x.N \tto \lambda x.N'$;

     * parallel substitution, $(\lambda x.M)N \rhd M'[N'/x]$, where, by induction,
       we know that $M \tto M'$ and $N\tto N'$. Using multiple steps,
       $(\lambda x.M)N \tto (\lambda x.M')N \tto (\lambda x.M')N' \to M'[N'/x]$;

     * extensionality, $\lambda x.M x \rhd M'$, where by induction $M \tto M'$, and trivially,
       $\lambda x.Mx \tto \lambda x.M'x$.

Because of this, the reflexive transitive closure of $\rhd$ is a subset and a
superset of $\tto$ at the same time. It follows that they must be equal.
#+end_proof

**** Substitution lemma                                                                  :ignore:
In order to prove that this newly defined relation has the diamond
property, we will define a reduction of a term with the property that
it can be reached from any of its parallel one-step reductions. We
first prove a lemma on substitution that will handle later the more
challenging cases of the proof.

#+attr_latex: :options [Substitution Lemma]
#+begin_lemma
<<lemma-subsl>>
Let $M,M',U$ and $U'$ be four lambda terms such that $M \rhd M'$ and $U \rhd U'$.
Then, we have $M[U/y] \rhd M'[U'/y]$ for any variable $y$.
#+end_lemma
#+begin_proof
By structural induction on the derivations of $M \rhd M'$ we have the following
cases, depending on what was the last derivation rule we used. 
Note that we are implicitly assuming the Barendregt's variable
convention: all variables have been renamed to avoid clashes.

  * Reflexivity, $M = x$. If $x$ precisely is the variable we are substituting, with $x=y$,
    we simply use $U \rhd U'$; if not, $x \neq y$, we use reflexivity on $x$ to get $x \rhd x$.

  * Parallel application. Let $M$ and $M'$ be $PN$ and $P'N'$ respectively, where
    $P \rhd P'$ and $N \rhd N'$. By induction hypothesis $P[U/y] \rhd P'[U'/y]$ and
    $N[U/y]\rhd N'[U'/y]$, hence $(PN)[U/y] \rhd (P'N')[U'/y]$ by definition
    of substitution.

  * Congruence. By induction, $N[U/y] \rhd N'[U'/y]$ and therefore $\lambda x.N[U/y] \rhd \lambda x.N'[U'/y]$.

  * Parallel substitution. Let $M$ and $M'$ be $(\lambda x.P)N$ and $(\lambda x.P')N'$ respectively,
    where $P \rhd P'$ and $N \rhd N'$. By induction hypothesis, $P[U/y] \rhd P'[U'/y]$ and $N[U/y] \rhd N[U'/y]$,
    hence $((\lambda x.P)N)[U/y] \rhd P'[U'/y][N'[U'/y]/x] = P'[N'/x][U'/y]$.

  * Extensionality. Let $M$ and $M'$ be $\lambda x.Px$ and $\lambda x.P'x$ respectively,
    where $x \notin \mathrm{FV}(P)$. By induction hypothesis, $P \rhd P'$, hence
    $\lambda x.P[U/y]x \rhd P'[U'/y]$. \qedhere
#+end_proof

**** Maximal parallel one-step reduct                                                    :ignore:
#+begin_definition 
The *maximal parallel one-step reduct* $M^{\ast}$ of a \lambda-term $M$ is defined
inductively as

  * $x^{\ast} = x$, if $x$ is a variable;
  * $(PN)^{\ast} = P^{\ast}N^{\ast}$;
  * $((\lambda x.P)N)^{\ast} = P^{\ast}[N^{\ast}/x]$;
  * $(\lambda x.N)^{\ast} = \lambda x.N^{\ast}$;
  * $(\lambda x.Px)^{\ast} = P^{\ast}$, given $x \notin \mathrm{FV}(P)$.
#+end_definition

**** Diamond property of parallel reduction                                              :ignore:
#+attr_latex: :options [Diamond property of parallel reduction]
#+begin_lemma
<<lemma-paralleldiamond>>
Given any $M'$ such that $M \rhd M'$, it can be proved that $M' \rhd M^{\ast}$. Parallel
one-step reduction has the diamond property.
#+end_lemma
#+begin_proof
We apply again induction on the possible derivations of $M \rhd M'$.

  * Reflexivity gives us $M' = x = M^{\ast}$.

  * Parallel application. By induction, we have $P \rhd P^\ast$ and $N \rhd N^{\ast}$; depending
    on the form of $P$, we have

    - $P$ is not a \lambda-abstraction and $P'N' \rhd P^{\ast}N^{\ast} = (PN)^{\ast}$.

    - $P = \lambda x.Q$ and $P \rhd P'$ could be derived using congruence to \lambda-abstraction
      or extensionality. On the first case we know by induction hypothesis that $Q'\rhd Q^{\ast}$
      and $(\lambda x.Q')N' \rhd Q^{\ast}[N^{\ast}/x]$. On the second case, we can take $P = \lambda x.Rx$, where,
      $R \rhd R'$. By induction, $(R'x) \rhd (Rx)^{\ast}$ and now we apply the substitution lemma
      to have $R'N' = (R'x)[N'/x] \rhd (Rx)^{\ast}[N^{\ast}/x]$.

  * Congruence. Given $N \rhd N'$; by induction $N' \rhd N^{\ast}$, and depending on the form of
    $N$ we have two cases

    - $N$ is not of the form $Px$ where $x \not\in \mathrm{FV}(P)$; we can apply congruence to 
      \lambda-abstraction.

    - $N = Px$ where $x \notin \mathrm{FV}(P)$; and $N \rhd N'$ could be derived by parallel application
      or parallel substitution. On the first case, given $P \rhd P'$, we know that $P' \rhd P^{\ast}$
      by induction hypothesis and $\lambda x.P'x \rhd P^{\ast}$ by extensionality. On the second case,
      $N = (\lambda y.Q)x$ and $N' = Q'[x/y]$, where $Q \rhd Q'$. Hence $P \rhd \lambda y.Q'$, and by
      induction hypothesis, $\lambda y.Q' \rhd P^{\ast}$.

  * Parallel substitution, with $N \rhd N'$ and $Q \rhd Q'$; we know that $M^{\ast} = Q^{\ast}[N^{\ast}/x]$
    and we can apply the substitution lemma (lemma [[lemma-subsl]]) to get $M' \rhd M^{\ast}$.

  * Extensionality. We know that $P \rhd P'$ and $x \notin \mathrm{FV}(P)$. By induction hypothesis,
    we have $P' \rhd P^{\ast} = M^{\ast}$.$\qedhere$
#+end_proof

**** Church-Rosser theorem                                                               :ignore:
#+attr_latex: :options [Church-Rosser Theorem]
#+begin_theorem
<<theorem-churchrosser>>
The relation $\tto_{\beta\eta}$ is confluent.
#+end_theorem
#+begin_proof
/(Tait, Martin-Löf)/. Parallel reduction, $\rhd$, satisfies the diamond property (Lemma [[lemma-paralleldiamond]]), 
which implies the Church-Rosser property. Its reflexive transitive closure is $\tto_{\beta\eta}$
(Lemma [[lemma-transclosureparallel]]),
whose diamond property implies confluence for $\to_{\beta\eta}$.
#+end_proof

*** Normalization
Once the Church-Rosser theorem is proved, we can formally define the
notion of a normal form as a completely reduced lambda term.

#+begin_definition
A \lambda-term is said to be in *\beta-normal form* if \beta-reduction
cannot be applied to it or any of its subformulas. We define /\eta-normal forms/
and /\beta\eta-normal forms/ analogously.
#+end_definition

Fully evaluating \lambda-terms means to iteratively apply reductions to
them until a normal form is reached. We know, by virtue of Theorem
[[theorem-churchrosser]], that if a normal form for a particular term
exists, then it is unique; but we do not know whether a normal form
actually exists. We say that a term /has a normal form/ if it can be
reduced to a normal form.

#+begin_definition
A term is /weakly normalizing/ if there exists a sequence of
reductions from it to a normal form. A term is /strongly normalizing/
if every possible sequence of reductions is finite.
#+end_definition

A consequence of Theorem [[theorem-churchrosser]] is that a weakly normalizing
term has a unique normal form. Strong normalization implies weak normalization,
but the converse is not true; as an example, the term $\Omega = (\lambda x.(x x))(\lambda x.(x x))$
is neither weakly nor strongly normalizing; and the term
$(\lambda x.\lambda y.y)\ \Omega\ (\lambda x.x)$
is weakly but not strongly normalizing. It can be reduced to a normal form as
\[
(\lambda x.\lambda y.y)\ \Omega\ (\lambda x.x) \longrightarrow_{\beta} (\lambda x.x).
\]

*** Standarization and evaluation strategies
# Barendregt, 1985, section 13.2

**** Motivation                                                                          :ignore:
# Leftmost vs Rightmost evaluation
# Leftmost does always normalize if it is possible
# Rightmost only normalizes if it is necessary

# https://cs.stackexchange.com/questions/7702/applicative-order-and-normal-order-in-lambda-calculus
# This case illustrates a more general phenomenon: applicative order
# reduction only ever finds a normal form if the term is strongly
# normalizing, whereas normal order reduction always finds the normal
# form if there is one. This happens because applicative order always
# evaluates fully arguments first, and so misses the opportunity for
# an argument to turn out to be unused; whereas normal order evaluates
# arguments as late as possible, and so always wins if the argument
# turns out to be unused.

# Statement: http://www.nyu.edu/projects/barker/Lambda/barendregt.94.pdf
# Barendregt (1984) Theorem 13.2.2
We would like to find a \beta-reduction strategy such that, if a term
has a normal form, it can be found by following that strategy. Our
basic result will be the *standarization theorem*, which shows that,
if a \beta-reduction to a normal form exists, then a sequence of
\beta-reductions from left to right on the \lambda-expression will be
able to find it. From this result, we will be able to prove that the
reduction strategy that always reduces the leftmost \beta-abstraction
will always find a normal form if it exists.
This section follows cite:kashima00, cite:barendsen94 and cite:barendregt84.

**** Leftmost one-step reduction                                  :ignore:
#+begin_definition
Any two lambda terms $M$ and $N$ are related by $\to_n$, and we write
this as $M \to_{n} N$, when $N$ can be obtained by \beta-reducing
the $n\text{-th}$ leftmost \beta-reducible application in the lambda term $M$.
We call $\to_{1}$ the *leftmost one-step reduction* and we write it as $\to_{l}$;
accordingly, $\tto_{l}$ is its reflexive transitive closure.
#+end_definition

**** Standard sequence                                            :ignore:
#+attr_latex: :options [Standard sequence]
#+begin_definition
Let $M_0,M_1,\dots,M_k$ be a sequence of lambda terms.
A sequence of reductions $M_0 \to_{n_1} M_1 \to_{n_2} M_2 \to_{n_3} \dots \to_{n_k} M_{k}$ 
is *standard* if $n_0 \leq n_1 \leq \dots \leq n_k$, that is, $\left\{ n_i \right\}$ is a non-decreasing sequence.
#+end_definition

We will prove that every term that can be reduced to a normal form can
be reduced to it using a standard sequence. This will imply the
existence of an optimal beta reduction strategy that will always reach
a normal form if one exists.

**** Standarization theorem                                       :ignore:
#+attr_latex: :options [Standarization theorem]
#+begin_theorem
<<thm-standarization>>
If $M \tto_{\beta} N$, there exists a standard sequence from $M$ to $N$.
#+end_theorem
#+begin_proof
/(Kashima, 2000)/
We start by defining the following two binary relations. The first one
is the minimal reflexive transitive relation on \lambda-terms
capturing a form of \beta-reduction called /head \beta-reduction/;
that is, it is the minimal relation $\tto_h$ such that

  * $A \tto_h A$,
  * $(\lambda x.A_0)A_1A_2 \dots A_m \tto_{h} A_0[A_1/x]A_2 \dots A_m$, for any term of the form $A_1A_2\dots A_n$, and
  * $A \tto_{h} C$ for any terms $A,B,C$ such that $A \tto_{h} B \tto_{h} C$.

The second one is called /standard reduction/. It is the minimal relation
between \lambda-terms such that

  * $M \tto_h x$ implies $M \tto_s x$, for any variable $x$,
  * $M \tto_h AB$, $A \tto_s C$ and $B \tto_s D$, imply $M \tto_s CD$,
  * $M \tto_h \lambda x.A$ and $A \tto_s B$ imply $M \to_s \lambda x.B$.

We can check the following trivial properties by structural induction

  1) $\tto_h$ implies $\tto_{l}$,
  2) $\tto_{s}$ implies the existence of a standard \beta-reduction,
  3) $\tto_{s}$ is reflexive, by induction on the structure of a term,
  4) if $M \tto_{h} N$, then $MP \tto_{h} NP$,
  5) if $M \tto_h N \tto_s P$, then $M \tto_{s} P$,
  6) if $M \tto_h N$, then $M[P/x] \tto_h N[P/x]$,
  7) if $M \tto_s N$ and $P \tto_s Q$, then $M[P/z] \tto_{s} N[Q/z]$.

Now we can prove that, given any lambda term $K$, the relation $K \tto_{s} (\lambda x.M)N$ implies $K \tto_s M[N/x]$.
From the fact that $K \tto_s (\lambda x.M)N$, we know that there must exist $P$ and $Q$ such
that $K \tto_h PQ$, $P \tto_s \lambda x.M$ and $Q \tto_s N$; and from $P \tto_s \lambda x.M$, we know
that there exists $W$ such that $P \tto_h \lambda x.W$ and $W \tto_s M$. From all this information,
we can conclude that
\[
K \tto_h PQ \tto_{h} (\lambda x.W)Q \tto W[Q/x] \tto_s M[N/x];
\]
which, by the third clause (3.), implies $K \tto_s M[N/x]$.

We finally prove that, if $K \tto_s M \to_{\beta} N$, then $K \tto_s N$. This proves the theorem,
as every \beta-reduction $M \tto_s M \tto_\beta N$ implies $M \tto_s N$. We analize the possible
ways in which $M \to_{\beta} N$ can be derived.

  1) If $K \tto_{s} (\lambda x.M)N \to_{\beta} M[N/x]$, it has been
     already showed that $K \tto_s M[N/x]$.
  2) If $K \tto_s MN \to_{\beta} M'N$ with $M \to_{\beta} M'$, we know that there exist $K \tto_h WQ$ 
     such that $W \tto_s M$ and $Q \tto_s N$; by induction $W \tto_s M'$, and then $WQ \tto_s M'N$.
     The case $K \tto_s MN \to_{\beta} MN'$ is entirely analogous.
  3) If $K \tto_s \lambda x.M \to_{\beta} \lambda x.M'$, with $M \to_{\beta} M'$, we know that there exists $W$ such
     that $K \tto_h \lambda x.W$ and $W \tto_s M$. By induction $W \tto_s M'$, and $K \tto_s \lambda x.M'$.$\qedhere$
#+end_proof

**** Leftmost reduction theorem                                                          :ignore:
#+attr_latex: :options [Leftmost reduction theorem]
#+begin_corollary
<<cor-leftmosttheorem>>
We define the *leftmost reduction strategy* as the strategy that
reduces the leftmost \beta-reducible application at each step.
If $M$ has a normal form, the leftmost reduction strategy will lead
to it.
#+end_corollary
#+begin_proof
Note that, if $M \to_n N$, where $N$ is in \beta-normal form; $n$ must be exactly
$1$. If $M$ has a normal form and $M \tto_{\beta} N$, by Theorem [[thm-standarization]],
there must exist a standard sequence from $M$ to $N$ whose last step is of the
form $\to_{l}$; as the sequence is non-decreasing, every step has to be of the form $\to_{l}$.
#+end_proof

*** SKI combinators
**** SKI definition                                               :ignore:
As we have seen in previous sections, untyped \lambda-calculus is already
a very syntactically simple system; but it can be further reduced to
a few \lambda-terms without losing its expressiveness. In particular, untyped
\lambda-calculus can be /essentially/ recovered from only two of its terms;
these are

 * $S = \lambda x.\lambda y.\lambda z. xz(yz)$, and
 * $K = \lambda x.\lambda y.x$.

A language can be defined with these combinators and function
application. Every \lambda-term can be translated to this language and recovered up
to $=_{\beta\eta}$ equivalence. For example, the identity \lambda-term, $I$, can be written as
$I = \lambda x.x = SKK$.

It is common to also add the $I = \lambda x.x$ as a basic term to this language,
even if it can be written in terms of $S$ and $K$, as a
way to ease the writing of long complex terms. Terms written with
these combinators are called */SKI-terms/*.

The language of *SKI-terms* can be defined by the Backus-Naus form
\[
\mathsf{SKI} ::= x \mid (\mathsf{SKI}\ \mathsf{SKI}) \mid S \mid K \mid I,
\]
where $x$ can represent any free variable.

**** Lambda transform                                             :ignore:
#+begin_definition
The *Lambda-transform* of a SKI-term is a \lambda-term defined
recursively as

  * $\lambdatrans(x) = x$, for any variable $x$;
  * $\lambdatrans(I) = (\lambda x.x)$;
  * $\lambdatrans(K) = (\lambda x.\lambda y.x)$;
  * $\lambdatrans(S) = (\lambda x.\lambda y.\lambda z.xz(yz))$;
  * $\lambdatrans(XY) = \lambdatrans(X)\lambdatrans(Y)$, where $X$ and $Y$ are any two SKI-terms.
#+end_definition

**** Bracket abstraction                                          :ignore:
#+begin_definition
Before translating back lambda terms to SKI combinators, we need the
auxiliary notion of bracket abstraction. The *bracket abstraction* of
the SKI-term $W$ on the variable $x$ is written as $[x].W$ and defined
recursively as

  * $[x].x = I$;
  * $[x].U = KU$, if $x \notin \freevars(U)$;
  * $[x].Vx = V$, if $V$ is a term such that $x \notin \freevars(V)$;
  * $[x].VV' = S([x].V)([x].V')$, otherwise.

where $\freevars$ is the set of free variables as in Definition
[[def-freevariables]].
#+end_definition

**** SKI abstraction                                              :ignore:
#+attr_latex: :options [SKI abstraction]
#+begin_definition
The *SKI abstraction* of a \lambda-term $P$, written as $\skiabs(P)$ is
defined recursively as

  * $\skiabs(x) = x$, for any variable $x$;
  * $\skiabs(MN) = \skiabs(M)\skiabs(N)$;
  * $\skiabs(\lambda x.M) = [x].\skiabs(M)$;

where $[x].U$ is the bracket abstraction of the SKI-term $U$.
#+end_definition

#+attr_latex: :options [SKI combinators and lambda terms]
#+begin_theorem
The SKI-abstraction is a retraction of the Lambda-transform of the term,
that is, for any SKI-term $U$, we have that $\skiabs(\lambdatrans(U)) = U$.
#+end_theorem
#+begin_proof
By structural induction on $U$,

  * $\skiabs\lambdatrans(x) = x$, for any variable $x$;
  * $\skiabs\lambdatrans(I) = [x].x = I$;
  * $\skiabs\lambdatrans(K) = [x].[y].x = [x].Kx = K$;
  * $\skiabs\lambdatrans(S) = [x].[y].[z].xz(yz) = [x].[y].Sxy = S$; and
  * $\skiabs\lambdatrans(MN) = MN$.$\qedhere$
#+end_proof

In general this translation is not an isomorphism. For instance,
$\lambdatrans(\skiabs(\lambda u. v u)) = \lambdatrans(v) = v$.
However, the \lambda-terms can be essentially recovered if we relax equality
between \lambda-terms to mean $=_{\beta\eta}$.
# This problem could be addressed by using a relaxed form of
# equality containing \eta-equivalence, see cite:Hindley08 for details.

#+ATTR_LATEX: :options [Recovering lambda terms from SKI combinators]
#+BEGIN_theorem
For any \lambda-term $M$,
\[
\lambdatrans(\skiabs(M)) =_{\beta\eta} M.
\]
#+END_theorem
#+BEGIN_proof
We can firstly prove by structural induction that $\lambdatrans([x].M) = \lambda x.\lambdatrans(M)$
for any $M$. In fact, we know that $\lambdatrans([x].x) = \lambda x.x$ for any 
variable $x$; we also know that
\[\begin{aligned}
\lambdatrans([x].MN) &= \lambdatrans(S([x].M)([x].N)) \\
          &= (\lambda x.\lambda y.\lambda z. xz(yz))(\lambda x.\lambdatrans(M))(\lambda x.\lambdatrans(N)) \\
          &= \lambda z.\lambdatrans(M)\lambdatrans(N);
\end{aligned}\]
also, if $x$ is free in $M$, we know that
$\lambdatrans([x].M) = \lambdatrans(KM) = (\lambda x.\lambda y.x) \lambdatrans(M) =_{\beta} \lambda x.\lambdatrans(M);$
and finally, if $x$ is free in $U$, we have that
$\lambdatrans([x].Ux) = \lambdatrans(U) =_{\eta} \lambda x.\lambdatrans(U)x$.
Now we can use this result to prove the main theorem. Again by
structural induction,

 * $\lambdatrans\skiabs(x) = x$;
 * $\lambdatrans\skiabs(MN) = \lambdatrans\skiabs(M)\lambdatrans\skiabs(N) = MN$;
 * $\lambdatrans\skiabs(\lambda x.M) = \lambdatrans([x].\skiabs(M)) =_{\beta\eta} \lambda x.\lambdatrans\skiabs(M) = \lambda x.M$.$\qedhere$
#+END_proof

*** Turing completeness
# Turing, Church and Gödel.
# Papers by Turing, Church and Gödel.
# The lambda calculus as a reasonable machine. Ugo Dal Lago.

# https://en.wikipedia.org/wiki/Entscheidungsproblem

Three different notions of computability were proposed in the 1930s,

 * the *general recursive functions* were defined by Herbrand and Gödel;
   they form a class of functions over the natural numbers closed under
   composition, recursion and unbounded search;

 * the *\lambda-definable functions* were proposed by Church; they are
   functions on the natural numbers that can be represented by
   \lambda-terms;

 * the *Turing computable functions*, proposed by Alan Turing as the
   functions that can be computed using /Turing machines/, theoretical
   models of a machine.

In cite:church36 and cite:turing37, Church and Turing proved the equivalence of
the three definitions. This lead to the metatheoretical */Church-Turing thesis/*,
which postulated the equivalence between these models of computation and the
intuitive notion of /effective calculability/ mathematicians were using.
In practice, this means that the \lambda-calculus, as a programming language, is as
expressive as Turing machines; it can define every computable function.
It is Turing-complete.

# We will informally prove this equivalence: 
# a \lambda-calculus interpreter will be written in chapter ?, proving
# that \lambda-calculus is representable in a Turing machine
# equivalent, namely, our computer;
# general recursive functions will be implemented in \lambda-calculus
# in chapter ? proving that a Turing machine can be represented in it.
# interpreter and implementing general recursive functions on it.

A complete implementation of untyped \lambda-calculus is discussed in
Chapter [[Implementation of \lambda-expressions]]; and a detailed description on how to use the
untyped \lambda-calculus as a programming language is given in Chapter
[[Programming in untyped \lambda-calculus]]. General recursive functions,
for example, can be encoded using these techniques, thus proving that it
is in fact Turing complete (see [[sec-fixed-points]]).  Note that the lambda
calculus has even a cost model allowing us to develop complexity theory
within it (see cite:dallago08). It is however beyond the scope of this text.

# Church - An unsolvable problem of elementary number theory
# Corollary 1 pág 362.
# The set of well-formed formulas which have no normal form is not
# recursively enumerable.

** Simply typed \lambda-calculus
<<sec-simplytypedlambda>>
# TODO: The weak lambda calculus as a reasonable machine

**** Motivation                                                                          :ignore:
*/Types/* were introduced in mathematics as a response to the
Russell's paradox found in the first naive axiomatizations of set
theory (see Corollary [[cor-russellparadox]]). An attempt to use untyped \lambda-calculus
as a foundational logical system by Church suffered from a variant called the 
/Rosser-Kleene paradox/ and types were a method to avoid it, as
detailed in cite:kleene35 and cite:curry46.
Once types are added to the calculus, a deep connection between \lambda-calculus and
logic arises. This connection will be discussed in Section
[[sec-curryhoward]].

In programming languages, types indicate how the programmer intends to
use the data, prevent errors and enforce certain invariants and
levels of abstraction in programs. The role of types in
\lambda-calculus when interpreted as a programming language closely
matches the usual notion, and typed \lambda-calculus has been the basis of many modern
type systems for programming languages.

*Simply typed \lambda-calculus* is a refinement of the untyped
\lambda-calculus. On it, each term has a type that limits how it can
be combined with other terms. Only a set of basic types and function
types between any to types are considered in this system.  Whereas
functions in untyped \lambda-calculus can be applied over any term,
once we introduce types, a function of type $A \to B$ can only be applied over a term of
type $A$ to produce a new term of type $B$. Note that $A$ and $B$ can
be, themselves, function types.

We present now an account of simply typed \lambda-calculus based
on cite:Hindley08. Our description will rely only on the /arrow type constructor/
$\to$. While other presentations of simply typed
\lambda-calculus extend this definition with type constructors
providing pairs or union types, as it is done in cite:selinger13, it
is clearer to present first a minimal version of the
\lambda-calculus. Such extensions will be explained later, and its
exposition will profit from the logical interpretation that we
develop in Section [[Propositions as types]].

*** Simple types
We start by assuming a set of *basic types*. Those basic types would
correspond, in a programming language interpretation, with the
fundamental types of the language, such as the strings or the
integers. Minimal presentations of \lambda-calculus tend to use only
one basic type.

#+attr_latex: :options [Simple types]
#+begin_definition
The set of *simple types* is generated by the Backus-Naur form
$\mathsf{Type} ::= \iota \mid \mathsf{Type} \to \mathsf{Type}$,
where $\iota$ can be any /basic type/. That is to say that, for every two types $A,B$, there exists a
*function type* $A \to B$ between them.
#+end_definition

*** Typing rules for simply typed \lambda-calculus
**** Terms on simply typed lambda calculus                                               :ignore:
We define the terms of simply typed \lambda-calculus using
the same constructors we used on the untyped version. The set of 
*typed lambda terms* is given by the following Backus-Naus form.
\[\mathsf{Term} ::=
x \mid
\mathsf{Term}\ \mathsf{Term} \mid
\lambda x^{\mathsf{Type}}. \mathsf{Term}.
\]
The main difference here with Definition [[def-lambdaterms]] is 
that every bound variable has a type, and therefore, every \lambda-abstraction
of the form $(\lambda x^A. m)$ can be applied only over terms type $A$; if $m$ is of
type $B$, this term will be of type $A \to B$. 

However, the set of raw typed \lambda-terms contains some meaningless terms
under this type interpretation, such as $(\lambda x^A. m)(\lambda x^A. m)$.
In particular, we cannot apply a function of type $A \to B$ to
a term of type $A \to B$; as it can only be applied to a term of type $A$.
*Typing rules* will give terms this desired expressive power. Only a subset
of the raw lambda terms can be obtained using typing rules, and we will choose to work
only with this subset. When a particular term $m$ has type $A$, we write
this relation as $m : A$. The $:$ symbol should be read as /''is of type''/.

**** Typing rules                                                                        :ignore:
#+begin_definition
A *typing context* is a sequence of type assumptions
$\Gamma = (x_1:A_1,\dots,x_n:A_n)$, where no variable $x_{i}$ appears more than once.
We will implicitly assume that the order in which these
assumptions appear does not matter.
#+end_definition

Every typing rule assumes a typing context, usually denoted by $\Gamma$.
Concatenation of two typing contexts $\Gamma$ and $\Delta$ is written with a comma, as
in $\Gamma,\Delta$; and the fact that $\psi$ follows from $\Gamma$ is written as $\Gamma \vdash \psi$.
Typing rules are written as rules of inference; the premises are
listed above and the conclusion is written below the line.

 1) The $(var)$ rule simply makes explicit the type of a variable from
    the context. That is, a context that assumes that $x : A$ can
    be written as $\Gamma,x:A$; and we can trivially deduce from it that $x:A$.
    \begin{prooftree}
    \RightLabel{($var$)}
    \AXC{}
    \UIC{$\Gamma, x:A \vdash x:A$}
    \end{prooftree}

 2) The $(abs)$ rule declares that the type of a \lambda-abstraction is the type of
    functions from the variable type to the result type. If a term $m:B$ can
    be built from the assumption that $x:A$, then $\lambda x^{A}. m : A \to B$. It acts as
    an /introduction/ of function terms.
   \begin{prooftree}
   \RightLabel{$(abs)$}
   \AXC{$\Gamma, x:A \vdash m : B$}
   \UIC{$\Gamma \vdash \lambda x.m : A \to B$}
   \end{prooftree}

 3) The $(app)$ rule declares the type of a well-typed application.
    A term $f : A \to B$ applied to a term $a : A$ is a term
    $f\ a : B$. It acts as an /elimination/ of function terms.
    \begin{prooftree}
    \RightLabel{$(app)$}
    \AXC{$\Gamma \vdash f : A \to B$}
    \AXC{$\Gamma \vdash a : A$}
    \BIC{$\Gamma \vdash f\ a : B$}
    \end{prooftree}


A term $m$ is *typeable* in a giving context $\Gamma$ if a typing
judgment of the form $\Gamma \vdash m : T$ can be derived using only
the previous typing rules.
From now on, we only consider typeable terms as the terms of simply
typed \lambda-calculus: the set of \lambda-terms of simply typed
\lambda-calculus is only a subset of the terms of untyped
\lambda-calculus.

**** Examples of typeable and non-typeable terms                                         :ignore:
#+ATTR_LATEX: :options [Typeable and non-typeable terms]
#+BEGIN_exampleth
The term $\lambda f.\lambda x.f (f x)$ is typeable.
If we abbreviate $\Gamma = f:A \to A,\ x:A$, the detailed typing derivation
can be written as
\begin{prooftree}
\AX$\fCenter$
\RightLabel{$(var)$}
\UI$\Gamma\ \fCenter\vdash f : A \to A$
\AX$\fCenter$
\RightLabel{$(var)$}
\UI$\Gamma\ \fCenter\vdash x : A$
\AX$\fCenter$
\RightLabel{$(var)$}
\UI$\Gamma\ \fCenter\vdash f : A \to A$
\RightLabel{$(app)$}
\BI$\Gamma\ \fCenter\vdash f\ x : A$
\RightLabel{$(app)$}
\BI$f : A \to A, x : A\ \fCenter\vdash f (f x) : A$
\RightLabel{$(abs)$}
\UI$f : A \to A\ \fCenter\vdash \lambda x. f (f x) : A \to A$
\RightLabel{$(abs)$}
\UI$\fCenter\vdash \lambda f.\lambda x.f (f x) : (A \to A) \to A \to A$
\end{prooftree}
The term $(\lambda x.x\ x)$, however, is not typeable. If $x$ were of type $\psi$,
it also should be of type $\psi \to \sigma$ for some $\sigma$ in order for $x\ x$ to
be well-typed;
but $\psi \equiv \psi \to \sigma$ is not solvable, as it can be shown by structural
induction on the term $\psi$.
#+END_exampleth

It can be seen that the typing derivation of a term somehow encodes
the complete \lambda-term. If we were to derive the term bottom-up, there
would be only one possible choice at each step on which rule to use.
In Section [[Unification and type inference]] we will discuss a type inference algorithm
that determines if a type is typeable and what its type should be,
and we will make precise this intuition.

*** Curry-style types
<<sec-currystyle>>
**** Church-style and Curry-style                                                        :ignore:
Two different approaches to typing in \lambda-calculus are commonly used.

 * *Church-style* typing, also known as /explicit typing/, originated
   from the work of Alonzo Church in cite:church40, where he described
   a simply-typed lambda calculus with two basic types. The term's
   type is defined as an intrinsic property of the term; and the same
   term has to be always interpreted with the same type.

 * *Curry-style* typing, also known as /implicit typing/,
   creates a formalism where every single term can be given an
   infinite number of possible types.  This technique is called
   /polymorphism/ when it is a formal part of the language; but
   here, it is only used to allow us to build intermediate terms
   without having to directly specify their type.

As an example, we can consider the identity term $I = \lambda x.x$. It would have to be 
defined for each possible type. That is, we should consider a family of different 
identity terms $I_A = \lambda x.x : A \to A$ for each type $A$. Curry-style typing allows
us to consider type templates with type variables, and to type the identity as
$I = \lambda x.x : \sigma \to \sigma$ where $\sigma$ is a free type variable.
The difference between the two typing styles is then not a mere notational
convention, but a difference on the expressive power that we assign to each
term. 

\\

**** Type templates                                                                      :ignore:
Assuming an infinite numerable set of *type variables*, we define
*type templates* as inductively generated by
$\TypeTemp ::=  \iota \mid \mathsf{Tvar} \mid \TypeTemp \to \TypeTemp$,
where $\iota$ is a basic type and $\mathsf{TVar}$ is a type variable.
That is, all basic types and type variables are atomic type templates;
and we also consider the arrow type between two type templates. The
interesting property of type variables is that they can act as
placeholders and be substituted for other type templates.

**** Type substitution                                                                   :ignore:
#+begin_definition
A *type substitution* $\psi$ is any function from type variables to type templates. Any
type substitution $\psi$ can be extended to a function between type templates called $\overline{\psi}$
and defined inductively by

   * $\overline{\psi} \iota = \iota$, for any basic type $\iota$;
   * $\overline{\psi} \sigma = \psi \sigma$, for any type variable $\sigma$;
   * $\overline{\psi} (A \to B) = \overline{\psi} A \to \overline{\psi} B$, for any two type templates $A$ and $B$.

That is, the type template $\overline{\psi} A$ is the same as $A$ but with every type variable
replaced according to the substitution $\psi$.
#+end_definition

We consider a type to be /more general/ than other if the latter can be obtained by
applying a substitution to the former. In this case, the latter is called an /instance/
of the former. For example, $A \to B$ is more general than its instance
$(C \to D) \to B$, where $A$ has been substituted by $C \to D$. A
crucial property of simply typed \lambda-calculus is that every type has a most
general type, called its /principal type/; this is proved in Theorem [[thm-typeinfer]].

**** Principal type                                                                      :ignore:
#+attr_latex: :options [Principal type]
#+begin_definition
A closed \lambda-term $M$ has a *principal type* $\pi$ if $M : \pi$, and given any
typing judgment
$M : \tau$, we can obtain $\tau$ as an instance of $\pi$, that is, $\overline{\sigma} \pi = \tau$.
#+end_definition

*** Unification and type inference
**** Unification                                                                         :ignore:
The unification of two type templates is the construction of two substitutions
making them equal as type templates; that is, the construction of a type that
is a particular instance of both at the same time. We will not only aim for
an unifier but for the most general one between them, the universal one.

A substitution $\psi$ is called an *unifier* of two sequences of type templates
$A_1\dots,A_n$ and $B_1,\dots,B_n$ if $\overline{\psi} A_i = \overline{\psi} B_i$ for all $i = 1,\dots,n$. We say that it
is the *most general unifier* if given any other unifier $\phi$ exists a substitution
$\varphi$ such that $\phi = \overline{\varphi} \circ \psi$.

#+attr_latex: :options [Unification]
#+begin_lemma
<<lemma-unification>>
If an unifier of $\left\{ A_1,\dots,A_n \right\}$ and $\left\{ B_1,\dots,B_n \right\}$ exists, the most general unifier
is $\mathsf{unify}(A_1,\dots,A_n;B_1,\dots,B_n)$, which is partially defined by induction as follows,
where $x$ is any type variable.

  1) $\mathsf{unify}(x;x) = \id$ and $\mathsf{unify}(\iota,\iota) = \id$.
  2) $\mathsf{unify}(x;B) = (x \mapsto B)$, the substitution that only changes $x$ by $B$;
     if $x$ does not occur in $B$. The algorithm *fails* if $x$ occurs in $B$.
  3) $\mathsf{unify}(A;x)$ is defined symmetrically.
  4) $\mathsf{unify}(A \to A'; B \to B') = \mathsf{unify}(A,A';B,B')$.
  5) $\mathsf{unify}(A,A_1,\dots; B,B_1,\dots) = \overline{\psi} \circ \rho$ where $\rho = \mathsf{unify}(A_1,\dots;B_1,\dots)$ 
     and $\psi = \mathsf{unify}(\overline{\rho}A; \overline{\rho}B)$.
  6) $\mathsf{unify}$ fails in any other case.

Moreover, the two sequences of types, $A_1\dots,A_n$ and $B_1,\dots,B_n$, have no unifier
if and only if $\mathsf{unify}(A_1,\dots,A_n;B_1,\dots,B_n)$ fails.
#+end_lemma
#+begin_proof
It is easy to notice by structural induction that, if
$\mathsf{unify}(A;B)$ exists, it is in fact an unifier. If the unifier
fails in clause 2, there is obviously no possible unifier: the number
of constructors on the first type template will be always smaller than
the second one.  If the unifier fails in clause 6, the type templates
are fundamentally different, they have different head constructors and
this is invariant to substitutions. This proves that the failure of
the algorithm implies the non existence of an unifier.

We now prove that, if $A$ and $B$ can be unified, $\mathsf{unify}(A,B)$ is the most general unifier.
For instance, in the clause 2, if we call $\psi = (x \mapsto B)$ and, if $\eta$ were another unifier,
then $\eta x = \overline{\eta}x = \overline{\eta} B = \overline{\eta}(\psi(x))$; hence $\overline{\eta} \circ \psi = \eta$ by definition of $\psi$. A similar argument can 
be applied to clauses 3 and 4. In the clause 5, we suppose the existence of some unifier $\psi'$. 
The recursive call gives us the most general unifier $\rho$ of $A_1,\dots,A_n$ and $B_1,\dots,B_{n}$; and 
since it is more general than $\psi'$, there exists an $\alpha$ such that $\overline{\alpha} \circ \rho = \psi'$. Now,
$\overline{\alpha}(\overline{\rho}A) = \psi'(A) = \psi'(B) = \overline{\alpha}(\overline{\rho} B)$, hence $\alpha$ is a unifier of $\overline{\rho}A$ and $\overline{\rho}B$; we can take the 
most general unifier to be $\psi$, so $\overline{\beta} \circ \psi = \overline{\alpha}$; and finally, $\overline{\beta} \circ (\overline{\psi} \circ \rho) = \overline{\alpha} \circ \rho = \psi'$.

We also need to prove that the unification algorithm
terminates.  Firstly, we note that every substitution generated by the
algorithm is either the identity or it removes at least one type
variable. We can perform induction on the size of the argument on all
clauses except for clause 5, where a substitution is applied and the
number of type variables is reduced.  Therefore, we need to apply
induction both on the number of type variables and the size of the
arguments.
#+end_proof

**** Type Inference                                                                      :ignore:
Using unification, we can write an algorithm inferring types.

#+attr_latex: :options [Type inference]
#+begin_theorem
<<thm-typeinfer>>
The function $\mathsf{typeinfer}(M,B)$, partially defined as follows, finds the most
general substitution $\sigma$ such that $x_1 : \sigma A_1, \dots, x_n : \sigma A_n \vdash M : \overline{\sigma} B$ is a
valid typing judgment if it exists; and fails otherwise.

  1) $\mathsf{typeinfer}(x_i:A_i,\Gamma \vdash x_i : B) = \mathsf{unify}(A_i,B)$;
  2) $\mathsf{typeinfer}(\Gamma \vdash MN : B) = \overline{\varphi} \circ \psi$, where $\psi = \mathsf{typeinfer}(\Gamma \vdash M : X \to B)$ and
     $\varphi = \mathsf{typeinfer}(\overline{\psi}\Gamma \vdash N : \overline{\psi}X)$ for a fresh type variable $X$;
  3) $\mathsf{typeinfer}(\Gamma \vdash \lambda x.M : B) = \overline{\varphi} \circ \psi$ where $\psi = \mathsf{unify}(B; z \to z')$ and
     $\varphi = \mathsf{typeinfer}(\overline{\psi}\Gamma, x:\overline{\psi}z \vdash M : \overline{\psi}z')$ for fresh type variables $z,z'$.

Note that the existence of fresh type variables is always asserted by
the set of type variables being infinite. The output of this algorithm
is defined up to a permutation of type variables.
#+end_theorem
#+begin_proof
The algorithm terminates by induction on the size of $M$. It is easy
to check by structural induction that the inferred type judgments are
in fact valid.  If the algorithm fails, by Lemma [[lemma-unification]], it
is also clear that the type inference is not possible.

On the first case, the type is obviously the most general substitution
by virtue of the previous Lemma [[lemma-unification]].  On the second
case, if $\alpha$ were another possible substitution, in particular, it should
be less general than $\psi$, so $\alpha = \beta \circ \psi$. As $\beta$ would be then a possible substitution
making $\overline{\psi}\Gamma \vdash N : \overline{\psi}x$ valid, it should be less general than $\varphi$, so 
$\alpha = \overline{\beta} \circ \psi = \overline{\gamma} \circ \overline{\varphi} \circ \beta$.
On the third case, if $\alpha$ were another possible substitution, it should unify
$B$ to a function type, so $\alpha = \overline{\beta} \circ \psi$. Then $\beta$ should make the type inference
$\overline{\psi}\Gamma, x:\overline{\psi}z \vdash M : \overline{\psi}z'$ possible, so $\beta = \overline{\gamma} \circ \varphi$.
We have proved that the inferred type is in general the most general one.
#+end_proof

#+attr_latex: :options [Principal type property]
#+begin_corollary
Every typeable pure \lambda-term has a principal type.
#+end_corollary
#+begin_proof
Given a typeable term $M$, we can compute $\mathsf{typeinfer}(x_1:A_1,\dots,x_n:A_n \vdash M : B)$,
where $x_1,\dots,x_n$ are the free variables on $M$ and $A_1,\dots,A_n,B$ are fresh type
variables. By virtue of Theorem [[thm-typeinfer]], the result is the most general type of $M$
if we assume the variables to have the given types.
#+end_proof

*** Subject reduction and normalization
**** Subject reduction                                                                   :ignore:
A crucial property is that type inference and \beta-reductions do not
interfere with each other. A term can be \beta-reduced without changing
its type.

#+attr_latex: :options [Subject reduction]
#+begin_theorem
Types are preserved on \beta-reductions; that is, if $\Gamma \vdash M : A$ and
and $M \tto_{\beta} M'$, then $\Gamma \vdash M' : A$.
#+end_theorem
#+begin_proof
If $M'$ has been derived by \beta-reduction, $M = (\lambda x.P)$
and $M' = P[Q/x]$. $\Gamma \vdash M:A$ implies $\Gamma,x:B \vdash P : A$ and
$\Gamma \vdash Q : B$. Again by structural induction on $P$ (where the only crucial
case uses that $x$ and $Q$ have the same type) we can prove
that substitutions do not alter the type and thus, $\Gamma,Q:B \vdash P[Q/x] : A$.
#+end_proof

**** Reducibility                                                                        :ignore:
We have seen previously that the term $\Omega = (\lambda x.xx)(\lambda x.xx)$ is
not weakly normalizing; but it is also non-typeable. In this section
we will prove that, in fact, every typeable term is strongly normalizing.
We start proving some lemmas about the notion of /reducibility/, which
will lead us to the Strong Normalization Theorem. This proof will
follow cite:girard89.

The notion of */reducibility/* is an abstract concept originally
defined by Tait in cite:tait67 which we will use to ease this
proof. It should not be confused with the notion of \beta-reduction.
We inductively define the set $\redu_T$ of *reducible* terms of type $T$
for basic and arrow types.

 * If $t : T$ where $T$ is a basic type, $t \in \redu_{T}$ if $t$ is strongly
   normalizable.

 * If $t : U \to V$, an arrow type, $t \in \redu_{U \to V}$ if $t\ u \in \redu_{V}$ for all
   $u \in \redu_{U}$.

**** Properties of reducibility                                                          :ignore:
We prove three properties of reducibility at the same time in order
to use mutual induction.

#+ATTR_LATEX: :options [Properties of reducibility]
#+BEGIN_proposition
<<prop-reducibilityprop>>
The following three properties hold;

  1. if $t \in \redu_{T}$, then $t$ is strongly normalizable;
  2. if $t \in \redu_{T}$ and $t \to_{\beta} t'$, then $t' \in \redu_{T}$; and
  3. if $t$ is not a \lambda-abstraction and $t' \in \redu_{T}$ for every $t \to_{\beta} t'$,
     then $t \in \redu_{T}$.
#+END_proposition
#+BEGIN_proof
For basic types, 1. holds definitionally; 2. holds by the definition of
strong normalization; and 3. follows from the fact that if any
one-step \beta-reduction leads to a strongly normalizing term then the
term itself must be strongly normalizing.

For arrow types,

  1. if $x : U$ is a variable, we can inductively apply (3) to get $x \in \redu_{U}$;
     then, $t\ x \in \redu_{V}$ is strongly normalizing and $t$ in particular must be 
     strongly normalizing;

  2. if $t \to_{\beta} t'$ then for every $u \in \redu_{U}$, $t\ u \in \redu_{V}$ and $t\ u \to_{\beta} t'\ u$.
     By induction, $t'\ u \in \redu_{V}$;

  3. if $u \in \redu_{U}$, it is strongly normalizable. As $t$ is not a \lambda-abstraction,
     he term $t\ u$ can only be reduced to $t'\ u$ or $t\ u'$. If $t \to_{\beta} t'$; by induction, $t'\ u \in \redu_{V}$.
     If $u \to_{\beta} u'$, we could proceed by induction over the length of the longest
     chain of \beta-reductions starting from $u$ and assume that $t\ u'$ is irreducible.
     In every case, we have proved that $t\ u$ only reduces to already reducible terms;
     thus, $t\ u \in \redu_{U}$. \qedhere
#+END_proof

**** Abstraction lemma                                                                   :ignore:
#+ATTR_LATEX: :options [Abstraction lemma]
#+BEGIN_lemma
<<lemma-reductionabstraction>>
If $v[u/x] \in \redu_{V}$ for all $u \in \redu_{U}$, then $\lambda x.v \in \redu_{U \to V}_{}_{}$.
#+END_lemma
#+BEGIN_proof
We apply induction over the sum of the lengths of the longest
\beta-reduction sequences from $v[x/x]$ and $u$. The term $(\lambda x.v) u$ can be \beta-reduced to

  * $v[u/x] \in \redu_{U}$; in the base case of induction, this is the only choice;
  * $(\lambda x.v')u$ where $v \to_{\beta }v'$, and, by induction, $(\lambda x.v') u \in \redu_{V}$;
  * $(\lambda x.v)u'$ where $u \to_{\beta} u'$, and, again by induction, $(\lambda x.v) u' \in \redu_{V}$.

Thus, by Proposition [[prop-reducibilityprop]], $(\lambda x.v) \in \redu_{U \to V}$.
#+END_proof

**** Strong normalization lemma                                                          :ignore:
A final lemma is needed before the proof of the Strong Normalization
Theorem.  It is a generalization of the main theorem, useful because
of the stronger induction hypothesis it provides.

#+ATTR_LATEX: :options [Strong Normalization lemma]
#+BEGIN_lemma
<<lemma-strongnormalization>>
Given an arbitrary $t : T$ with free variables $x_{1} : U_{1}, \dots, x_{n} : U_{n}$, and reducible
terms $u_{1} \in \redu_{U_1}, \dots, u_{n} \in \redu_{U_{2}}$, we know that
\[
t[u_1 / x_1][u_2 / x_{2}]\dots[u_n / x_n] \in \redu_{T}.
\]
#+END_lemma
#+BEGIN_proof
We call $\tilde{t} = t[u_1 / x_1][u_2 / x_{2}]\dots[u_n / x_n]$ and apply structural induction over $t$,

  * if $t = x_i$, then we simply use that $u_i \in \redu_{U_i}$,

  * if $t = v\ w$, then we apply induction hypothesis to get $\tilde{v} \in \redu_{R \to T},\tilde{w} \in \redu_{R}$ 
    for some type $R$. Then, by definition, $\tilde{t} = \tilde{v}\ \tilde{w} \in \redu_T$,

  * if $t = \lambda y. v : R \to S$, then by induction $\tilde{v}[r/y] \in \redu_S$ for every $r : R$.
    We can then apply Lemma [[lemma-reductionabstraction]] to get that
    $\tilde{t} = \lambda y.\tilde{v} \in \redu_{R \to S}$.$\qedhere$
#+END_proof

#+attr_latex: :options [Strong Normalization Theorem]
#+begin_theorem
In simply typed \lambda-calculus, all terms are strongly normalizing.
#+end_theorem
#+BEGIN_proof
It is the particular case of Lemma [[lemma-strongnormalization]] where we
take $u_i = x_i$.
#+END_proof

**** Turing completeness of STLC                                                         :ignore:
# [[https://math.stackexchange.com/questions/1319149/what-breaks-the-turing-completeness-of-simply-typed-lambda-calculus][What breaks turing completeness of STLC]] (link)
Every term normalizes in simply typed \lambda-calculus and every
computation ends, therefore, simply typed \lambda-calculus must be not
Turing complete.
# !!!! Detail and check this proof

** The Curry-Howard correspondence
<<sec-curryhoward>>
# Tutorial on Curry-Howard http://purelytheoretical.com/papers/ATCHC.pdf
# Local soundness and completeness http://www.cs.cmu.edu/~fp/courses/15816-s10/lectures/01-judgments.pdf
# https://www.elsevier.com/books/lectures-on-the-curry-howard-isomorphism/sorensen/978-0-444-52077-7

*** Extending the simply typed \lambda-calculus
<<sec-extendingstlc>>
We will add now special syntax for some terms and types, such as
pairs, unions and unit types. This new syntax will make our
\lambda-calculus more expressive, but the unification and type
inference algorithms will continue to work in a similar way. The
previous proofs and algorithms can be extended to cover all the new
cases.

\\

**** Simple types II                                              :ignore:
The new set of *simple types* is given by the following BNF
\[\mathsf{Type} ::= \iota \mid 
\mathsf{Type} \to \mathsf{Type} \mid
\mathsf{Type} \times \mathsf{Type} \mid
\mathsf{Type} + \mathsf{Type} \mid
1 \mid
0,\]
where $\iota$ is any /basic type/.
That is to say that, for any given types $A,B$, there exists a product
type $A \times B$, consisting of the pairs of elements where the first
one is of type $A$ and the second one of type $B$; there exists the
union type $A + B$, consisting of a disjoint union of tagged terms
from $A$ or $B$; an unit type $1$ with only an element, and an empty
or void type $0$ without inhabitants.

\\

**** Raw typed lambda terms II                                    :ignore:
The new set of *typed lambda terms* is given by the BNF
\[\begin{aligned} 
\mathsf{Term} ::=\ &
x \mid
\mathsf{Term}\mathsf{Term} \mid
\lambda x. \mathsf{Term} \mid \\&
\left\langle \mathsf{Term},\mathsf{Term} \right\rangle \mid
\pi_1 \mathsf{Term} \mid
\pi_2 \mathsf{Term} \mid \\&
\textrm{inl}\ \mathsf{Term} \mid
\textrm{inr}\ \mathsf{Term} \mid
\textrm{case}\ \mathsf{Term}\ \textrm{of}\ \mathsf{Term}; \mathsf{Term} \mid \\&
\textrm{abort}\ \mathsf{Term} \mid \ast.
\end{aligned}\]

And the use of these new terms is formalized by the following extended
set of typing rules.

 1) The $(var)$ rule simply makes explicit the type of a variable from
    the context.
    \begin{prooftree}
    \LeftLabel{($var$)}
    \AXC{}
    \UIC{$\Gamma, \red{x}:\blue{A} \vdash \red{x}:\blue{A}$}
    \end{prooftree}

 2) The $(abs)$ and $(app)$ rules construct and apply function terms.
    \begin{prooftree}
    \LeftLabel{$(abs)$}
    \AXC{$\Gamma, \red{x}:\blue{A} \vdash \red{m} : \blue{B}$}
    \UIC{$\Gamma \vdash \red{\lambda x.m} : \blue{A \to B}$}
    \LeftLabel{$(app)$}
    \AXC{$\Gamma \vdash \red{f} : \blue{A \to B}$}
    \AXC{$\Gamma \vdash \red{a} : \blue{A}$}
    \BIC{$\Gamma \vdash \red{f\ a} : \blue{B}$}
    \noLine
    \BIC{}
    \end{prooftree}

 3) The $(pair)$ rule constructs pairs of elements. The $(\pi_1)$ and $(\pi_2)$ 
    rules destruct a pair into its projections.
    \begin{prooftree}
    \LeftLabel{$(pair)$}
    \AXC{$\Gamma \vdash \red{a} : \blue{A}$}
    \AXC{$\Gamma \vdash \red{b} : \blue{B}$}
    \BIC{$\Gamma \vdash \red{\pair{a,b}} : \blue{A \times B}$}
    \LeftLabel{$(\pi_1)$}
    \AXC{$\Gamma \vdash \red{m} : \blue{A \times B}$}
    \UIC{$\Gamma \vdash \red{\pi_1\ m} : \blue{A}$}
    \LeftLabel{$(\pi_2)$}
    \AXC{$\Gamma \vdash \red{m} : \blue{A \times B}$}
    \UIC{$\Gamma \vdash \red{\pi_2\ m} : \blue{B}$}
    \noLine
    \TIC{}
    \end{prooftree}

 4) The $(inl)$ and $(inr)$ rules provide the two ways of creating a tagged
    union type, while the $(case)$ rule extracts a term from a union type
    applying case analysis. Note that we write $[a].n$ and $[b].p$ to
    explicitly indicate that $n$ and $p$ can depend on $a$ and $b$, respectively.
    \begin{prooftree}
    \LeftLabel{$(inl)$}
    \AXC{$\Gamma \vdash \red{a} : \blue{A}$}
    \UIC{$\Gamma \vdash \red{\mathrm{inl}\ a} : \blue{A + B}$}
    \LeftLabel{$(inr)$}
    \AXC{$\Gamma \vdash \red{b} : \blue{B}$}
    \UIC{$\Gamma \vdash \red{\mathrm{inr}\ b} : \blue{A + B}$}
    \noLine
    \BIC{}
    \end{prooftree}
    \begin{prooftree}
    \LeftLabel{$(case)$}
    \AXC{$\Gamma \vdash \red{m} : \blue{A + B}$}
    \AXC{$\Gamma, \red{a}:\blue{A} \vdash \red{n} : \blue{C}$}
    \AXC{$\Gamma, \red{b}:\blue{B} \vdash \red{p} : \blue{C}$}
    \TIC{$\Gamma \vdash (\red{\mathrm{case}\ m\ \mathrm{of}\ [a].n;\ [b].p}) : \blue{C}$}
    \end{prooftree}
    
 5) The $(\ast)$ rule simply creates the only element of type $1$.
    \begin{prooftree}
    \LeftLabel{$(\ast)$}
    \AXC{$$}
    \UIC{$\Gamma \vdash \red{\ast} : \blue{1}$}
    \end{prooftree}

 6) The $(abort)$ rule extracts a term of any type from the void type.
    If we reach a void type, we have reached an error, and thus we
    can throw any typed exception.
    \begin{prooftree}
    \LeftLabel{$(abort)$}
    \AXC{$\Gamma \vdash \red{m} : \blue{0}$}
    \UIC{$\Gamma \vdash \red{\mathrm{abort}_A\ m} : \blue{A}$}
    \end{prooftree}

**** Beta-eta reductions in extended typed lambda calculus        :ignore:
The \beta-reduction of terms is defined the same way as for the untyped
\lambda-calculus; except for the inclusion of \beta-rules governing the
new terms, each for every new destruction rule.

  1) Function application, $(\lambda x.m)\ n \to_{\beta} m[n/x]$.
  2) First projection, $\pi_1 \left\langle m,n \right\rangle \to_{\beta} m$.
  3) Second projection, $\pi_2 \left\langle m,n \right\rangle \to_{\beta} n$.
  4) Case rule, $(\mathrm{case}\ m\ \mathrm{of}\ [x].n;\ [y].p) \to_{\beta} n[a/x]$ if $m$ is of the form
     $m = \mathrm{inl}\ a$; and $(\mathrm{case}\ m\ \mathrm{of}\ [x].n;\ [y].p) \to_{\beta} p[b/y]$ if $m$ is of the
     form $m = \mathrm{inr}\ b$.

On the other hand, new \eta-rules are defined, each for every new
construction rule.

  1) Function extensionality, $\lambda x.f\ x \to_{\eta} f$ for any $f : A \to B$.
  2) Definition of product, $\langle \pi_1\ m, \pi_{2}\ m \rangle \to_{\eta} m$ for any $m : A \times B$.
  3) Uniqueness of unit, $t \to_{\eta} \ast$ for any $t : 1$.
  4) Case rule, $(\mathrm{case}\ m\ \mathrm{of}\ [a].p[ \mathrm{inl}\ a/c ];\ [b].p[ \mathrm{inr}\ b/c ]) \to_{\eta} p[m/c]$
     for any $m : A + B$.

*** Natural deduction
<<sec-naturaldeduction>>
The natural deduction is a logical system due to Gentzen. We introduce
it here following cite:selinger13 and cite:wadler15. Its relationship
with the simply-typed lambda calculus will be made explicit in Section 
[[Propositions as types]].

\\

**** Rules of natural deduction                                   :ignore:
We use the logical binary connectives $\blue{\to},\blue{\land},\blue{\lor}$, and two unary
connectives, $\blue{\top}$ and $\blue{\bot}$, representing respectively the trivially true and false
propostions. The rules defining natural deduction come in
pairs; there are introductors and eliminators for every
connective. Every introductor uses a set of assumptions to generate a
formula and every eliminator gives a way to extract precisely that set
of assumptions.

 1) Every axiom on the context can be used.
    \begin{prooftree} 
    \RightLabel{(Ax)}
    \AXC{}  
    \UIC{$\Gamma,\blue{A} \vdash \blue{A}$}
    \end{prooftree}

 2) Introduction and elimination of the $\to$ connective. Note that the
    elimination rule corresponds to /modus ponens/ and the introduction
    rule corresponds to the /deduction theorem/.
    \begin{prooftree}
    \RightLabel{($I_{\to}$)}
    \AXC{$\Gamma, \blue{A} \vdash \blue{B}$}
    \UIC{$\Gamma \vdash \blue{A \to B}$}
    \RightLabel{($E_{\to}$)}
    \AXC{$\Gamma \vdash \blue{A \to B}$}
    \AXC{$\Gamma \vdash \blue{A}$}
    \BIC{$\Gamma \vdash \blue{B}$}
    \noLine
    \BIC{}
    \end{prooftree}

 3) Introduction and elimination of the $\land$ connective. Note that the
    introduction in this case takes two assumptions, and there are
    two different elimination rules.
    \begin{prooftree}
    \RightLabel{($I_{\land}$)}
    \AXC{$\Gamma \vdash \blue{A}$}
    \AXC{$\Gamma \vdash \blue{B}$}
    \BIC{$\Gamma \vdash \blue{A \land B}$}
    \RightLabel{($E_{\land}^1$)}
    \AXC{$\Gamma \vdash \blue{A \land B}$}
    \UIC{$\Gamma \vdash \blue{A}$}
    \RightLabel{($E_{\land}^2$)}
    \AXC{$\Gamma \vdash \blue{A \land B}$}
    \UIC{$\Gamma \vdash \blue{B}$}
    \noLine
    \TIC{}
    \end{prooftree}

 4) Introduction and elimination of the $\lor$ connective. Here, we need
    two introduction rules to match the two assumptions we use on the
    eliminator.
    \begin{prooftree}
    \RightLabel{($I_{\lor}^1$)}
    \AXC{$\Gamma \vdash \blue{A}$}
    \UIC{$\Gamma \vdash \blue{A \lor B}$}
    \RightLabel{($I_{\lor}^2$)}
    \AXC{$\Gamma \vdash \blue{B}$}
    \UIC{$\Gamma \vdash \blue{A \lor B}$}
    \RightLabel{($E_{\lor}$)}
    \AXC{$\Gamma \vdash \blue{A \lor B}$}
    \AXC{$\Gamma,\blue{A} \vdash \blue{C}$}
    \AXC{$\Gamma,\blue{B} \vdash \blue{C}$}
    \TIC{$\Gamma \vdash \blue{C}$}
    \noLine
    \TIC{}
    \end{prooftree}

 5) Introduction for $\top$. It needs no assumptions and, consequently,
    there is no elimination rule for it.
    \begin{prooftree}
    \RightLabel{($I_{\top}$)}
    \AXC{}
    \UIC{$\Gamma \vdash \blue{\top}$}
    \end{prooftree}

 6) Elimination for $\bot$. It can be eliminated in all generality, and,
    consequently, there are no introduction rules for it. This elimination
    rule represents the /"ex falsum quodlibet"/ principle that says that
    falsity implies anything.
    \begin{prooftree}
    \RightLabel{($E_{\bot}$)}
    \AXC{$\Gamma \vdash \blue{\bot}$}
    \UIC{$\Gamma \vdash \blue{C}$}
    \end{prooftree}

**** Deduction trees                                              :ignore:
Proofs on natural deduction are written as deduction trees, and they
can be simplified according to some simplification rules, which can
be applied anywhere on the deduction tree. On these rules, a chain
of dots represents any given part of the deduction tree.

  1) An implication and its antecedent can be simplified using the
     antecedent directly on the implication.
     #+latex: \\[-40pt]
     \begin{prooftree}
     \AXC{$[\blue{A}]$}\noLine
     \UIC{$\vdots^{1}$}\noLine
     \UIC{$\blue{B}$}
     \UIC{$\blue{A} \to \blue{B}$}
     \AXC{$\vdots^2$}\noLine
     \UIC{$\blue{A}$}
     \BIC{$\blue{B}$}
 
     \UIC{$\vdots$}\noLine
     \AXC{$\Longrightarrow$}
     \UIC{}\noLine\UIC{}\noLine\UIC{}\noLine
 
     \AXC{$\vdots^{2}$}\noLine
     \UIC{$\blue{A}$}\noLine
     \UIC{$\vdots^{1}$}\noLine
     \UIC{$\blue{B}$}
     \UIC{$\vdots$}\noLine
     \noLine
     \TIC{}
     \end{prooftree}

  2) The introduction of an unused conjunction can be simplified
     as
    \begin{prooftree}
    \AXC{$\vdots^{1}$}\noLine
    \UIC{$\blue{A}$}
    \AXC{$\vdots^{2}$}\noLine
    \UIC{$\blue{B}$}
    \BIC{$\blue{A} \land \blue{B}$}
    \UIC{$\blue{A}$}
    \UIC{$\vdots$}\noLine
    \AXC{$\Longrightarrow$}
    \UIC{}\noLine\UIC{}\noLine\UIC{}\noLine
    \AXC{$\vdots^{1}$}\noLine
    \UIC{$\blue{A}$}
    \UIC{$\vdots$}\noLine
    \noLine
    \TIC{}
    \end{prooftree}

    and, similarly, on the other side as
    \begin{prooftree}
    \AXC{$\vdots^{1}$}\noLine
    \UIC{$\blue{A}$}
    \AXC{$\vdots^{2}$}\noLine
    \UIC{$\blue{B}$}
    \BIC{$\blue{A} \land \blue{B}$}
    \UIC{$\blue{B}$}
    \UIC{$\vdots$}\noLine
    \AXC{$\Longrightarrow$}
    \UIC{}\noLine\UIC{}\noLine\UIC{}\noLine
    \AXC{$\vdots^{2}$}\noLine
    \UIC{$\blue{B}$}
    \UIC{$\vdots$}\noLine
    \noLine
    \TIC{}
    \end{prooftree}

  3) The introduction of a disjunction followed by its elimination can
     be also simplified
     #+latex: \\[-40pt]
     \begin{prooftree}
     \AXC{$\vdots^{1}$}\noLine
     \UIC{$\blue{A}$}
     \UIC{$\blue{A} \vee \blue{B}$}
     \AXC{$[\blue{A}]$}\noLine
     \UIC{$\vdots^2$}\noLine
     \UIC{$\blue{C}$}
     \AXC{$[\blue{B}]$}\noLine
     \UIC{$\vdots^3$}\noLine
     \UIC{$\blue{C}$}
     \TIC{$\blue{C}$}
 
     \UIC{$\vdots$}\noLine
     \AXC{$\Longrightarrow$}
     \UIC{}\noLine\UIC{}\noLine\UIC{}\noLine
 
     \AXC{$\vdots^{1}$}\noLine
     \UIC{$\blue{A}$}\noLine
     \UIC{$\vdots^{2}$}\noLine
     \UIC{$\blue{C}$}
     \UIC{$\vdots$}\noLine
     \noLine
     \TIC{}
     \end{prooftree}

     and a similar pattern is used on the other side of the disjunction
     #+latex: \\[-40pt]
     \begin{prooftree}
     \AXC{$\vdots^{1}$}\noLine
     \UIC{$\blue{B}$}
     \UIC{$\blue{A} \vee \blue{B}$}
     \AXC{$[\blue{A}]$}\noLine
     \UIC{$\vdots^2$}\noLine
     \UIC{$\blue{C}$}
     \AXC{$[\blue{B}]$}\noLine
     \UIC{$\vdots^3$}\noLine
     \UIC{$\blue{C}$}
     \TIC{$\blue{C}$}
 
     \UIC{$\vdots$}\noLine
     \AXC{$\Longrightarrow$}
     \UIC{}\noLine\UIC{}\noLine\UIC{}\noLine
 
     \AXC{$\vdots^{1}$}\noLine
     \UIC{$\blue{B}$}\noLine
     \UIC{$\vdots^{3}$}\noLine
     \UIC{$\blue{C}$}
     \UIC{$\vdots$}\noLine
     \noLine
     \TIC{}
     \end{prooftree}

*** Propositions as types
<<sec-propositionstypes>>
In 1934, Curry observed in cite:curry34 that the type of a function
$(\blue{A \to B})$ could be read as an implication and that the existence of a
function of that type was equivalent to the provability of the proposition.
Previously, the *Brouwer-Heyting-Kolmogorov interpretation* of intuitionistic
logic had given a definition of what it meant to be a proof of an intuinistic
formula, where a proof of the implication $(\blue{A \to B})$ was a function converting
a proof of $\blue{A}$ into a proof of $\blue{B}$. It was not until 1969 that Howard pointed
a deep correspondence between the simply-typed \lambda-calculus and the
natural deduction at three levels

  1. propositions are types;
  2. proofs are programs; and
  3. simplification of proofs is evaluation of programs.

In the case of simply typed \lambda-calculus and natural deduction,
the correspondence starts when we describe the following one-to-one
relation between types and propositions.

\begin{center}\begin{tabular}{c|c}
Types & Propositions \\
\hline
Unit type ($\blue{1}$) & Truth ($\blue{\top}$) \\
Product type ($\blue{\times}$) & Conjunction ($\blue{\land}$) \\
Union type ($\blue{+}$) & Disjunction ($\blue{\lor}$) \\
Function type ($\blue{\to}$) & Implication ($\blue{\to}$) \\
Empty type ($\blue{0}$) & False ($\blue{\bot}$) \\
\end{tabular}\end{center}

Where, in particular, the negation of a proposition $\blue{\neg A}$ is interpreted
as the fact that that proposition implies falsehood, $\blue{A \to \bot}$; and its
corresponding type is a function from the type $\blue{A}$ to the empty type, $\blue{A \to 0}$.

Now it is easy to notice that every deduction rule of Section [[Natural deduction]] 
has a correspondence with a typing rule of Section [[Extending the simply typed \lambda-calculus]].
The only distinction between them is the
appearance of \lambda-terms on the first set of rules. As every typing rule
results on the construction of a particular kind of \lambda-term, they can
be interpreted as encodings of proof in the form of derivation trees. That is,
terms are proofs of the propositions represented by their types.

#+ATTR_LATEX: :options [Curry-Howard correspondence example]
#+BEGIN_exampleth
In particular, the typing derivation of the term
\[
\red{\lambda a. \lambda b. \pair{a,b}}
\]
can be seen as a deduction tree proving $\blue{A \to B \to A \wedge B}$; as
the following diagram shows.
\begin{prooftree}
\EnableBpAbbreviations
\AXC{$\red{a} : \blue{A}$}
\AXC{$\red{b} : \blue{B}$}
\RightLabel{$(pair)$}
\BIC{$\red{\pair{a,b}} : \blue{A \times B}$}
\RightLabel{$(abs)$}
\UIC{$\red{\lambda b.\pair{a,b}} : \blue{B \to A \times B}$}
\RightLabel{$(abs)$}
\UIC{$\red{\lambda a.\lambda b.\pair{a,b}} : \blue{A \to B \to A \times B}$}
\end{prooftree}
# \begin{prooftree}
# \EnableBpAbbreviations
# \AXC{$\cterms{a }\ctypes{: A}$}
# \AXC{$\cterms{b }\ctypes{: B}$}
# \RightLabel{$(pair)$}
# \BIC{$\cterms{<a,b> }\ctypes{: A \times B}$}
# \RightLabel{$(abs)$}
# \UIC{$\cterms{λb.<a,b> }\ctypes{: B \to A \times B}$}
# \RightLabel{$(abs)$}
# \UIC{$\cterms{λa.λb.<a,b> }\ctypes{: A \to B \to A \times B}$}
# \end{prooftree}
#+END_exampleth

Furthermore, under this interpretation, 
*/simplification rules are precisely \beta-reduction rules/*.
This makes execution of \lambda-calculus
programs correspond to proof simplification on natural deduction.
The Curry-Howard correspondence is then not only a simple bijection
between types and propositions, but a deeper isomorphism regarding the
way they are constructed, used in derivations, and simplified.

#+attr_latex: :options [Curry-Howard simplification example]
#+begin_exampleth
As an example of this duality, we will write a proof/term of the proposition/type 
$\blue{A \to B + A}$ and we are going to simplify/compute it using proof simplification
rules/\beta-rules. Similar examples can be found in cite:wadler15.

We start with the following derivation tree;
#+latex: \\[-40pt]
\begin{prooftree}\EnableBpAbbreviations
\AXC{$\red{m } : \blue{ [A+B]}$}
\AXC{$\red{c } : \blue{ A}$}
\RightLabel{$(inr)$}
\UIC{$\red{\mathrm{inr}\ c} : \blue{ B+A}$}
\AXC{$\red{c } : \blue{ B}$}
\RightLabel{$(inl)$}
\UIC{$\red{\mathrm{inl}\ c } : \blue{ B+A}$}
\RightLabel{$(case)$}
\TIC{$\red{\mathrm{case}\ m\ \mathrm{of}\ [c].\mathrm{inr}\ c; [c].\mathrm{inl}\ c } : \blue{ B+A}$}
\RightLabel{$(abs)$}
\UIC{$\red{\lambda m.\mathrm{case}\ m\ \mathrm{of}\ [c].\mathrm{inr}\ c; [c].\mathrm{inl}\ c } : \blue{ A+B \to B+A}$}

\AXC{$\red{a } : \blue{ A}$}
\RightLabel{$(inl)$}
\UIC{$\red{\mathrm{inl}\ a } : \blue{ A+B}$}
\RightLabel{$(app)$}
\BIC{$\red{(\lambda m.\mathrm{case}\ m\ \mathrm{of}\ [c].\mathrm{inr}\ c; [c].\mathrm{inl}\ c)\ (\mathrm{inl}\ a) } : \blue{ B+A}$}
\RightLabel{$(abs)$}
\UIC{$\red{\lambda a.((\lambda m.\mathrm{case}\ m\ \mathrm{of}\ [c].\mathrm{inr}\ c; [c].\mathrm{inl}\ c)\ (\mathrm{inl}\ a)) } : \blue{ A \to B + A}$}
\end{prooftree}

which is encoded by the term $\red{\lambda a.(\lambda m.\mathrm{case}\ m\ \mathrm{of}\ [c].\mathrm{inr}\ c; [c].\mathrm{inl}\ c)\ (\lambda a.\mathrm{inl}\ a)}$.
We apply the simplification rule/\beta-rule of the implication/function application
to get
\begin{prooftree}\EnableBpAbbreviations
\AXC{$\red{z} : \blue{ A}$}
\RightLabel{$(inl)$}
\UIC{$\red{\mathrm{inl}\  z} : \blue{ A+B}$}
\AXC{$\red{a }: \blue{ A}$}
\RightLabel{$(inr)$}
\UIC{$\red{\mathrm{inr}\ a} : \blue{ B+A}$}
\AXC{$\red{b} : \blue{ B}$}
\RightLabel{$(inl)$}
\UIC{$\red{\mathrm{inl}\  b} : \blue{ B+A}$}
\RightLabel{$(case)$}
\TIC{$\red{\mathrm{case}\ (\mathrm{inl}\  z)\ \mathrm{of}\ [a].\mathrm{inr}\ a; [b].\mathrm{inl}\  b} : \blue{ B+A}$}
\RightLabel{$(abs)$}
\UIC{$\red{\lambda z.\mathrm{case}\ (\mathrm{inl}\  z)\ \mathrm{of}\ [a].\mathrm{inr}\ a; [b].\mathrm{inl}\  b} : \blue{ A \to B +A}$}
\end{prooftree}

which is encoded by the term $\red{\lambda z.\mathrm{case}\ (\mathrm{inl}\  z)\ \mathrm{of}\ [a].\mathrm{inr}\ a; [b].\mathrm{inl}\ b}$. We finally
apply the case simplification/reduction rule to get
\begin{prooftree}\EnableBpAbbreviations
\AXC{$\red{a } : \blue{ A}$}
\RightLabel{$(inr)$}
\UIC{$\red{\mathrm{inr}\ a } : \blue{ B+A}$}
\RightLabel{$(abs)$}
\UIC{$\red{\lambda a.\mathrm{inr}\ a} : \blue{ A \to B + A}$}
\end{prooftree}

which is encoded by $\red{\lambda a.\mathrm{inr}\ a}$.

On Chapter [[Implementation of \lambda-expressions]], we develop a \lambda-calculus interpreter
which is able to check and simplify proofs in intuitionistic logic.
This example could be checked and simplified by this interpreter as
it is shown at Figure [[mikrogentzen]].

#+caption: An example of the Curry-Howard correspondence in Mikrokosmos.
#+name: mikrogentzen
[[./images/mikrogentzen.png]]
#+end_exampleth

# Extending the Curry-Howard correspondence in other type systems
** Other type systems
*** \lambda-cube
The *\lambda-cube* is a taxonomy for Church-style type systems given
by Barendregt in cite:barendregt92. It describes eight type systems
based on the \lambda-calculus along three axes, representing three
properties of the systems.

  1) *Parametric polymorphism:* terms that depend on types. This is
     achieved via universal quantification over types. It allows type
     variables and binders for them. An example is the following parametric
     identity function where $\Lambda$ acts as a $\lambda$ for types, and $\tau$ is a
     type variable.
     \[
     \mathrm{id} \equiv \Lambda \tau . \lambda x . x : \forall \tau . \tau \to \tau, 
     \]
     It can be applied to any particular type $A$ to obtain the 
     specific identity function for that type as
     \[
     \mathrm{id}_{A} \equiv \lambda x.x : A \to A.
     \]

  2) *Type operators:* types that depend on types.  An example of type
     operator is $[-]$, which sends each type $A$ to the type $[A]$ of
     lists of elements of $A$. If we also assume polymorphism, a
     higher-order function mapping a function argument over a list
     would have the following type.
     \[ \mathrm{map} : \forall \tau. \forall \sigma. (\tau \to \sigma) \to [\tau] \to [\sigma] \]

  3) *Dependent types:* types that depend on terms.  An example is the
     type $\mathrm{Vect}(n)$ of vectors of a fixed length $n$, where $n$ is, itself,
     an element of a natural numbers type $n : \mathbb{N}$. The type of vectors
     of any length, $\mathrm{Vect}(0) + \mathrm{Vect}(1) + \mathrm{Vect}(2) + \dots$, is written as
     \[
     \sum_{n : \mathbb{N}} \mathrm{Vect}(n).
     \]
     Chapters [[Locally cartesian closed categories and dependent types]]
     and [[Martin-Löf type theory]] are devoted to the study of dependent
     types.
# Pierce
# Lectures on the Curry-Howard isomorphism
# Introduction to generalized type systems - Barendregt

# https://en.wikipedia.org/wiki/System_F#System_F.CF.89
The \lambda-cube is shown in the following figure.
\[\begin{tikzcd}[column sep=small]
&&& |[label={above:\lcubett{System F$\omega$}}]| \systemfo \ar{rr}
&&  |[label=above:\lcubett{CoC},label=above:\phantom{System Fo}]| \systemcoc 
& \\
\phantom{.}  
&&  |[label={left:\lcubett{System F}}]| \systemf \ar{ur}\ar{rr} 
&&  \systemfp \ar{ur}
&& \\ 
&&& \systemo \ar{rr}\ar{uu} 
&&  |[label=right:\lcubett{wCoC}]| \systemlpo \ar{uu}
&&  \phantom{\lambda}\phantom{PQW}  \\
\ar[\lcred]{uu}[\lcred]{\text{\parbox{2cm}{\centering terms depend on types}}}
&&  |[label=below:\lcubett{STLC}]| \stlc \ar{uu}\ar{rr}\ar{ur} 
&&  |[label=below:\lcubett{DTLC}]| \systemlp \ar{uu}\ar{ur} 
&& \phantom{.} \\ 
&&  \ar[\lcred]{rr}[swap,\lcred]{\text{\parbox{2cm}{\centering types depend on terms}}} 
&& \phantom{.} 
& \ar[\lcred]{ur}[swap,\lcred]{\text{\parbox{2cm}{\centering types depend on types}}} 
&
\end{tikzcd}\]

It presents the following type systems. Some of which are not commonly used,
but all of them are strongly normalizing.

 * *Simply typed \lambda-calculus* ($\stlc$); as described in Section
   [[Typing rules for simply typed \lambda-calculus]].
 * *Simply typed \lambda-calculus with operators* ($\systemo$).
 * *System F* ($\systemf$) and *System F-omega* ($\systemfo$) add polymorphism to the
   simply typed \lambda-calculus and type operators. The Haskell
   programming language is based on System F-omega with some restrictions.
 * *Dependently typed \lambda-calculus* ($\systemlp$); used 
   in the Edinburgh Logical Framework for logic programming
   (see cite:harper93).
 * *Calculus of constructions* ($\systemcoc$); where full mathematical theories
   can be developed (see cite:coquand88). It is used in the Coq Proof Assistant.
   
The \lambda-cube is generalized by the theory of pure type systems, described
in cite:barendregt92 and cite:geuvers93.

# https://cstheory.stackexchange.com/questions/7561/whats-the-relation-and-difference-between-calculus-of-inductive-constructions-a

*** TODO Hindley-Milner
*** TODO Gödel's System T
*** TODO System F                                                :noexport:
**** TODO System F is strongly normalizing
*** TODO Type algebra
# Type algebra should be studied, at least, on System F.
# Properties of type algebra can be proved in Agda.

**** Lists, trees and generating functions
**** Derivatives and one-hole contexts
**** Seven trees in one
*** TODO Pure type systems
In particular *System F* is equivalent to the single-sorted pure system $\lambda 2$.
# https://www.ps.uni-saarland.de/extras/fscd17/

*** TODO Subtyping (?)

*** TODO Inductive and coinductive definitions
* Mikrokosmos
** Implementation of \lambda-expressions
*** The Haskell programming language
**** Haskell as a programming choice                              :ignore:
*Haskell* is the purely functional programming language of our choice
to implement our \lambda-calculus interpreter. Its own design is
heavily influenced by the \lambda-calculus and it is a general-purpose
language with a rich ecosystem and plenty of consolidated
libraries[fn:hackagelibs] in areas such as parsing, testing or system
interaction; matching the requisites of our project. In the following
sections, we describe this ecosystem in more detail and justify our
choice.

[fn:hackagelibs]: A categorized list of libraries can be found in the
central package archive of the Haskell community:
https://hackage.haskell.org/packages/

**** History of Haskell                                           :ignore:
In the 1980s, many lazy programming languages were independently being
written by researchers such as /Miranda/, /Lazy ML/, /Orwell/, /Clean/
or /Daisy/. All of them were similar in expressive power, but their
differences were holding back the efforts to communicate ideas on
functional programming, so the *Haskell 98 Report* was a first standarized
reference of a common lazy functional language. A revised version
can be read in cite:haskell98. We will use its most standard implementation:
the *Glasgow Haskell Compiler (GHC)*; an open source compiler written in Haskell
and C. The complete history of Haskell and its design decisions is
detailed on cite:hudak07_haskell, but we are interested in the following
properties:

**** Haskell's properties                                                                :ignore:
Haskell is

 1. *strongly and statically typed*, meaning that it only compiles
    well-typed programs and it does not allow implicit type
    casting; type declarations are then useful in our interpreter
    to keep a track of what kind of data are we dealing with at
    each specific function;

 2. *lazy*, with /non-strict semantics/, meaning that it will not
    evaluate a term or the argument of a function until it is needed;
    this can help to solve the traditional efficiency problems on functional
    programming (see cite:hughes89);

 3. *purely functional*; as the evaluation order is demand-driven and
    not explicitly known, it is not possible to perform ordered
    input/output actions or any other side-effects that rely on the
    evaluation order; this helps modularity of our code, testing, and
    verfication;

 4. *referentially transparent*; as a consequence of its purity, every
    term on the code can be replaced by its definition without
    changing the global meaning of the program; this allows equational
    reasoning with rules that are directly derived from \lambda-calculus
    and makes it easier to reason about our functions;

 5. based on *System F\omega* with some restrictions; crucially, it
    implements *System F* adding quantification over type operators
    even if it does not allow abstraction on type operators; the GHC
    Haskell compiler, however, allows the user to activate extensions
    that implement dependent types.
    # https://stackoverflow.com/a/21220357/2552681

#+ATTR_LATEX: :options [A first example in Haskell]
#+BEGIN_exampleth
This example shows the basic syntax and how its type system and
its implicit laziness can be used.

#+BEGIN_SRC haskell
-- The type of the term can be declared.
id :: a -> a  -- Polymorphic type variables are allowed,
id x = x      -- and the function is defined equationally.
-- This definition performs short circuit evaluation thanks
-- to laziness. The unused argument can be omitted.
(&&) :: Bool -> Bool -> Bool
True  && x = x                -- (true and x) is always x
False && _ = False            -- (false and y) is always false
-- Laziness also allows infinite data structures.
nats :: [Integer]         -- List of all natural numbers,
nats = 1 : map (+1) nats  -- defined recursively.
#+END_SRC
#+END_exampleth

**** Haskell's syntax                                                                    :ignore:
Where most imperative languages use semicolons to separate sequential
commands, Haskell has no notion of sequencing, and programs are
written in a purely declarative way. A Haskell program essentially
consist on a series of definitions (of both types and terms) and type
declarations. The following example shows the definition of a binary
tree and its preorder.

#+BEGIN_SRC haskell
-- A tree is either empty or a node with two subtrees.
data Tree a = Empty | Node a (Tree a) (Tree a)
-- The preorder function takes a tree and returns a list
preorder :: Tree a -> [a]
preorder Empty            = []
preorder (Node x lft rgt) = preorder lft ++ [x] ++ preorder rgt
#+END_SRC

We can see on the previous example that function definitions allow
/pattern matching/, that is, data constructors can be used in
definitions to decompose values of the type. This increases
readability when working with algebraic data types or implementing
inductive definitions. Note that the majority of the definitions
we discussed in Sections [[sec-untypedlambda]] and [[sec-simplytypedlambda]]
are precisely structurally inductive.

While infix operators are allowed, function application is
left-associative in general.  Definitions using partial application
are allowed, meaning that functions on multiple arguments can use
currying and can be passed only one of its arguments to define a new
function.  For example, a function that squares every number on a list
could be written in two ways, as the following example shows.  The
second one, because of its simplicity, is usually preferred.

#+BEGIN_SRC haskell
squareList :: [Int] -> [Int]
squareList list = map square list
squareList' :: [Int] -> [Int]
squareList' = map square
#+END_SRC

**** Type classes, monads                                                                :ignore:
A characteristic piece of Haskell are *type classes*, which allow 
defining common interfaces for different types. In the following
example, we define =Monad= as the type class of types with suitably
typed =return= and =>>== operators.

#+BEGIN_SRC haskell
class Monad m where
  return :: a   -> m a
  (>>=)  :: m a -> (a -> m b) -> m b
#+END_SRC

And lists, for example, are monads in this sense.

#+BEGIN_SRC haskell
instance Monad [] where
  return x = [x]               -- returns a one-element list
  xs >>= f = concat (map f xs) -- map and concatenation
#+END_SRC

Monads are used in I/O, error propagation and stateful
computations. Another characteristical syntax bit of Haskell is the
=do= notation, which provides a nicer, cleaner way to concatenate
computations with monads that resembles an imperative language. The
following example uses the list monad to compute the list of
Pythagorean triples.

#+BEGIN_SRC haskell
pythagorean = do
  a <- [1..]               -- let a be any natural
  b <- [1..a]              -- let b be a natural between 1 and a
  c <- [1..b]              -- let c be a natural between 1 and b
  guard (a^2 == b^2 + c^2) -- filter the list
  return (a,b,c)           -- return matching tuples
#+END_SRC

Note that this list is infinite. As the language is lazy, this does not
represent a problem: the list will be evaluated only on demand.

Another common example of an instance of the =Monad= typeclass is the
/Maybe monad/ used to deal with error propagation. A =Maybe a= type can
consist of a term of type =a=, written as =Just a=; or as a =Nothing=
constant, signalling an error. The monad is then defined as

#+BEGIN_SRC haskell
instance Monad Maybe where
  return x = Just x
  xs >>= f = case xs of Nothing -> Nothing | Just a -> Just (f a)
#+END_SRC

and can be used as in the following example to use /exception-like/
error handling in a pure declarative language.

#+BEGIN_SRC haskell
roots :: (Float,Float,Float) -> Maybe Int
roots (a,b,c) = do
  -- Some errors can occur during this computation
  discriminant <- sqroot (b*b - 4*c*a)         -- roots of negative numbers?
  root1 <- safeDiv ((-b) + discriminant) (2*a) -- division by zero?
  root2 <- safeDiv ((-b) - discriminant) (2*a)
  -- The monad ensures that we return a number only if no error has been raised
  return (root1,root2)
#+END_SRC

A more detailed treatment of monads from the perspective of category
theory is presented in Section [[sec-monads]].
# [[http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.22.2636][CiteSeerX — Faking It: Simulating Dependent Types in Haskell]]

*** De Bruijn indexes
Nicolaas Govert *De Bruijn* proposed (see cite:debruijn81) a way of defining \lambda-terms modulo
\alpha-conversion based on indices.  The main goal of De Bruijn
indices is to remove all variables from binders and replace every
variable on the body of an expression with a number, called /index/,
representing the number of \lambda-abstractions in scope between the
ocurrence and its binder. Consider the following example where we draw
arrows between each term and its intermediate \lambda-abstractions: the \lambda-term
\[ \red{\lambda\tikzmark{2} y}.\ \tikzmark{3}y\ 
  (\blue{\lambda\tikzmark{1} z}.\ \tikzmark{0}y\ 
  \tikzmark{4}z) \begin{tikzpicture}[remember picture, overlay, bend right=45, -latex, redPRL]
  \draw ([yshift=2ex]pic cs:0) to ([yshift=2ex]pic cs:1);
  \draw ([yshift=2ex]pic cs:1) to ([yshift=2ex]pic cs:2);
  \draw ([yshift=2ex]pic cs:3) to ([yshift=2ex]pic cs:2);
  \end{tikzpicture} \begin{tikzpicture}[remember picture, overlay, bend left=45, -latex, bluePRL]
  \draw ([yshift=-1ex]pic cs:4) to ([yshift=-1ex]pic cs:1);
  \end{tikzpicture}
\]
can be written with de Bruijn indices as $\red{\lambda}\ (1\ \blue{\lambda}\ (2\ 1))$.
# Se podría explicar esto con colores y diagramas

De Bruijn also proposed a notation for the \lambda-calculus
changing the order of binders and \lambda-applications.  A review on
the syntax of this notation, its advantages and De Bruijn indexes, can be found in
cite:kamareddine01. In this section, we are going to describe De Bruijn
indexes while preserving the usual notation of \lambda-terms; that is, /De Bruijn/
/indexes/ and /De Bruijn notation/ are two different concepts and we are going to
use only the former one for clarity of exposition.

#+attr_latex: :options [De Bruijn indexed terms]
#+begin_definition
We define recursively the set of \lambda-terms using de Bruijn notation
as the terms generated from the following Backus normal form.
\[\begin{aligned}
\mathtt{Exp} &::= 
 \underbrace{\mathbb{N}}_{\textit{variable}}
 \mid
 \underbrace{(\lambda\ \mathtt{Exp})}_{\textit{abstraction}}
 \mid
 \underbrace{(\mathtt{Exp}\ \mathtt{Exp})}_{\textit{application}} \\
\mathbb{N} &::= 0 \mid 1 \mid 2 \mid \dots \\
\end{aligned}\]
#+end_definition

Our internal definition closely matches the formal one. The names of
the constructors are =Var=, =Lambda= and =App=, representing
variables, abstractions and applications, respectively.

#+BEGIN_SRC haskell
-- | A lambda expression using DeBruijn indexes.
data Exp = Var Integer -- ^ integer indexing the variable.
         | Lambda Exp  -- ^ lambda abstraction
         | App Exp Exp -- ^ function application
         deriving (Eq, Ord)
#+END_SRC

This notation avoids the need for the Barendregt's variable convention and
the \alpha-reductions. It will be useful to implement \lambda-calculus without
having to worry about the specific names of variables.

*** Substitution
We now implement the substition operation described in Section
[[sec-freeboundvars]], as it will be needed for \beta-reducing terms on
de Bruijn indices. In order to define the substitution of the n-th
variable by a \lambda-term $P$ on a given term, we must

 * find all the ocurrences of the variable. At each level of scope
   we are looking for the successor of the number we were looking
   for before;

 * decrease the higher variables to reflect the disappearance of
   a lambda;

 * replace the ocurrences of the variables by the new term, taking
   into account that free variables must be increased to avoid them
   getting captured by the outermost lambda terms. 

In our code, we can apply the function =subs= to any expression. When
it is applied to a \lambda-abstraction, the index and the free
variables of the replaced term are increased with an auxiliary
function called =incrementFreeVars=; whenever it is applied to a
variable, the previous cases are taken into consideration.

#+BEGIN_SRC haskell
-- | Substitutes an index for a lambda expression
subs :: Integer -> Exp -> Exp -> Exp
subs n p (Lambda e) = Lambda (subs (n+1) (incrementFreeVars 0 p) e)
subs n p (App f g)  = App (subs n p f) (subs n p g)
subs n p (Var m)
  | n == m    = p         -- The lambda is replaced directly  
  | n <  m    = Var (m-1) -- A more exterior lambda decreases a number
  | otherwise = Var m     -- An unrelated variable remains untouched
#+END_SRC

Now \beta-reduction can be defined using this =subs= function.

#+BEGIN_SRC haskell
betared :: Exp -> Exp
betared (App (Lambda e) x) = substitute 1 x e
betared e = e
#+END_SRC

*** De Bruijn-terms and \lambda-terms
The internal language of the interpreter uses de Bruijn expressions,
while the user interacts with it using lambda expressions with alphanumeric
variables. Our definition of a lambda expression with variables will be
used in parsing and output formatting.

#+BEGIN_SRC haskell
data NamedLambda = LambdaVariable String                    
                 | LambdaAbstraction String NamedLambda     
                 | LambdaApplication NamedLambda NamedLambda
#+END_SRC

**** Lambda to deBruijn                                           :ignore:
The translation from a natural lambda expression to De Bruijn notation
is done using a dictionary which keeps track of bounded variables.

#+BEGIN_SRC haskell
tobruijn :: Map.Map String Integer -- ^ names of the variables used
         -> Context                -- ^ names already binded on the scope
         -> NamedLambda            -- ^ initial expression
         -> Exp
-- Every lambda abstraction is inserted in the variable dictionary,
-- and every number in the dictionary increases to reflect we are entering
-- a deeper context.
tobruijn d context (LambdaAbstraction c e) = 
     Lambda $ tobruijn newdict context e
        where newdict = Map.insert c 1 (Map.map succ d)

-- Translation distributes over applications.
tobruijn d context (LambdaApplication f g) = 
     App (tobruijn d context f) (tobruijn d context g)

-- We look for every variable on the local dictionary and the current scope.
tobruijn d context (LambdaVariable c) =
  case Map.lookup c d of
    Just n  -> Var n
    Nothing -> fromMaybe (Var 0) (MultiBimap.lookupR c context)
#+END_SRC

**** deBruijn to Lambda                                           :ignore:
The translation from a de Bruijn expression to a natural one is done
considering an infinite list of possible variable names and keeping a list
of currently-on-scope variables to name the indices.

#+BEGIN_SRC haskell
-- | An infinite list of all possible variable names 
-- in lexicographical order.
variableNames :: [String]
variableNames = concatMap (`replicateM` ['a'..'z']) [1..]

-- | A function translating a deBruijn expression into a 
-- natural lambda expression.
nameIndexes :: [String] -> [String] -> Exp -> NamedLambda
nameIndexes _    _   (Var 0) = LambdaVariable "undefined"
nameIndexes used _   (Var n) = 
  LambdaVariable (used !! pred (fromInteger n))
nameIndexes used new (Lambda e) = 
  LambdaAbstraction (head new) (nameIndexes (head new:used) (tail new) e)
nameIndexes used new (App f g) = 
  LambdaApplication (nameIndexes used new f) (nameIndexes used new g)
#+END_SRC

*** Evaluation
As we proved on Corollary [[cor-leftmosttheorem]], the leftmost reduction
strategy will find the normal form of any given term provided that it
exists. Consequently, we will implement reduction in our interpreter
using a function that simply applies the leftmost possible reductions
at each step. As a side benefit, this will allow us to easily show how
the interpreter performs step-by-step evaluations to the final user
(see Section [[sec-verbose]]).

#+BEGIN_SRC haskell
-- | Simplifies the expression recursively.
-- Applies only one parallel beta reduction at each step.
simplify :: Exp -> Exp
simplify (Lambda e)           = Lambda (simplify e)
simplify (App (Lambda f) x)   = betared (App (Lambda f) x)
simplify (App (Var e) x)      = App (Var e) (simplify x)
simplify (App a b)            = App (simplify a) (simplify b)
simplify (Var e)              = Var e

-- | Applies repeated simplification to the expression until it stabilizes and
-- returns all the intermediate results.
simplifySteps :: Exp -> [Exp]
simplifySteps e
  | e == s    = [e]
  | otherwise = e : simplifySteps s
  where s = simplify e
#+END_SRC

From the code we can see that the evaluation finishes whenever the
expression stabilizes. This can happen in two different cases

  * there are no more possible \beta-reductions, and the algorithm
    stops; or

  * \beta-reductions do not change the expression. The computation
    would lead to an infinite loop, so it is immediately stopped.
    An common example of this is the \lambda-term
    $(\lambda x.x x)(\lambda x.x x)$.

*** Principal type inference
<<sec-typeinference>>
The interpreter implements the /unification/ and /type inference/ algorithms
described in Lemma [[lemma-unification]] and Theorem [[thm-typeinfer]]. Their
recursive nature makes them very easy to implement directly on Haskell.

**** Type templates and substitutions                             :ignore:
We implement a simply-typed lambda calculus with /Curry-style typing/
(see Section [[sec-currystyle]]) and type templates. Our type system has a
/unit/ type; a /void/ type; /product/ types; /union/ types; and
/function/ types.

#+BEGIN_SRC haskell
-- | A type template is a free type variable or an arrow between two
-- types; that is, the function type.
data Type = Tvar Variable
          | Arrow Type Type
          | Times Type Type
          | Union Type Type
          | Unitty
          | Bottom
          deriving (Eq)
#+END_SRC

We will work with substitutions on type templates. They can be directly
defined as functions from types to types. A basic substitution that
inserts a given type on the place of a variable will be our building
block for more complex ones.

#+BEGIN_SRC haskell
type Substitution = Type -> Type

-- | A basic substution. It changes a variable for a type
subs :: Variable -> Type -> Substitution
subs x typ (Tvar y)
  | x == y    = typ
  | otherwise = Tvar y
subs x typ (Arrow a b) = Arrow (subs x typ a) (subs x typ b)
subs x typ (Times a b) = Times (subs x typ a) (subs x typ b)
subs x typ (Union a b) = Union (subs x typ a) (subs x typ b)
subs _ _ Unitty = Unitty
subs _ _ Bottom = Bottom
#+END_SRC

**** Unification                                                  :ignore:
Unification will be implemented making extensive use of the =Maybe=
monad. If the unification fails, it will return an error value, and
the error will be propagated to the whole computation. The algorithm
is exactly the same that was defined in Lemma [[lemma-unification]].

#+BEGIN_SRC haskell
-- | Unifies two types with their most general unifier. Returns the substitution
-- that transforms any of the types into the unifier.
unify :: Type -> Type -> Maybe Substitution
unify (Tvar x) (Tvar y)
  | x == y    = Just id
  | otherwise = Just (subs x (Tvar y))
unify (Tvar x) b
  | occurs x b = Nothing
  | otherwise  = Just (subs x b)
unify a (Tvar y)
  | occurs y a = Nothing
  | otherwise  = Just (subs y a)
unify (Arrow a b) (Arrow c d) = unifypair (a,b) (c,d)
unify (Times a b) (Times c d) = unifypair (a,b) (c,d)
unify (Union a b) (Union c d) = unifypair (a,b) (c,d)
unify Unitty Unitty = Just id
unify Bottom Bottom = Just id
unify _ _ = Nothing

-- | Unifies a pair of types
unifypair :: (Type,Type) -> (Type,Type) -> Maybe Substitution
unifypair (a,b) (c,d) = do
  p <- unify b d
  q <- unify (p a) (p c)
  return (q . p)
#+END_SRC

**** Type inference                                               :ignore:
The type inference algorithm from Theorem [[thm-typeinfer]] is more involved.
It takes a list of fresh variables, a type context, a lambda expression and a
constraint on the type, expressed as a type template. It outputs
a substitution. As an example, the following code shows the type 
inference algorithm for function types.

#+BEGIN_SRC haskell
-- | Type inference algorithm. Infers a type from a given context and expression
-- with a set of constraints represented by a unifier type. The result type must
-- be unifiable with this given type.
typeinfer :: [Variable] -- ^ List of fresh variables
          -> Context    -- ^ Type context
          -> Exp        -- ^ Lambda expression whose type has to be inferred
          -> Type       -- ^ Constraint
          -> Maybe Substitution

typeinfer (x:vars) ctx (App p q) b = do -- Writing inside the Maybe monad.
  sigma <- typeinfer (evens vars) ctx                  p (Arrow (Tvar x) b)
  tau   <- typeinfer (odds  vars) (applyctx sigma ctx) q (sigma (Tvar x))
  return (tau . sigma)
#+END_SRC

The final form of the type inference algorithm will use a
normalization algorithm shortening the type names and will apply the
type inference to the empty type context.

**** Gentzen deduction trees                                      :ignore:
A generalized version of the type inference algorithm is used to
generate derivation trees from terms, as it was described in Section
[[sec-propositionstypes]]. In order to draw these diagrams in Unicode
characters, a data type for character blocks has been defined. A
monoidal structure is defined over them; blocks can be joined
vertically and horizontally; and every deduction step can be drawn
independently.

#+BEGIN_SRC haskell
newtype Block = Block { getBlock :: [String] }
  deriving (Eq, Ord)

instance Monoid Block where
  mappend = joinBlocks -- monoid operation, joins blocks vertically
  mempty  = Block [[]] -- neutral element

-- Type signatures
joinBlocks :: Block -> Block -> Block
stackBlocks :: String -> Block -> Block -> Block
textBlock :: String -> Block
deductionBlock :: Block -> String -> [Block] -> Block
box :: Block -> Block
#+END_SRC

** User interaction
*** Monadic parser combinators
The common approach to building parsers in functional programming is to
model parsers as functions. Higher-order functions on parsers act as
/combinators/, which are used to implement complex parsers in a
modular way from a set of primitive ones. In this setting, parsers
exhibit a monad algebraic structure, which can be used to simplify
the combination of parsers. A technical report on *monadic parser combinators*
can be found on cite:hutton96.

The use of monads for parsing was discussed for the first time in cite:Wadler85,
and later in cite:Wadler90 and cite:hutton98. The parser type is
defined as a function taking an input =String= and returning a list of pairs,
representing a successful parse each. The first component of the pair
is the parsed value and the second component is the remaining
input. The Haskell code for this definition is the following,
where the monadic structure is defined by =>>== and =return=.

#+BEGIN_SRC haskell
  -- A parser takes a string an returns a list of possible parsings with
  -- their remaining string.
  newtype Parser a = Parser (String -> [(a,String)])
  parse :: Parser a -> String -> [(a,String)]
  parse (Parser p) = p
  -- A parser can be composed monadically, the composed parser (p >>= q)
  -- applies q to every possible parsing of p. A trivial one is defined.
  instance Monad Parser where
    return x = Parser (\s -> [(x,s)]) -- Trivial parser, directly returns x.
    p >>= q  = Parser (\s -> concat [parse (q x) s' | (x,s') <- parse p s ])
#+END_SRC

Given a value, the =return= function creates a parser that consumes no input
and simply returns the given value. The =>>== function acts as a sequencing
operator for parsers; it takes two parsers and applies the second one
over the remaining inputs of the first one, using the parsed values on
the first parsing as arguments.

An example of primitive *parser* is the =item= parser, which consumes a
character from a non-empty string. It is written in Haskell code using
pattern matching on the string as follows.

#+BEGIN_SRC haskell
item :: Parser Char
item = Parser (\s -> case s of "" -> []; (c:s') -> [(c,s')])
#+END_SRC

An example of *parser combinator* is the =many= function, which
creates a parser that allows one or more applications of the given
parser. In the following example =many item= would be a parser
consuming all characters from the input string.

#+BEGIN_SRC haskell
many :: Paser a -> Parser [a]
many p = do
  a  <- p
  as <- many p
  return (a:as)
#+END_SRC

*Parsec* is a monadic parser combinator Haskell library described in
cite:leijen2001. We have chosen to use it due to its simplicity and
extensive documentation. As we expect to use it to parse user live
input, which will tend to be short, performance is not a critical
concern. A high-performace library supporting incremental parsing,
such as *Attoparsec* cite:attoparsec, would be suitable otherwise.

*** Verbose mode
<<sec-verbose>>
As we mentioned previously, the evaluation of lambda terms can be
analyzed step-by-step. The interpreter allows us to see the complete
evaluation when the /verbose mode/ is activated. To activate it, we
can execute =:verbose on= in the interpreter.  The difference can be
seen on the following example, which shows the execution of the
expression $1+2$, first without intermediate results, and later,
showing every intermediate step.

#+begin_src bash
mikro> plus 1 2
λa.λb.(a (a (a b))) ⇒ 3

mikro> :verbose on
verbose: on
mikro> plus 1 2
((plus 1) 2)
((λλλλ((4 2) ((3 2) 1)) λλ(2 1)) λλ(2 (2 1)))
(λλλ((λλ(2 1) 2) ((3 2) 1)) λλ(2 (2 1)))
λλ((λλ(2 1) 2) ((λλ(2 (2 1)) 2) 1))
λλ(λ(3 1) (λ(3 (3 1)) 1))
λλ(2 (λ(3 (3 1)) 1))
λλ(2 (2 (2 1)))
λa.λb.(a (a (a b))) ⇒ 3
#+end_src

The interpreter output can be colored to show specifically where it
is performing reductions. It is activated by default, but can be deactivated
by executing =:color off=. The following code implements /verbose mode/ in both
cases.

#+BEGIN_SRC haskell
-- | Shows an expression, coloring the next reduction if necessary
showReduction :: Exp -> String
showReduction (Lambda e) = "λ" ++ showReduction e
showReduction (App (Lambda f) x) = betaColor (App (Lambda f) x)
showReduction (Var e) = show e
showReduction (App rs x) = "("++showReduction rs++" "++showReduction x++")"
showReduction e = show e
#+END_SRC

*** SKI mode
Every \lambda-term can be written in terms of SKI combinators.
SKI combinator expressions can be defined as a binary tree having
variables, S, K, and I as possible leafs.

#+BEGIN_SRC haskell
data Ski = S | K | I | Comb Ski Ski | Cte String
#+END_SRC

The SKI-abstraction and bracket abstraction algorithms are implemented
on Mikrokosmos, and they can be used by activating the /ski mode/ with
=:ski on=. When this mode is activated, every result is written in terms
of SKI combinators.

#+begin_example
mikro> 2
λa.λb.(a (a b)) ⇒ S(S(KS)K)I ⇒ 2
mikro> and
λa.λb.((a b) a) ⇒ SSK ⇒ and
#+end_example

The code implementing these algorithms follows directly from the
theoretical version in cite:Hindley08.

#+BEGIN_SRC haskell
-- | Bracket abstraction of a SKI term, as defined in Hindley-Seldin
-- (2.18).
bracketabs :: String -> Ski -> Ski
bracketabs x (Cte y) = if x == y then I else Comb K (Cte y)
bracketabs x (Comb u (Cte y))
  | freein x u && x == y = u
  | freein x u           = Comb K (Comb u (Cte y))
  | otherwise            = Comb (Comb S (bracketabs x u)) (bracketabs x (Cte y))
bracketabs x (Comb u v)
  | freein x (Comb u v)  = Comb K (Comb u v)
  | otherwise            = Comb (Comb S (bracketabs x u)) (bracketabs x v)
bracketabs _ a           = Comb K a

-- | SKI abstraction of a named lambda term. From a lambda expression
-- creates a SKI equivalent expression. The following algorithm is a
-- version of the algorithm (9.10) on the Hindley-Seldin book.
skiabs :: NamedLambda -> Ski
skiabs (LambdaVariable x)      = Cte x
skiabs (LambdaApplication m n) = Comb (skiabs m) (skiabs n)
skiabs (LambdaAbstraction x m) = bracketabs x (skiabs m)
#+END_SRC

** Usage
*** Installation
The complete Mikrokosmos suite is divided in multiple parts:

 1) the *Mikrokosmos interpreter*, written in Haskell;
 2) the *Jupyter kernel*, written in Python;
 3) the *CodeMirror Lexer*, written in Javascript;
 4) the *Mikrokosmos libraries*, written in the Mikrokosmos language;
 5) the *Mikrokosmos-js* compilation, which can be used in web browsers.

These parts will be detailed on the following sections. A system that
already satisfies all dependencies (Stack, Pip and Jupyter), can install
Mikrokosmos using the following script, which is detailed on this section

#+BEGIN_SRC sh
stack install mikrokosmos                             # Mikrokosmos interpreter
sudo pip install imikrokosmos                  # Jupyter kernel for Mikrokosmos
git clone https://github.com/mroman42/mikrokosmos-lib.git ~/.mikrokosmos # Libs
#+END_SRC

**** Mikrokosmos interpreter :ignore:
The *Mikrokosmos interpreter* is listed in the central Haskell package
archive[fn:hackage]. The packaging of Mikrokosmos has been done using
the *cabal* tool; and the configuration of the package can be read in
the file =mikrokosmos.cabal= of the source code. As a result,
Mikrokosmos can be installed using the Haskell package managers
*cabal* and *stack*.

#+BEGIN_SRC sh
cabal install mikrokosmos          # Installation with cabal
stack install mikrokosmos          # Installation with stack
#+END_SRC

**** Mikrokosmos Jupyter kernel :ignore:
The *Mikrokosmos Jupyter kernel* is listed in the central Python
package archive[fn:pipmikro].  Jupyter is a dependency of this kernel, which only
can be used in conjunction with it. It can be installed with the
=pip= package manager.

#+BEGIN_SRC sh
sudo pip install imikrokosmos      # Installation with pip
#+END_SRC

The installation can be checked by listing the available Jupyter
kernels.

#+BEGIN_SRC sh
jupyter kernelspec list            # Checks installation
#+END_SRC

**** Mikrokosmos libraries :ignore:
The *Mikrokosmos libraries* can be downloaded directly from their GitHub
repository[fn:mikrokosmoslibgit]. They have to be placed under
=~/.mikrokosmos= if we want them to be locally available or under
=/usr/lib/mikrokosmos= if we want them to be globally available.

#+BEGIN_SRC sh
git clone https://github.com/mroman42/mikrokosmos-lib.git ~/.mikrokosmos
#+END_SRC

**** Complete script :ignore:
The following script installs the complete Mikrokosmos suite on a
fresh system. It has been tested under =Ubuntu 16.04.3 LTS (Xenial
Xerus)=.

# TODO: Usa virtualenv en vez de sudo -H pip

#+BEGIN_SRC sh
# 1. Installs Stack, the Haskell package manager
wget -qO- https://get.haskellstack.org | sh
STACK=$(which stack)

# 2. Installs the ncurses library, used by the console interface
sudo apt install libncurses5-dev libncursesw5-dev

# 3. Installs the Mikrokosmos interpreter using Stack
$STACK setup
$STACK install mikrokosmos

# 4. Installs the Mikrokosmos standard libraries
sudo apt install git
git clone https://github.com/mroman42/mikrokosmos-lib.git ~/.mikrokosmos

# 5. Installs the IMikrokosmos kernel for Jupyter
sudo apt install python3-pip
sudo -H pip install --upgrade pip
sudo -H pip install jupyter
sudo -H pip install imikrokosmos
#+END_SRC

[fn:pipmikro]: The Jupyter-Mikrokosmos package can be found in https://pypi.org/project/imikrokosmos/.
[fn:hackage]: Hackage can be accesed in http://hackage.haskell.org/
and the Mikrokosmos package can be found in https://hackage.haskell.org/package/mikrokosmos
[fn:mikrokosmoslibgit]: The repository can be accessed in: https://github.com/mroman42/mikrokosmos-lib.git

*** Mikrokosmos interpreter
Once installed, the Mikrokosmos \lambda interpreter can be opened from
the terminal with the =mikrokosmos= command. It will enter a /read-eval-print loop/
where \lambda-expressions and interpreter commands can be evaluated.

#+BEGIN_EXAMPLE
$> mikrokosmos
Welcome to the Mikrokosmos Lambda Interpreter!
Version 0.7.0. GNU General Public License Version 3.
mikro> _
#+END_EXAMPLE

The interpreter evaluates every line as a lambda expression. Examples
on the use of the interpreter can be read on the following
sections. Apart from the evaluation of expressions, the interpreter
accepts the following commands

  * =:quit= and =:restart=, stop the interpreter;
  * =:verbose= activates /verbose mode/;
  * =:ski= activates /SKI mode/;
  * =:types= changes between untyped and simply typed \lambda-calculus;
  * =:color= deactivates colored output;
  * =:load= loads a library.

Figure [[mikrosession]] is an example session on the Mikrokosmos interpreter.

#+caption: Mikrokosmos interpreter session.
#+name: mikrosession
[[./images/mikrosession.png]]

*** Jupyter kernel
The *Jupyter Project* cite:jupyter is an open source project providing
support for interactive scientific computing. Specifically, the
Jupyter Notebook provides a web application for creating interactive
documents with live code and visualizations. 

We have developed a Mikrokosmos kernel for the Jupyter Notebook,
allowing the user to write and execute arbitrary Mikrokosmos code
on this web application. An example session can be seen on Figure
[[jupytersession]].

#+caption: Jupyter notebook Mikrokosmos session.
#+name: jupytersession
[[./images/jupytersession.png]]

The implementation is based on the =pexpect= library for Python.  It
allows direct interaction with any REPL and collects its results.
Specifically, the following Python lines represent the central idea of
this implementation

#+BEGIN_SRC python
# Initialization
mikro = pexpect.spawn('mikrokosmos')
mikro.expect('mikro>')

# Interpreter interaction
# Multiple-line support
output = ""
for line in code.split('\n'):
    # Send code to mikrokosmos
    self.mikro.sendline(line)
    self.mikro.expect('mikro> ')

    # Receive and filter output from mikrokosmos
    partialoutput = self.mikro.before
    partialoutput = partialoutput.decode('utf8')
    output = output + partialoutput
#+END_SRC

A =pip= installable package has been created following the
Python Packaging Authority guidelines[fn:pypaguide]. This allows
the kernel to be installed directly using the =pip= python package manager.

#+BEGIN_SRC bash
sudo -H pip install imikrokosmos
#+END_SRC

[fn:pypaguide]: The PyPA packaging user guide can be found in its official
page: https://packaging.python.org/

*** CodeMirror lexer
*CodeMirror* [fn:codemirror] is a text editor for the browser
implemented in Javascript. It is used internally by the Jupyter
Notebook.

A CodeMirror lexer for Mikrokosmos has been written. It uses
Javascript regular expressions and signals the ocurrence of any kind
of operator to CodeMirror. It enables syntax highlighting for Mikrokosmos
code on Jupyter Notebooks. It comes bundled with the kernel specification
and no additional installation is required.

#+BEGIN_SRC javascript
	CodeMirror.defineSimpleMode("mikrokosmos", {
	    start: [
	    // Comments
	    {regex: /\#.*/,
            token: "comment"},
	    // Interpreter
            {regex: /\:load|\:verbose|\:ski|\:restart|\:types|\:color/,
            token: "atom"},
	    // Binding
	    {regex: /(.*?)(\s*)(=)(\s*)(.*?)$/,
	    token: ["def",null,"operator",null,"variable"]},
	    // Operators
	    {regex: /[=!]+/,
            token: "operator"},
	    ],
	    meta: {
		dontIndentStates: ["comment"],
		lineComment: "#"
	    }
	}
#+END_SRC

[fn:codemirror]: Documentation for CodeMirror can be found in its
official page: https://codemirror.net/

*** JupyterHub
*JupyterHub* manages multiple instances of independent single-user
Jupyter notebooks. It has been used to serve Mikrokosmos notebooks and
tutorials to students. In order to install Mikrokosmos on a server and
use it as =root= user, we perform the following steps.

  * Cloning the libraries into =/usr/lib/mikrokosmos=. They should be
    available system-wide.

  * Installing the Mikrokosmos interpreter into =/usr/local/bin=. In
    this case, we can choose not to install Mikrokosmos from source, but
    simply copy the binaries and check the availability of the
    =ncurses= library.

  * Installing the Mikrokosmos Jupyter kernel as usual.

A JupyterHub server was made available at =iemath1.ugr.es=.  Our
server used a SSL certificate and OAuth autentication via GitHub.
Mikrokosmos tutorials and exercises were installed for every student.

*** Calling Mikrokosmos from Javascript
The GHCjs[fn:ghcjs] compiler allows transpiling from Haskell to Javascript.
Its foreign function interface allows a Haskell function to be passed as
a continuation to a Javascript function.

A particular version of the =Main.hs= module of Mikrokosmos was
written in order to provide a =mikrokosmos= function, callable from
Javascript. This version includes the standard libraries automatically
and reads blocks of text as independent Mikrokosmos commands. The
relevant use of the foreign function interface is shown in the
following code, which provides =mikrokosmos= as a Javascript function
once the code is transpiled.

#+BEGIN_SRC haskell
foreign import javascript unsafe "mikrokosmos = $1"
    set_mikrokosmos :: Callback a -> IO ()
#+END_SRC

In particular, the following is an example of how to call
Mikrokosmos from Javascript.

#+BEGIN_SRC javascript
button.onclick = function () {
   editor.save();
   outputcode.getDoc().setValue(mikrokosmos(inputarea.value).mkroutput);
   textAreaAdjust(outputarea);
}
#+END_SRC

A small script has been written in Javascript to help with the task of
embedding Mikrokosmos into a web page. It and can be included directly
from the following direction, using GitHub as a CDN.

#+begin_center
https://mroman42.github.io/mikrokosmos-js/mikrobox.js
#+end_center

The script will convert any HTML script tag written as follows into a
CodeMirror pad where Mikrokosmos can be executed.

#+BEGIN_SRC html
<div class="mikrojs-console">
<script type="text/mikrokosmos">
(λx.x)
... your code
</script>
</div>
#+END_SRC

The Mikrokosmos tutorials are an example of this feature and can be
seen on Figure [[mikrokosmosjstutorial]].  They can be accessed from the
following direction.

#+begin_center
https://mroman42.github.io/mikrokosmos/
#+end_center

**** Image                                                                               :ignore:
#+caption: Mikrokosmos embedded into a web page.
#+name: mikrokosmosjstutorial
[[./images/mikrokosmosjs.png]]

[fn:ghcjs]: The GHCjs documentation is available on its web page https://github.com/ghcjs/ghcjs

** Programming environment
*** Cabal, Stack and Haddock
The Mikrokosmos documentation as a Haskell library is included
in its own code. It uses *Haddock*, a tool that generates documentation
from annotated Haskell code; it is the /de facto/ standard for Haskell
software.

Dependencies and packaging details for Mikrokosmos are specified in
a file distributed with the source code called =mikrokosmos.cabal=.
It is used by the package managers *stack* and *cabal* to provide the
necessary libraries even if they are not available system-wide. The
*stack* tool is also used to package the software, which is uploaded
to /*Hackage*/.

*** Testing
*Tasty* is the Haskell testing framework of our choice for this
project. It allows the user to create a comprehensive test suite
combining multiple types of tests. The Mikrokosmos code is tested
using the following techniques

  * *unit tests*, in which individual core functions are tested
    independently of the rest of the application;

  * *property-based testing*, in which multiple test cases are created
    automatically in order to verfiy that a specified property always
    holds; this has been useful to test our implementation of several
    algorithms on the lambda calculus;

  * *golden tests*, a special case of unit tests in which the expected
    results of an IO action, as described on a file, are checked to
    match the actual ones; they have been used to check correctness
    of the Mikrokosmos language.
    
We are using the *HUnit* library for unit tests. It tests particular
cases of type inference, unification and parsing. The following is an
example of unit test, as found in =tests.hs=. It checks that the type
inference of the identity term is correct.

#+BEGIN_SRC haskell
-- Checks that the type of λx.x is exactly A → A
testCase "Identity type inference" $
  typeinference (Lambda (Var 1)) @?= Just (Arrow (Tvar 0) (Tvar 0))
#+END_SRC

We are using the *QuickCheck* library for property-based tests. It
tests transformation properties of lambda expressions. In the following
example, it tests that any De Bruijn expression keeps its meaning when
translated into a \lambda-term.

#+BEGIN_SRC haskell
-- Tests if translation preserves meaning
QC.testProperty "Expression -> named -> expression" $
  \expr -> toBruijn emptyContext (nameExp expr) == expr
#+END_SRC

We are using the *tasty-golden* package for golden tests.  Mikrokosmos
can be passed a file as an argument to interpret it and show only the
results. This feature is used to create a golden test in which the
interpreter is asked to provide the correct interpretation of a given
file.  This file is called =testing.mkr=, and contains library
definitions and multiple tests. Its expected output is
=testing.golden=. For example, the following Mikrokosmos code can be
found on the testing file.

#+BEGIN_SRC haskell
:types on
caseof (inr 3) (plus 2) (mult 2)
#+END_SRC

While the expected output is the following.

#+BEGIN_SRC haskell
-- types: on
-- λa.λb.(a (a (a (a (a (a b)))))) ⇒ 6 :: (A → A) → A → A
#+END_SRC

*** Version control and continuous integration
Mikrokosmos uses *git* as its version control system and the code,
which is licensed under GPLv3, can be publicly accessed on the
following GitHub repository:

#+begin_center
https://github.com/mroman42/mikrokosmos
#+end_center

Development takes place on the =development= git branch and permanent
changes are released into the =master= branch. Some more minor
repositories have been used in the development; they directly
depend on the main one.

 * https://github.com/mroman42/mikrokosmos-js
 * https://github.com/mroman42/jupyter-mikrokosmos
 * https://github.com/mroman42/mikrokosmos-lib

The code uses the *Travis CI* continuous integration system to run
tests and check that the software builds correctly after each change
and in a reproducible way on a fresh Linux installation provided by
the service.

** Programming in untyped \lambda-calculus
<<sec-programming-untyped>>
# Untyped \lambda-calculus in programming languages

This section explains how to use untyped \lambda-calculus to encode
data structures such as booleans, linked lists, natural numbers or
binary trees. All of this is done in pure \lambda-calculus, avoiding
the addition of new syntax or axioms.

This presentation follows the Mikrokosmos tutorial on \lambda-calculus, which
aims to teach how it is possible to program using untyped \lambda-calculus
without discussing more advanced technical topics such as those we addressed on
Chapter [[sec-untypedlambda]]. It also follows the exposition on cite:selinger13 of
the usual Church encodings.

All the code on this section is valid Mikrokosmos code.

*** Basic syntax
In the interpreter, \lambda-abstractions are written with the symbol =\=,
representing a \lambda. This is a convention used on some functional languages
such as Haskell or Agda. Any alphanumeric string can be a variable and
can be defined to represent a particular \lambda-term using the === operator.

As a first example, we define the identity function (=id=), function 
composition (=compose=) and a constant function on two arguments which
always returns the first one untouched (=const=).

#+BEGIN_SRC haskell
id = \x.x
compose = \f.\g.\x.f (g x)
const = \x.\y.x
#+END_SRC

Evaluation of terms will be presented as comments to the code, as in
the following example.

#+BEGIN_SRC haskell
compose id id                                                -- [1]: λa.a ⇒ id
#+END_SRC

It is important to notice that multiple argument functions are defined as
higher one-argument functions that return different functions as arguments.
These intermediate functions are also valid \lambda-terms. For example,

#+BEGIN_SRC haskell
discard = const id
#+END_SRC

is a function that discards one argument and returns the identity, =id=.
This way of defining multiple argument functions is called the /currying/
of a function in honor to the american logician Haskell Curry in cite:haskell58.
It is a particular instance of a deeper fact we will detail on Chapter
[[sec-cartesianclosedlambdacalculus]]: exponentials are defined by the adjunction
$\hom(A \times B, C) \cong \hom(A, \hom(B,C))$.

*** A technique on inductive data encoding
<<technique-on-inductive>>
We will implicitly use a technique on the majority of our data
encodings that allows us to write an encoding for any algebraically
inductive generated data. This technique is used without explicit
comment on cite:selinger13 and represents the basis of what is called
the *Church encoding* of data in \lambda-calculus.

We start considering the usual inductive representation of
a data type with constructors, as we do when representing a
syntax with a BNF. For example, the naturals can be written
as $\mathtt{Nat} ::= \mathtt{Zero} \mid \mathtt{Succ}\ \mathtt{Nat}$; and, in general a datatype
$D$ with constructors $C_1,C_2,C_3,\dots$ is written as
$\mathtt{D} ::= C_1 \mid C_2 \mid C_3 \mid \dots$.

It is not possible to directly encode constructors on
\lambda-calculus. Even if we were able to declare constants, they
would have no computational content; the data structure would not be
reduced under any \lambda-term, and we would need at least the ability
to pattern-match on the constructors to define functions on them. Our
\lambda-calculus would need to be extended with additional syntax for
every new data structure.

Our technique, instead, is to define a data term as a function on
multiple arguments representing the missing constructors. For instance,
the number $2$, which would be written as $\mathtt{Succ}(\mathtt{Succ}(\mathtt{Zero}))$ using the
BFN, is encoded as $2 = \lambda s.\ \lambda z.\ s (s (z))$. In general, any instance of the data
structure $\mathtt{D}$ is encoded as a \lambda-expression depending on
all of its constructors, as in $\lambda c_{1}.\ \lambda c_{2}.\ \lambda c_{3}.\ \dots\ \lambda c_{n}. (\textit{term})$.

This acts as the definition of an initial algebra over the
constructors (see Section [[sec-algebras]]) and lets us to compute over
instances of that algebra by instantiating it on particular cases. We
will develop explicit examples of this technique on the following
sections.

*** Booleans
Booleans can be defined as the data generated by a pair of zero-ary
constuctors, each one representing a truth value, as in 
$\mathtt{Bool} ::= \mathtt{True} \mid \mathtt{False}$.  Consequently, the Church encoding of booleans
takes these constructors as arguments and defines the following
two elements.

#+BEGIN_SRC haskell
true  = \t.\f.t
false = \t.\f.f
#+END_SRC

**** If-else interpretation                                       :ignore:
Note that =true= and the =const= function we defined earlier are
exactly the same term up to \alpha-conversion. The same thing happens
with =false= and =alwaysid=.  The absence of types prevents any effort
to discriminate between these two uses of the same
\lambda-term. Another side-effect of this definition is that our
=true= and =false= terms can be interpreted as binary functions
choosing between two arguments, that is, $\mathtt{true}(a,b) = a$, and
$\mathtt{false}(a,b) = b$.

We can test this interpretation on the interpreter to get the
expected results.

#+BEGIN_SRC haskell
true id const                                                   --- [1]: id
false id const                                                  --- [2]: const
#+END_SRC

And this inspires the definition of an =ifelse= combinator as the
identity, when applied to boolean values.

#+BEGIN_SRC haskell
ifelse = \b.b
(ifelse true) id const                                          --- [1]: id
(ifelse false) id const                                         --- [2]: const
#+END_SRC

**** Logic gates                                                  :ignore:
The usual logic gates can be defined using this interpretation of
the booleans.

#+BEGIN_SRC haskell
and = \p.\q.p q p
or = \p.\q.p p q
not = \b.b false true
xor = \a.\b.a (not b) b
implies = \p.\q.or (not p) q

xor true true                                                   --- [1]: false
and true true                                                   --- [2]: true
#+END_SRC

*** Natural numbers
**** Peano natural numbers                                        :ignore:
Our definition of natural numbers is inspired by the Peano natural numbers.
We use two constructors

 * zero is a natural number, written as Z;
 * the successor of a natural number is a natural number, written as S;

and the BNF we defined when discussing how to encode inductive data
in Section [[technique-on-inductive]].

#+BEGIN_SRC haskell
0    = \s.\z.z
succ = \n.\s.\z.s (n s z)
#+END_SRC

This definition of =0= is trivial: given a successor function and a
zero, return zero. The successor function seems more complex, but
it uses the same underlying idea: given a number, a successor and a
zero, apply the successor to the interpretation of that number using
the same successor and zero.

We can then name some natural numbers as follows, even if we can not
define an infinite number of terms as we might wish.

#+BEGIN_SRC haskell
1 = succ 0
2 = succ 1
3 = succ 2
4 = succ 3
5 = succ 4
6 = succ 5
...
#+END_SRC

**** Interpretation as higher-order functions                     :ignore:
The interpretation a natural number $n$ as a higher order function
is a function taking an argument =f= and applying them $n$ times over
the second argument. See the following examples.

#+BEGIN_SRC haskell
5 not true                                                      --- [1]: false
4 not true                                                      --- [2]: true 
double = \n.\s.\z.n (compose s s) z
double 3                                                        --- [3]: 6
#+END_SRC

**** Addition and multiplication                                  :ignore:
Addition $n+m$ applies the successor $m$ times to $n$; and multiplication
$nm$ applies the $n\text{-fold}$ application of the successor $m$ times to $0$.

#+BEGIN_SRC haskell
plus = \m.\n.\s.\z.m s (n s z)
mult = \m.\n.\s.\z.m (n s) z
plus 2 1                                                        --- [1]: 3
mult 2 4                                                        --- [2]: 8
#+END_SRC

*** The predecessor function and predicates on numbers
**** Predecessor                                                  :ignore:
The predecessor function is much more complex than the previous ones.
As we can see, it is not trivial how could we compute the predecessor
using the limited form of induction that Church numerals allow.

Stephen Kleene, one of the students of Alonzo Church only discovered
how to write the predecessor function after thinking about it for a
long time (and he only discovered it while a long visit at the
dentist's, which is the reason why this definition is often called the
/wisdom tooth trick/, see cite:crossley75). We will use a slightly
different version of that definition, as we consider it to be simpler
to understand.

We will start defining a /reverse composition/ operator, called
=rcomp=; and we will study what happens when it is composed to itself;
that is, the operator we define in the following code
#+BEGIN_SRC haskell
rcomp = \f.\g.\h.h (g f)
\f.3 (inc f)                         --- [1]: λa.λb.λc.c (a (a (b a)))
\f.4 (inc f)                         --- [2]: λa.λb.λc.c (a (a (a (b a))))
\f.5 (inc f)                         --- [3]: λa.λb.λc.c (a (a (a (a (b a)))))
#+END_SRC
allows us to use the =b= argument to discard the first instance of the
=a= argument and return the same number wihtout the last constructor.
Thus, our definition of =pred= is
#+BEGIN_SRC haskell
pred = \n.\s.\z.(n (inc s) (\x.z) (\x.x))
#+END_SRC

**** Predicates                                                   :ignore:
From the definition of =pred=, some predicates on numbers can be
defined. The first predicate will be a function distinguishing a
successor from a zero. It will be user later to build more complex
ones. It is built by appliying a =const false= function =n= times to a
true constant. Only if it is applied =0= times, it will return a true
value.

#+BEGIN_SRC haskell
iszero = \n.(n (const false) true)
iszero 0                                                        --- [1]: true
iszero 2                                                        --- [2]: false
#+END_SRC

From this predicate, we can derive predicates on equality and ordering.

#+BEGIN_SRC haskell
leq = \m.\n.(iszero (minus m n))
eq  = \m.\n.(and (leq m n) (leq n m))
#+END_SRC

*** Lists and trees
We would need two constructors to represent a list: a $\mathsf{nil}$ signaling
the end of the list and a $\mathsf{cons}$, appending an element to the head of
the list. For instance, a list would be
$\mathsf{cons}\ 1\ (\mathsf{cons}\ 2\ (\mathsf{cons}\ 3\ \mathsf{nil}))$. Our definition takes those two
constructors into account.

#+BEGIN_SRC haskell
nil  = \c.\n.n
cons = \h.\t.\c.\n.(c h (t c n))
#+END_SRC

The interpretation of a list as a higher-order function is its
$\mathsf{fold}$ function, a function taking a binary operation and an initial
element and appliying the operation repeteadly to every element on
the list.
\[\mathsf{cons}\ 1\ (\mathsf{cons}\ 2\ (\mathsf{cons}\ 3\ \mathsf{nil}))
\overset{\mathsf{fold}\ \mathsf{plus}\ 0}\longrightarrow 
\mathsf{plus}\ 1\ (\mathsf{plus}\ 2\ (\mathsf{plus}\ 3\ 0)) = 6\]

The $\mathsf{fold}$ operation can be defined as follows. Many
operations on lists are particular instances of it.

#+BEGIN_SRC haskell
fold = \c.\n.\l.(l c n)
sum  = fold plus 0
prod = fold mult 1
all  = fold and true
any  = fold or false
length = fold (\h.\t.succ t) 0

sum (cons 1 (cons 2 (cons 3 nil)))                              --- [1]: 6   
all (cons true (cons true (cons true nil)))                     --- [2]: true
#+END_SRC

**** Map and filter                                                                      :ignore:
The two most commonly used particular cases of fold and frequent examples
of the functional programming paradigm are $\mathsf{map}$ and $\mathsf{filter}$.

  - The *map* function applies a function $f$ to every element on a
    list.
  - The *filter* function removes the elements of the list that do not
    satisfy a given predicate. It /filters/ the list, leaving only
    elements that satisfy the predicate.

They can be defined as follows.

#+BEGIN_SRC haskell
map = \f.(fold (\h.\t.cons (f h) t) nil)
filter = \p.(fold (\h.\t.((p h) (cons h t) t)) nil)
#+END_SRC

The $\mathsf{map}$ function, given a list of the form $\mathsf{cons}\ h\ t$, returns a new
list $\mathsf{cons}\ (f\ h)\ t$;
and given an empty list $\mathsf{nil}$, returns $\mathsf{nil}$. On the $\mathsf{filter}$ fuction, we use a
boolean to decide at each step whether to return a list with a head or
return the tail ignoring the head.

#+BEGIN_SRC haskell
mylist = cons 1 (cons 2 (cons 3 nil))
sum (map succ mylist)                                           --- [1]: 9
length (filter (leq 2) mylist)                                  --- [2]: 2
#+END_SRC

**** Binary trees                                                                        :ignore:
Lists have been defined using two constructors and *binary trees* will
be defined using the same technique. The only difference with lists is
that the =cons= constructor is replaced by a =node= constructor, which
takes two binary trees as arguments. That is, a binary tree is

 * an empty tree; or
 * a node, containing a label, a left subtree, and a right subtree.

Defining functions using a fold-like combinator is again very simple
due to the chosen representation. We need a variant
of the usual function acting on three arguments, the label, the right
node and the left node.

#+BEGIN_SRC haskell
-- Binary tree definition
node = \x.\l.\r.\f.\n.(f x (l f n) (r f n))
-- Example on natural numbers
mytree    = node 4 (node 2 nil nil) (node 3 nil nil)
triplesum = \a.\b.\c.plus (plus a b) c
mytree triplesum 0                                              --- [1]: 9
#+END_SRC

**** TODO The universal properties of fold, map and filter
*** Fixed points
<<sec-fixed-points>>
A fixpoint combinator is a term representing a higher-order function
that, given any function $f$, solves the equation $x = f\ x$
for $x$, meaning that, if $(\mathsf{fix}\ f)$ is the fixpoint of $f$, the following
sequence of equations holds
\[
\mathsf{fix}\ f =
f (\mathsf{fix}\ f) =
f ( f (\mathsf{fix}\ f)) =
f ( f ( f (\mathsf{fix}\ f))) =
\dots
\]

Such a combinator exists; and it can be defined and used as

#+BEGIN_SRC haskell
fix := (\f.(\x.f (x x)) (\x.f (x x)))
fix (const id)                                                 --- [1]: id
#+END_SRC

Where =:== defines a function without trying to evaluate it to a
normal form; this is useful in cases like the previous one, where the
function has no normal form. Examples of its applications are a
/factorial/ function or a /fibonacci/ function, as in

#+BEGIN_SRC haskell
fact := fix (\f.\n.iszero n 1 (mult n (f (pred n))))
fib  := fix (\f.\n.iszero n 1 (plus (f (pred n)) (f (pred (pred n)))))
fact 3                                                         --- [1]: 6
fib 3                                                          --- [2]: 5
#+END_SRC
Note the use of $\mathsf{iszero}$ to stop the recursion.

The $\mathsf{fix}$ function cannot be evaluated without arguments into a closed
form, so we have to delay the evaluation of the expression when we
bind it using =!==. Our evaluation strategy, however, will always find
a way to reduce the term if it is possible, as we saw in Corollary
[[cor-leftmosttheorem]]; even if it has intermediate irreducible terms.

#+BEGIN_SRC haskell
fix              -- diverges
true  id fix     -- evaluates to id
false id fix     -- diverges
#+END_SRC

Other examples of the interpreter dealing with non terminating functions
include infinite lists as in the following examples, where we take the
first term of an infinite list without having to evaluate it
completely or compare an infinite number arising as the fix point of
the successor function with a finite number.

#+BEGIN_SRC haskell
-- Head of an infinite list of zeroes
head = fold const false
head (fix (cons 0))
-- Compare infinity with other numbers
infinity := fix succ                                         --- [1]: 0    
leq infinity 6                                               --- [2]: false
#+END_SRC

These definitions unfold as

 * $\mathsf{fix\ (cons\ 0) = cons\ 0\ (cons\ 0\ (cons\ 0\ \dots))}$, an infinite list of zeroes;
 * $\mathsf{fix\ succ = succ\ (succ\ (succ\ \dots))}$, an infinite natural number.

As a final example, we define a minimisation operator that finds the
first natural causing a given predicate to return true.  This, with all the
previous considerations about how to program with natural numbers, can
be used to prove that Gödel's \mu-recursive functions can be encoded
inside untyped lambda calculus, and thus, it is Turing-complete.

#+BEGIN_SRC haskell
mu := \p.fix (\f.\n.(p n) n (f (succ n))) 0
mu (\n.eq (mult 2 n) 10)                                     --- [1]: 5
#+END_SRC

** Programming in the simply typed \lambda-calculus
<<sec-programming-typed>>
This section explains how to use the simply typed \lambda-calculus to
encode compound data structures and proofs in intuitionistic logic.
We will use the interpreter as a typed language and, at the same time,
as a proof assistant for the intuitionistic propositional logic.

This presentation of simply typed structures follows the Mikrokosmos
tutorial and the previous sections on simply typed \lambda-calculus
(see Section [[sec-simplytypedlambda]]). All the code on this section is
valid Mikrokosmos code.

*** Function types and typeable terms
Types can be activated with the commmand =:types on=. If types are
activated, the interpreter will infer (see Section [[sec-typeinference]])
the principal type of every term before its evaluation.  The type will
then be displayed after the result of the computation.

#+attr_latex: :options [Typed terms on Mikrokosmos]
#+begin_exampleth
The following are examples of already defined terms on lambda calculus and
their corresponding types. It is important to notice how our previously
defined booleans have two different types; while our natural numbers will
have all the same type except from zero, whose type is a generalization on
the type of the natural numbers.

#+begin_src haskell
id    --- [1]: λa.a ⇒ id, I, ifelse :: A → A
true  --- [2]: λa.λb.a ⇒ K, true :: A → B → A
false --- [3]: λa.λb.b ⇒ nil, 0, false :: A → B → B
0     --- [4]: λa.λb.b ⇒ nil, 0, false :: A → B → B
1     --- [5]: λa.λb.(a b) ⇒ 1 :: (A → B) → A → B
2     --- [6]: λa.λb.(a (a b)) ⇒ 2 :: (A → A) → A → A
S     --- [7]: λa.λb.λc.((a c) (b c)) ⇒ S :: (A → B → C) → (A → B) → A → C
K     --- [8]: λa.λb.a ⇒ K, true :: A → B → A
#+end_src
#+end_exampleth

If a term is found to be non-typeable, Mikrokosmos will output an error
message signaling the fact. In this way, the evaluation of \lambda-terms
that could potentially not terminate is prevented. Only typed \lambda-terms
will be evaluated while the option =:types= is on; this ensures the termination
of every computation on typed terms.

#+attr_latex: :options [Non-typeable terms on Mikrokosmos]
#+begin_exampleth
Fixed point operators are a common example of non typeable terms. Its evaluation
on untyped \lambda-calculus would not terminate; and the type inference algorithm
fails on them.

#+BEGIN_SRC haskell
fix
--- Error: non typeable expression
fix (\f.\n.iszero n 1 (plus (f (pred n)) (f (pred (pred n))))) 3
--- Error: non typeable expression
#+END_SRC

Note that the evaluation of compound \lambda-expressions where the fixpoint
operators appear applied to other terms can terminate, but the terms are
still non typeable.
#+end_exampleth

*** Product, union, unit and void types
Until now, we have only used the function type. That is to say that we
are working on the implicational fragment of the simply-typed lambda
calculus we described when first describing typing rules.  We are now
going to extend our type system in the same sense we extended (see
Section [[sec-extendingstlc]]) that simply-typed lambda calculus. The
following types are added to the system.

| Type | Name          | Description                       |
|------+---------------+-----------------------------------|
| =→=  | Function type | Functions from a type to another  |
| =×=  | Product type  | Cartesian product of types        |
| =+=  | Union type    | Disjoint union of types           |
| =⊤=  | Unit type     | A type with exactly one element   |
| =⊥=  | Void type     | A type with no elements           |

And the following typed constructors are added to the language.

| Constructor | Type                              | Description               |
|-------------+-----------------------------------+---------------------------|
| =(-,-)=     | =A → B → A × B=                   | Pair of elements          |
| =fst=       | =(A × B) → A=                     | First projection          |
| =snd=       | =(A × B) → B=                     | Second projection         |
| =inl=       | =A → A + B=                       | First inclusion           |
| =inr=       | =B → A + B=                       | Second inclusion          |
| =caseof=    | =(A + B) → (A → C) → (B → C) → C= | Case analysis of an union |
| =unit=      | =⊤=                               | Unital element            |
| =abort=     | =⊥ → A=                           | Empty function            |
| =absurd=    | =⊥ → ⊥=                           | Particular empty function |

They correspond to the constructors we described on previous
sections. The only new term is the =absurd= function, which is
only a particular case of =abort=, useful when we want to make explicit
that we are deriving an instance of the empty type. This addition will
only make the logical interpretation on the following sections
clearer.

#+attr_latex: :options [Extended STLC on Mikrokosmos]
#+begin_exampleth
The following are examples of typed terms and functions on Mikrokosmos
using the extended typed constructors. The following terms are presented

  * a function swapping pairs, as an example of pair types;
  * two-case analysis of a number, deciding whether to multiply it by two
    or to compute its predecessor;
  * difference between =abort= and =absurd=;
  * example term containing the unit type.

#+BEGIN_SRC haskell
:load types
swap = \m.(snd m,fst m)
swap                 --- [1]: λa.((SND a),(FST a)) ⇒ swap :: (A × B) → B × A
caseof (inl 1) pred (mult 2) --- [2]: λa.λb.b ⇒ nil, 0, false :: A → B → B  
caseof (inr 1) pred (mult 2) --- [3]: λa.λb.(a (a b)) ⇒ 2 :: (A → A) → A → A
\x.((abort x),(absurd x))    --- [4]: λa.((ABORT a),(ABSURD a)) :: ⊥ → A × ⊥
#+END_SRC

Now it is possible to define a new encoding of the booleans with an
uniform type. The type =⊤ + ⊤= has two inhabitants, =inl ⊤= and =inr
⊤=; and they can be used by case analysis.

#+BEGIN_SRC haskell
btrue = inl unit
bfalse = inr unit
bnot = \a.caseof a (\a.bfalse) (\a.btrue)
bnot btrue                            --- [1]: (INR UNIT) ⇒ bfalse :: A + ⊤
bnot bfalse                           --- [2]: (INL UNIT) ⇒ btrue :: ⊤ + A
#+END_SRC
#+end_exampleth

With these extended types, Mikrokosmos can be used as a proof checker on
first-order intuitionistic logic by virtue of the Curry-Howard
correspondence.

*** A proof in intuitionistic logic
<<section-proof-lem>>
Under the logical interpretation of Mikrokosmos, we can transcribe
proofs in intuitionistic logic to \lambda-terms and check them on the
interpreter. The translation between logical propositions and types is
straightforward, except for the *negation* of a proposition $\neg A$, that
must be written as $(A \to \bot)$, a function to the empty type.

#+begin_theorem
In intuitionistic logic, the double negation of the Law of Excluded
Middle holds for every proposition. That is, we know that $\neg\neg(A \vee \neg A)$
for an arbitrary proposition $A$.
#+end_theorem
#+begin_proof
Suppose $\neg (A \lor \neg A)$. We are going to prove first that, under this
specific assumption, $\neg A$ holds. If $A$ were true, $A \lor \neg A$ would be true and we
would arrive to a contradition, so $\neg A$. But then, if we have $\neg A$ we also have
$A \lor \neg A$ and we arrive to a contradiction with the assumption. We must conclude
that $\neg \neg (A \lor \neg A)$.
#+end_proof

Note that this is, in fact, a constructive proof. Although it seems
to use the intuitionistically forbidden technique of proving by
contradiction, it is actually only proving a negation.  There is a
difference between assuming $A$ to prove $\neg A$ and assuming $\neg
A$ to prove $A$:
the first one is simply a proof of a negation, the
second one uses implicitly the law of excluded middle.

This can be translated to the Mikrokosmos implementation of simply
typed \lambda-calculus as the following term, whose type is
precisely $((A + (A \to \bot)) \to \bot) \to \bot$.
#+BEGIN_SRC haskell
notnotlem = \f.absurd (f (inr (\a.f (inl a))))
notnotlem 
--- [1]: λa.(ABSURD (a (INR λb.(a (INL b))))) :: ((A + (A → ⊥)) → ⊥) → ⊥
#+END_SRC
The derivation tree
can be seen directly on the interpreter as Figure [[mikrogentzen]] shows.

#+caption: Proof of the double negation of the Law of Excluded Middle in Mikrokosmos.
#+name: mikrogentzen
[[./images/mikrogentzen2.png]]

* Category theory
** Categories
*** Motivation                                                                            :ignore:
*Categories* are algebraic structures that capture the notion of
composition. They consist of objects linked by composable arrows; to
which associativity and identity laws will apply.  Thus, a category
has to rely in some notion of /collection of objects/.  When
interpreted inside set-theory, this term can denote sets or proper
classes.  We want to talk about categories containing subsets of the
class of all sets, and thus it is necessary to allow the objects to
form a proper class (which is not itself a set) in order to avoid
inconsistent results such as the Russell's paradox.  This is why we
will consider a particular class of categories of small
set-theoretical size to be specially well-behaved.

#+attr_latex: :options [Small and locally small categories]
#+begin_definition
A category is said to be *small* if the collection of its objects can
be given by a set (instead of a proper class).  It is *locally small*
if the collection of arrows between any two objects can be given by a
set.
#+end_definition

A different approach, however, would be to simply take /objects/ and
/arrows/ as fundamental concepts of our theory. These foundational
concerns will not cause any explicit problem in this presentation of
category theory, so we will keep it deliberately open to both
interpretations.

*** Definition of category
**** Categories, objects and morphisms                            :ignore:
#+begin_definition
A *category* ${\cal C}$ (following cite:maclane78 or cite:awodey10) is given by
a collection whose elements are called /objects/, sometimes denoted $\mathrm{obj}({\cal C})$ or simply ${\cal C}$;
and a collection whose elements are called /morphisms/.
Every morphism $f$ is assigned two objects, its /domain/ and its
/codomain/; we write $f \colon A \to B$ to indicate that $f$ has domain $A$ and
codomain $B$.

Given any two morphisms $f \colon A \to B$ and $g \colon B \to C$, there exists a
*composition* morphism $g \circ f \colon A \to C$. Composition of morphisms
is a partially defined binary operation satisfying the following
two axioms. It must be /associative/,
verifying that $h \circ (g \circ f) = (h \circ g) \circ f$ for any composable morphisms
$f,g,h$; and there must exist an /identity/ morphism $\id_{A}\colon A \to A$ for each
object $A$, verifying that $f \circ \id_A = f = \id_B \circ f$ for all $f \colon A \to B$.
#+end_definition

**** Definition of hom-sets                                       :ignore:
The collection of morphisms between two objects $A$ and $B$ is called
an *hom-set* and it is written as $\hom(A,B)$. When necessary, we can
use a subscript, as in $\hom_{{\cal C}}(A,B)$, to explicitly specify the
category we are working in.

***** OLD Endomorphisms
The set of *endomorphisms*
of an object $A$ is defined as $\mathrm{end}(A) = \hom(A,A)$.

*** Morphisms
**** Morphisms: introduction                                      :ignore:
Objects in category theory are an atomic concept and can be only
studied by their morphisms; that is, by how they relate to each other.
In other words, the essence of a category is given not by its objects,
but by the morphisms between them and how composition is defined.
It is so much so, that we will consider two objects essentially
equivalent (and we will call them /isomorphic/) whenever they relate
to other objects in the exact same way. This occurs if we can find
an invertible morphism connecting both: composition by this morphism
or its inverse will translate arrows from one object to the other.

**** Isomorphisms                                                 :ignore:
#+begin_definition
A morphism $f : A \to B$ is an *isomorphism* if there exists a morphism
$f^{-1} : B \to A$ such that $f^{-1} \circ f = \id_{A}$ and $f \circ f^{-1} = \id_{B}$.
This morphism is called an *inverse* of $f$. When an isomorphism between
two objects $A$ and $B$ exists, we say they are /isomorphic/, and we write
$A \cong B$.
#+end_definition

**** Unicity of inverses                                          :ignore:
#+begin_proposition
<<prop-unicityinverse>>
There is, at most, a single way to invert a morphism.  If the inverse of a
morphism exists, it is unique. In fact, if a morphism has a left-side
inverse and a right-side inverse, they must be equal.
#+end_proposition
#+begin_proof
Given $f : A \to B$ with a left-side inverse $g_1 \colon B \to A$ and a right-side
inverse $g_2 : B \to A$; we have that
\[
g_1 = g_1 \circ \id_A = g_1 \circ (f \circ g_2) = 
(g_1 \circ f) \circ g_2 =
\id \circ g_2 = g_2.\qedhere
\]
#+end_proof

**** Equivalence relation                                         :ignore:
As expected, /to be isomorphic to/ is an equivalence
relation. In particular, reflexivity follows from the fact that the
identity is its own inverse, $\id = \id^{-1}$; symmetry follows from the
inverse of an isomorphism being itself an isomorphism, $(f^{-1})^{-1} = f$;
and transitivity follows by the fact that the composition of isomorphisms
is itself an isomorphism, $(f \circ g)^{-1} = g^{-1} \circ f^{-1}$. All these equalities
can be checked from the axioms of a category.

**** Monomorphisms and epimorphisms                               :ignore:
We can notice that morphisms are an abstraction of the notion of
structure-preserving maps between mathematical structures.  Two
structures can be identified if they are related by an isomorphism.
From this perspective, it seems natural to ask how injective and
surjective can be described only in terms of composition.
/Monomorphisms/ and /epimorphisms/ will be abstractions of the usual
injective and surjective homomorphisms, respectively.

#+attr_latex: :options [Monomorphisms and epimorphisms]
#+begin_definition
A *monomorphism* is a left-cancellable morphism, that is, $f : A \to B$ is
a monomorphism if, for every pair of morphisms $g,h : B \to A$, the
equality $f \circ g = f \circ h$ implies $g = h$.

Dually, an *epimorphism* is a right-cancellable morphism, that is, $f : A \to B$ is
an epimorphism if, for every $g,h : B \to A$, the equality $g \circ f = h \circ f$
implies $g = h$.
#+end_definition

***** TODO Bimorphisms
A morphism that is a monomorphism and an epimorphism at the same time is
called a *bimorphism*.

#+begin_remark
A morphism can be a bimorphism without being an isomorphism. We will
cover [[*Examples of categories][examples]] of this fact later.
#+end_remark

**** Retractions and sections                                     :ignore:
Note that we could have chosen a stronger and non-equivalent notion
to generalize the notions of injective and surjective functions.

#+attr_latex: :options [Retractions and sections]
#+begin_definition
A *retraction* is a left inverse, that is, a morphism that has a right
inverse; conversely, a *section* is a right inverse or, in other
words, a morphism that has a left inverse.
#+end_definition

By virtue of Proposition [[prop-unicityinverse]], a morphism that is both
a retraction and a section is an isomorphism. In general, however, not
every epimorphism is a section and not every monomorphism is a
retraction. Consider for instance a category with two objects and a
single morphism connecting them; it is a monomorphism and an
epimorphism, but it has no inverse. In any case, we will usually work
with the more general notion of monomorphisms and epimorphisms.

*** Products and sums
**** Motivation                                                   :ignore:
/Products and sums/ are very widespread notions in mathematics.
Whenever a new structure is defined, it is common to ask what the
product or sum of two of these structures would be. Examples of
products are the cartesian product of sets, the product topology or
the product of abelian groups; examples of sums are the disjoint
union of sets, topological sum or the free product of groups.  Following
this idea, we can consider certain structures to constitute a $0$ or a $1$
for these operations; these are called /initial and final objects/.

We will abstract categorically these notions in terms of /universal/
/properties/. This point of view, however, is an important shift with
respect to how these properties are classicallys defined. We will not
define the product of two objects in terms of their internal structure
(categorically, objects are atomic and do not have any); but in terms
of all the other objects, that is, in terms of the complete structure
of the category. This turns inside-out the focus of the definitions.
Moreover, objects defined in terms of universal properties are usually
not uniquely determined, but only determined /up to isomorphism/. This
reinforces our previous idea of considering two isomorphic objects in
a category as /essentially/ the same object.

**** Terminal and initial objects                                 :ignore:
#+attr_latex: :options [Initial and terminal objects]
#+begin_definition
An object $0$ is an *initial object* if for every object $A$ exists an 
unique morphism of the form $o_A \colon 0 \to A$. An object $1$ is a *terminal object* if
for every object $A$ exists an unique morphism of the form $\ast_A \colon A \to 1$.
#+end_definition

**** Unicity                                                      :ignore:
Note that these objects may not exist in any given category;
but when they do, they are essentially unique. If $A,B$ are initial
objects, by definition, there are a unique morphism $f : A \to B$, a
unique morphism $g : B \to A$, and two unique morphisms $A \to A$ and $B \to B$.
By uniqueness, $f \circ g = \id$ and $g \circ f = \id$, hence $A \cong B$.
An analogous proof can be written for terminal objects.

**** Products and sums                                            :ignore:
# TODO: The definition of product was given by MacLane on 1949. (Awodey on CTF2.0)

#+attr_latex: :options [Products and sums]
#+begin_definition
<<def-product>>
An object $A\times B$ with two morphisms $\pi_1 \colon A\times B \to A$ and $\pi_2 \colon A \times B \to B$ 
is a *product* of $A$ and $B$ if for any other object $D$ with 
two morphisms $f_1 : D \to A$ and $f_2 : D \to B$, there exists a unique morphism
$h : D \to A \times B$, such that $f_1 = \pi_1 \circ h$ and $f_2 = \pi_2 \circ h$ as in the following
commutative diagram.
\[\begin{tikzcd}
& D \dar[dashed]{\exists! h} \ar[bend left]{dr}{f_2}\ar[bend right,swap]{dl}{f_1} & \\
A& A \times B \rar[swap]{\pi_2}\lar{\pi_1} & B
\end{tikzcd}\]
An object $A + B$ with two morphisms $i_{1} \colon A \to A+B$ and $i_2 \colon B \to A + B$ is the
*sum* of $A$ and $B$ for any other object $D$ with two morphisms $f_1 : A \to D$ and
$f_2 : B \to D$, there exists a unique morphism $h : D \to A+B$, such that $f_1 = h \circ i_1$
and $f_2 = h \circ i_2$ as in the following commutative diagram.
\[\begin{tikzcd}
& D & \\
A \ar[bend left]{ur}{f_1}\rar[swap]{i_1} & A+B \uar[dashed]{\exists! h}  & 
B \ar[bend right,swap]{ul}{f_2}\lar{i_2}
\end{tikzcd}\]
#+end_definition

Note that neither the product nor the sum of two objects necessarily exist
on a category; but when they do, they are essentially unique. This
justifies writing them as $A \times B$ and $A+B$.  The proof is
similar to that of the unicity of initial and terminal objects.

*** Examples of categories
Many mathematical structures, such as sets, groups, or partial orders,
are particular cases of a category.  Apart from these, we will be also
interested in categories whose /objects/ are known mathematical
structures (the category of all groups, the category of all sets, and
so on). The following are examples on how general the definition of a
category is.

**** Discrete categories                                          :ignore:
#+begin_exampleth
A category is *discrete* if it has no other morphisms than the
identities.  A discrete small category is uniquely defined by the
underlying set of its objects and every class of objects defines a
discrete category. Thus, small discrete categories can be regarded
as sets.
#+end_exampleth

**** Monoids, groups, groupoids                                   :ignore:
#+begin_exampleth
A single-object category is a *monoid*. A category in which every
morphism is an isomorphism is a *groupoid*. A *group* is a category
which is a monoid and a groupoid at the same time. These definitions
are equivalent to the usual ones if we take morphisms as the
elements and composition as the binary operation.
#+end_exampleth

**** Posets                                                       :ignore:
#+begin_exampleth
*Partially ordered sets* are categories with, at most, one morphism
between any two objects. We say $a \leq b$ whenever $\rho_{a,b} \colon a \to b$ exists.
In a partially ordered set, the product of two objects would be its
join, the coproduct would be its meet and the initial and terminal
objects would be the greatest and the least element, respectively.

In particular, every ordinal can be seen as a partially ordered set
and defines a category. For example, if we take the finite ordinal
$[n] = (0 < \dots < n)$, it could be interpreted as the category given
by the following diagram.
\[\begin{tikzcd}
0 \rar\arrow[loop above]\ar[bend right]{rr}\ar[bend right]{rrrr} &
1 \rar\arrow[loop above]\ar[bend right]{rrr} &
2 \rar\arrow[loop above]\ar[bend right]{rr} &
\dots \rar &
n \arrow[loop above]
\end{tikzcd}\]
#+end_exampleth

**** Category of Sets                                             :ignore:
#+attr_latex: :options [The category of sets]
#+begin_exampleth
The category $\Set$ is defined as the category with all sets as
objects and functions between them as morphisms. It is trivial to
check associativity of composition and the existence of the identity
function for any set.

In this category, the product is given by the usual cartesian product
\[
A \times B = \big\{ (a,b) \mid a \in A,\ b \in B \big\},
\]
with the projections $\pi_A(a,b) = a$ and $\pi_B(a,b) = b$. We can easily
check that, if we have $f : C \to A$ and $g : C \to B$, there is a unique
function given by $h(c) = (f(c),g(c))$ such that $\pi_A \circ h = f$ and
$\pi_B \circ h = g$.

The initial object in $\Set$ is given by the empty set $\varnothing$: given any set $A$,
the only function of the form $f : \varnothing \to A$ is the empty one. The final
object, however, is only defined up to isomorphism: given any set with
a single object $\{u\}$, there exists a unique function of the form $f : A \to \left\{ u \right\}$
for any set $A$; namely, the one defined as $\forall a \in A: f(a) = u$. Every
two sets with exactly one object are trivially isomorphic.

Similarly, the sum of two sets $A,B$ is given by its disjoint union $A \sqcup B$; 
which can be defined in many different (but equivalent) ways. For instance,
we can add a label to the elements of each sets before joining them in
order to ensure that the union is in fact disjoint. That is, a possible
coproduct is
\[
A \sqcup B = \left\{ (a,0) \mid a \in A \right\} \cup \left\{ (b,1) \mid b \in B \right\}
\]
with the inclusions $i_A(a) = (a,0)$ and $i_B(b) = (b,1)$. Given any two functions
$f : A \to C$ and $g : A \to C$, there exists a unique function $h : A \sqcup B \to C$,
given by
\[ h(x,n) = 
\left\{ \begin{array}{ll}
   f(x) & \mbox{if } n = 0, \\
   g(x) & \mbox{if } n = 1,
\end{array}\right.
\]
such that $f = h \circ i_A$ and $g = h \circ i_B$.
#+end_exampleth

**** Category of Groups                                           :ignore:
#+attr_latex: :options [Groups and modules]
#+begin_exampleth
The category $\mathsf{Grp}$ is defined as the category with groups as
objects and group homomorphisms between them as morphisms. The
category $R\text{-Mod}$ is defined as the category with
$R\text{-modules}$ as objects and module homomorphisms between them as
morphisms. We know that the composition of module homomorphisms and
the identity are also module homomorphisms. In particular, abelian
groups form a category as $\mathbb{Z}\text{-modules}$.
#+end_exampleth

**** Category of Topological spaces                               :ignore:
#+attr_latex: :options [The category of topological spaces]
#+begin_exampleth
The category $\mathsf{Top}$ is defined as the category with
topological spaces as objects and continuous functions between them as
morphisms.
#+end_exampleth
# Product topology

** Functors and natural transformations
#+begin_quote
/"Category" has been defined in order to define "functor" and "functor"/
/has been defined in order to define "natural transformation"./

   -- *Saunders MacLane*, /Categories for the working mathematician/, cite:maclane42.
#+end_quote

Functors and natural transformations were defined for the first time
by Eilenberg and MacLane in cite:maclane42 and cite:eilenberg45 while
studying cohomology theory. While initially they were devised mainly
as a language for this study, they have proven its foundational value
with the passage of time. The notion of naturality will be a key
element of our presentation of algebraic theories and categorical
logic.

*** Functors
**** Definition of functor                                        :ignore:
*Functors* can be seen as a homomorphisms of categories that preserve
composition and identity arrows. A functor between two categories, $F : {\cal C} \to {\cal D}$,
is given by

  * an *object function*, $F : \mathrm{obj}({\cal C}) \to \mathrm{obj}({\cal D})$;
  * and an *arrow function*, $F : \hom(A, B) \to \hom(FA, FB)$, for any two
    objects $A,B$ of the category;

such that $F(\id) = \id$, and $F(f \circ g) = Ff \circ Fg$. We can arrange functors,
at least in the case of small categories, into a category of categories.

\\

**** Composition of functors                                      :ignore:
#+BEGIN_definition
The category $\Cats$ is defined as the category of (small) categories as
objects and functors as morphisms.

 * Given two functors $F \colon {\cal C} \to {\cal B}$ and $G \colon {\cal B} \to {\cal A}$, their composite functor
   $G \circ F : {\cal C} \to {\cal A}$ is given by the composition of the object and arrow functions
   of the functors. This composition is trivially associative.

 * The identity functor on a category $\Id_{{\cal C}}\colon {\cal C} \to {\cal C}$ is given by identity object
   and arrow functions. It is trivially neutral with respect to composition.
#+END_definition

**** Full and faithfull functors                                  :ignore:
We now consider certain properties of functors in this category.
We say that a functor $F$ is *full* if every $g\colon FA \to FB$ is of
the form $Ff$ for some morphism $f \colon A \to B$. We say $F$ is *faithful*
if, for every two arrows $f_1,f_2\colon A \to B$, $Ff_1 = Ff_2$ implies $f_1 = f_2$.
It is easy to notice that the composition of faithful (respectively,
full) functors is again a faithful functor (respectively, full).

These notions are equivalent to notions of injectivity and surjectivity
on the arrow function between any two objects.
Note, however, that a faithful functor needs not to be injective on objects nor
on morphisms. In particular, if $A,A',B,B'$ are four different objects,
it could be the case that $FA = FA'$ and $FB = FB'$; and, if $f : A \to B$ and
$f' : A' \to B'$ were two morphisms, it could be the case that $Ff = Ff'$.
The following notion of isomorphism does require the complete functor
to have an inverse.

**** Isomorphisms of categories                                   :ignore:
#+begin_definition
<<def-isomorphismcategories>>
An *isomorphism of categories* is a functor $F$ whose object and arrow functions
are bijections. Equivalently, it is a functor $F$ such that there exists an /inverse/
functor $G$ such that $F \circ G$ and $G \circ F$ are the identity functor.
#+end_definition

Unfortunately, this notion of isomorphism of categories is too strict in
some cases.  Sometimes, the two compositions $F \circ G$ and $G \circ F$
are not exactly the identity functor, but isomorphic to it in some
sense yet to be made precise. We develop weaker notions in the next
section.

*** Natural transformations
**** Natural transformations                                      :ignore:
We have defined functors relating structures on different categories,
and now, we could consider if any two given functors can be related in
a /canonical/ way, involving no arbitrary choices.  An example is the
relation between the identity functor and the double dual functor in
vector spaces. They are related by the canonical isomorphism that
sends each vector to the operator that evaluates a function over
it. In this case, the isomorphism can be described without making any
explicit reference to the space. On the other hand, the isomorphism
relating a vector space to its dual depends on the choice of a basis.
A family of /canonical/ linear isomorphisms $\sigma_V \colon V \to V^{\ast}$ translating between
an space and its dual, should be invariant to linear maps $\mu \colon V \to W$, so
it should satisfy $\sigma_V(v)(w) = \sigma_W(\mu(v))(\mu(w))$, but this is not possible
for all $\mu$ linear.  The notion of /natural transformation/ formalizes
this intuitive idea.
# https://www.ams.org/journals/tran/1945-058-00/S0002-9947-1945-0013131-6/S0002-9947-1945-0013131-6.pdf

A *natural transformation* between two functors $F$ and $G$ with the same domain
and codomain, written as $\alpha\colon F \tonat G$, is a family of morphisms parameterized by
the objects of the domain category, $\{\alpha_C\colon FC \to GC\}_{C \in {\cal C}}$, such that
$\alpha_{C'} \circ Ff = Gf \circ \alpha_C$ for every arrow $f \colon C \to C'$. That is, the following
diagram commutes.
\[\begin{tikzcd}
C \dar{f} & & FC \rar{\alpha_C}\dar[swap]{Ff} & GC \dar{Gf} \\
C' & & FC' \rar{\alpha_{C'}} & GC'
\end{tikzcd}\]

Sometimes, we also say that the family of morphisms $\alpha$ is /natural/ in its
argument. This naturality property is what allows us to "translate" a
commutative diagram from a functor to another, as in the following example.
\[\begin{tikzcd}
A\arrow{dd}{h}\drar{f} &   & & F A\arrow{dd}{F h}\drar{F f} \arrow{rrr}{\alpha_A} &     & & G A\arrow{dd}{}\drar{G f} &     \\
  & B \dlar{g} & &     & F B \dlar{F g} \arrow{rrr}{\alpha_B} & &     & G B \dlar{G g} \\
C &   & & F C \arrow{rrr}{\alpha_C} &     & & G C &     \\
\end{tikzcd}\]

**** Natural isomorphisms                                         :ignore:
*Natural isomorphisms* are natural transformations in which every
component, every morphism of the parameterized family, is
invertible. In this case, the inverses form themselves a new
transformation, whose naturality follows from the naturality of the
original transformation. We say that $F$ and $G$ are
/naturally isomorphic/, $F \cong G$, when there is a natural isomorphism
between them.

\\

**** Equivalence of categories                                    :ignore:
The notion of a natural isomorphism between functors allows us to
weaken the condition of strict equality we imposed when talking about
isomorphisms of categories (Definition [[def-isomorphismcategories]]).
We say that two categories ${\cal C}$ and ${\cal D}$ are *equivalent* if there exist two
functors $F \colon {\cal C} \to {\cal D}$ and $G \colon {\cal D} \to {\cal C}$ such that $G \circ F \cong \Id_{{\cal C}}$ and
$F \circ G \cong \Id_{{\cal D}}$. The pair of functors endowed with the two natural
isomorphisms is called an /equivalence of categories/

*** Composition of natural transformations
**** Vertical and horizontal                                      :ignore:
The next reasonable step is to ask how natural transformations compose.
If we draw natural transformations between functors as double arrows,
as in the following diagram,
\[\begin{tikzcd}
{\cal C} 
\arrow[bend left=50]{r}[name=U,below]{}{F}
\arrow[bend right=50]{r}[name=D]{}[swap]{G}
& 
{\cal D} \arrow[Rightarrow,from=U,to=D]{}{\alpha}
\end{tikzcd}\]
we notice that two different notions of composition arise; we have a 
/vertical/ composition of natural transformations, which,
diagramatically, composes the two sequential natural transformations
on the left side into a single transformation on the right side of the
following diagram;
\[\begin{tikzcd}[column sep=large]
{\cal C} 
\arrow[bend left=80]{r}[name=U,below]{}{F}
\arrow[bend right=80]{r}[name=D]{}[swap]{H}
\arrow[]{r}[name=C]{}[swap,xshift=-1.5ex]{G}
\arrow[]{r}[name=C2,below]{}[]{}
& 
{\cal D}
\arrow[Rightarrow,from=U,to=C]{}{\alpha}
\arrow[Rightarrow,from=C2,to=D]{}{\beta}
&
{\cal C}
\arrow[bend left=50]{r}[name=U,below]{}{F}
\arrow[bend right=50]{r}[name=D]{}[swap]{H}
& 
{\cal D} \arrow[Rightarrow,from=U,to=D]{}{\alpha\cdot\beta}
\end{tikzcd}\]
and we have a /horizontal/ composition of natural transformations,
which composes the two parallel natural transformations on the left
side into a single transformation on the right side of the following
diagram.
\[\begin{tikzcd}[column sep=large]
{\cal C} 
\arrow[bend left=50]{r}[name=U,below]{}{F}
\arrow[bend right=50]{r}[name=D]{}[swap]{G}
& 
{\cal D} \arrow[Rightarrow,from=U,to=D]{}{\alpha}
\arrow[bend left=50]{r}[name=UU,below]{}{F'}
\arrow[bend right=50]{r}[name=DD]{}[swap]{G'}
&
{\cal E} \arrow[Rightarrow,from=UU,to=DD]{}{\alpha'}
&
{\cal C}
\arrow[bend left=50]{r}[name=U,below]{}{F' \circ F}
\arrow[bend right=50]{r}[name=D]{}[swap]{G' \circ G}
& 
{\cal E} \arrow[Rightarrow,from=U,to=D]{}{\alpha'\circ\alpha}
\end{tikzcd}\]

**** Vertical composition                                         :ignore:
#+begin_definition
The *vertical composition* of two natural transformations $\alpha : F \tonat G$ and
$\beta : G\tonat H$, denoted by $\beta \cdot \alpha$ is the family of morphisms defined by the
objectwise composition of the morphisms of the two natural transformations.
That is, $(\beta \cdot \alpha) = \{\beta_C \circ \alpha_C\}_{C \in {\cal C}}$.
#+end_definition

Naturality of this family follows from the naturality of its two
factors. Given any morphism $f \colon A \to B$, the commutativity of the
external square on the diagram below follows from the commutativity of
the two internal squares.
\[\begin{tikzcd}
FA \rar{Ff}\dar{\alpha_A}\arrow[swap,bend right=90]{dd}{(\beta \cdot \alpha)_A} &
FB \dar{\alpha_{B}} \arrow[bend left=90]{dd}{(\beta \cdot \alpha)_{B}} \\
GA \rar{Gf}\dar{\beta_A}  &
GB \dar{\beta_{B}} \\
HA \rar{Hf}  &
HB
\end{tikzcd}\]

**** Horizontal composition                                       :ignore:
#+attr_latex: :options [Horizontal composition of natural transformations]
#+begin_definition
The *horizontal composition* of two natural transformations $\alpha \colon F \to G$ and
$\alpha' \colon F' \to G'$, with domains and codomains as in the following diagram
\[\begin{tikzcd}[column sep=large]
{\cal C} 
\arrow[bend left=50]{r}[name=U,below]{}{F}
\arrow[bend right=50]{r}[name=D]{}[swap]{G}
& 
{\cal D} 
\arrow[Rightarrow,from=U,to=D]{}{\alpha}
\arrow[bend left=50]{r}[name=UU,below]{}{F'}
\arrow[bend right=50]{r}[name=DD]{}[swap]{G'}
&
{\cal E} 
\arrow[Rightarrow,from=UU,to=DD]{}{\alpha'}
\end{tikzcd}\]
is denoted by $\alpha' \circ \alpha \colon F'\circ F \to G' \circ G$ and is defined as the family of
morphisms given by $\alpha' \circ \alpha = \{G'\alpha_C \circ \alpha'_{FC}\}_{C \in {\cal C}} = \{\alpha'_{GC} \circ F'\alpha_C\}_{C \in {\cal C}}$, that is,
by the diagonal of the following square, which is commutative by the naturality
of $\alpha'$.
\[\begin{tikzcd}[column sep=huge]
F'FC\rar{\alpha'_{FC}} 
\drar{\scriptsize{(\alpha' \circ \alpha)_C}} 
\dar[swap]{F'\alpha_C} & 
G'FC \dar{G' \alpha_C} \\
F'GC\rar{\alpha'_{GC}} &
G'GC
\end{tikzcd}\]
#+end_definition

Naturality of this family follows again from the naturality of its two
factors. Given any morphism $f \colon A \to B$, the following diagram is commutative
because it is the composition of two naturality squares given by the
naturality of $F'\alpha$ and $\alpha'$.
\[\begin{tikzcd}
F'FA \rar{F'\alpha} \dar{F'Ff} &
F'GA \rar{\alpha'}  \dar{F'Gf} &
G'GA \dar{G'Gf} \\
F'FB \rar{F'\alpha} &
F'GB \rar{\alpha'} &
G'GB
\end{tikzcd}\]

**** Interchange law                                              :ignore:
#+ATTR_LATEX: :options [Interchange law]
#+BEGIN_proposition
<<prop-interchangelaw>>
The two possible ways of composing vertical and horizontal transformations
in a diagram like the following one
\[\begin{tikzcd}[column sep=large]
{\cal C} 
\arrow[bend left=80]{r}[name=U,below]{}{F}
\arrow[bend right=80]{r}[name=D]{}[swap]{H}
\arrow[]{r}[name=C]{}[swap,xshift=-1.5ex]{G}
\arrow[]{r}[name=C2,below]{}[]{}
& 
{\cal D}
\arrow[Rightarrow,from=U,to=C]{}{\alpha}
\arrow[Rightarrow,from=C2,to=D]{}{\beta}
\arrow[bend left=80]{r}[name=U3,below]{}{F'}
\arrow[bend right=80]{r}[name=D3]{}[swap]{H'}
\arrow[]{r}[name=C3]{}[swap,xshift=-1.5ex]{G'}
\arrow[]{r}[name=C23,below]{}[]{}
&
{\cal E}
\arrow[Rightarrow,from=U3,to=C3]{}{\alpha'}
\arrow[Rightarrow,from=C23,to=D3]{}{\beta'}
\end{tikzcd}\]
are actually equivalent. That is, $(\beta' \cdot \alpha') \circ (\beta \cdot \alpha) = (\beta' \circ \beta) \cdot (\alpha' \circ \alpha)$.
#+END_proposition
#+BEGIN_proof
By naturality of $\alpha'$, we have
\[\begin{aligned}
(\beta' \cdot \alpha') \circ (\beta \cdot \alpha) &=
\{\beta'_{HC} \circ \alpha'_{HC} \circ F'\beta_{C} \circ F'\alpha_C\}_{C \in {\cal C}} \\
&= \{\beta'_{HC} \circ G'\beta_{C} \circ \alpha'_{GC} \circ F'\alpha_C\}_{C \in {\cal C}} \\
&= (\beta' \circ \beta) \cdot (\alpha' \circ \alpha).\qedhere
\end{aligned}\]
#+END_proof

** Constructions on categories
Before continuing our study of functors and universal properties, we
provide some constructions and examples of categories we will need in
the future.  In particular, we consider some variations on the definition
of functors and we use them to construct new categories.

*** Product categories
**** Product category                                             :ignore:
The *product category* (see cite:eilenberg45) of two categories ${\cal C}$ and ${\cal D}$,
denoted by ${\cal C} \times {\cal D}$, is their product object in the category $\mathsf{Cat}$. Explicitly,
it is given by

  * objects of the form $\left\langle C,D \right\rangle$, where $C \in {\cal C}$ and $D \in {\cal D}$;
  * and morphisms of the form $\pair{f,g} : \pair{C,D} \to \pair{C',D'}$, where $f \colon C \to C'$ and
    $g \colon D \to D'$ are morphisms in their respective categories.

The identity morphism of any object $\pair{C,D}$ is $\pair{\id_C, \id_D}$, and composition is
defined componentwise as $\pair{f',g'} \circ \pair{f,g} = \pair{f' \circ f,g' \circ g}$.
The definition of the product also provides /projection functors/ $P\colon {\cal C} \times {\cal D} \to {\cal C}$
and $Q : {\cal C} \times {\cal D} \to {\cal D}$ on arrows as $P\pair{f,g} = f$ and $Q\pair{f,g} = g$.
\\

**** Product of functors                                          :ignore:
The *product functor* of two functors $F\colon {\cal C} \to {\cal C}'$ and $G \colon {\cal D} \to {\cal D}'$ 
is the unique functor $F \times G \colon {\cal C} \times {\cal D} \to {\cal C}' \times {\cal D}'$ making the
following diagram commute.
\[\begin{tikzcd}
{\cal C} \dar{F} &
{\cal C} \times {\cal D}  \rar{Q}\lar[swap]{P} \dar[dashed]{F \times G}&
{\cal D} \dar{G} \\
{\cal C}' &
{\cal C}' \times {\cal D}' \rar[swap]{Q'}\lar{P'}&
{\cal D}'
\end{tikzcd}\]
Explicitly, it acts on arrows as $(F \times G)\pair{f,g} = \pair{Ff,Gg}$.
In this sense, the $\times$ operation could be seen as a /functor/ /with/
/two arguments/ acting on objects and morphisms of the $\Cats$ category.
We now formalize this idea of a functor in two variables.
\\

**** Bifunctors                                                   :ignore:
*Bifunctors* are functors from a product category, but they can also be
regarded as functors on two variables. As we will show in the following
proposition, they are completely determined by the two families of functors
we obtain when we fix any of the arguments. We will also study a
characterization of naturality between these functors.

#+ATTR_LATEX: :options [Conditions for the existence of bifunctors]
#+BEGIN_proposition
<<prop-existence-bifunctor>>
Let ${\cal B}, {\cal C}, {\cal D}$ categories with two families of functors
\[
\{F_C \colon {\cal B} \to {\cal D}\}_{C \in {\cal C}}
\quad\text{ and }\quad
\{G_B \colon {\cal C} \to {\cal D}\}_{B \in {\cal B}},
\]
such that $G_B(C) = F_C(B)$ for all $B,C$.
A bifunctor $S \colon {\cal B} \times {\cal C} \to {\cal D}$ such that $S(-,C) = F_C$ and $S(B,-) = G_B$ 
for all $B \in {\cal B}$ and $C \in {\cal C}$ exists if and only if for every $f \colon B \to B'$ and $g \colon C \to C'$,
\[
G_{B'}g \circ F_Cf = F_{C'}f \circ G_Bg.
\]
#+END_proposition
#+BEGIN_proof
If the equality holds, the bifunctor can be defined as $S(b,c) = G_B(c) = F_C(b)$
in objects and as $S(f,g) = G_{B'}g \circ F_Cf = F_{C'}f \circ G_Bg$ on morphisms. This
bifunctor preserves identities, as $S(\id,\id) = G_B(\id) \circ F_C(\id) = \id \circ \id = \id$;
and it preserves composition, as, for any morphisms $f,f',g,g'$ with suitable
domain and codomain, we have
\[
S(f',g') \circ S(f,g) =
Gg' \circ Ff' \circ Gg \circ Ff =
Gg' \circ Gg \circ Ff' \circ Ff =
S(f'\circ f, g' \circ g).
\]
On the other hand, if a bifunctor exists, the condition is satisfied because
\[\begin{aligned}
G_{B'}(g) \circ F_C(f) 
&= S(\id_{B'}, g) \circ S(f, \id_C)
= S(\id_{B'} \circ f, g \circ \id_C) \\
&= S(f \circ \id_B, \id_{C'} \circ g)
= S(f,\id_{C'}) \circ S(\id_B,g) \\
&= F_{C'}(f) \circ G_B(f).\qedhere
\end{aligned}\]
#+END_proof

**** Naturality for bifunctors                                    :ignore:
#+ATTR_LATEX: :options [Naturality for bifunctors]
#+BEGIN_proposition
<<prop-naturality-bifunctor>>
Naturality on both components of a bifunctor is equivalent to naturality
in the usual sense. Given $S,S'$ bifunctors, the family $\alpha_{B,C} \colon S(B,C) \to S'(B,C)$ is a natural 
transformation if and only if $\alpha_{B,C}$ is natural in $B$ for each $C$ and natural
in $C$ for each $B$.
#+END_proposition
#+BEGIN_proof
If $\alpha$ is natural, in particular, we can use the identities to prove that
it must be natural in its two components.
\[\begin{tikzcd}
S(B,C) \rar{\alpha}\dar[swap]{S\pair{f,\id}} & 
S'(B,C) \dar{S'\pair{f,\id}} &&
S(B,C) \rar{\alpha} \dar[swap]{S\pair{\id,g}} &
S'(B,C) \dar{S'\pair{\id,g}} \\
S(B',C) \rar{\alpha} &
S'(B',C) &&
S(B,C') \rar{\alpha} &
S'(B,C')
\end{tikzcd}\]
If both components of $\alpha$ are natural, the naturality of the natural
transformation follows from the composition of these two squares
\[\begin{tikzcd}
S(B,C)   \rar{\alpha} \dar[swap]{S\pair{f,\id}} &
S'(B,C)  \dar{S'\pair{f,\id}} \\
S(B',C)  \rar{\alpha} \dar[swap]{S\pair{\id,g}} &
S'(B',C) \dar{S'\pair{\id,g}} \\
S(B',C') \rar{\alpha}  &
S'(B',C')
\end{tikzcd}\]
where each square is commutative by the naturality of each component
of $\alpha$.
#+END_proof

*** Opposite categories and contravariant functors
For many constructions in categories, it makes sense to consider how
the process of /reverting all the arrows/ yields a new construction.
\\

**** Opposite category                                            :ignore:
The *opposite category* ${\cal C}^{op}$ of a category ${\cal C}$ is a category with the
same objects as ${\cal C}$ but with all its arrows reversed. That is, for each
morphism $f : A \to B$, there exists a morphism $f^{op} : B \to A$ in ${\cal C}^{op}$.
Composition is defined as $f^{op} \circ g^{op} = (g\circ f)^{op}$,
exactly when the composite $g \circ f$ is defined in ${\cal C}$.

Reversing all the arrows is a process that directly translates every
property of the category into its /dual/ property. A morphism $f$ is a
monomorphism if and only if $f^{op}$ is an epimorphism; a terminal object
in ${\cal C}$ is an initial object in ${\cal C}^{op}$ and a right inverse becomes a left
inverse on the opposite category. This process is also an /involution/,
where $(f^{op})^{op}$ can be seen as $f$, and $({\cal C}^{op})^{op}$ is trivially isomorphic to ${\cal C}$.

**** Contravariant functors                                       :ignore:
#+attr_latex: :options [Contravariant functor]
#+begin_definition
A *contravariant* functor from ${\cal C}$ to ${\cal D}$ is a functor from the opposite category,
that is, $F \colon {\cal C}^{op}\to {\cal D}$. Non-contravariant functors are often called *covariant*
functors, to emphasize the difference.
#+end_definition

#+ATTR_LATEX: :options [Hom functors]
#+BEGIN_exampleth
In a locally small category ${\cal C}$, the *Hom-functor* is the bifunctor
$\hom \colon {\cal C}^{op} \times {\cal C} \to \Sets$, defined as $\hom(A,B)$ for any two objects $A,B \in {\cal C}$.
Given $f \colon A \to A'$ and $g \colon B \to B'$, this functor is defined on any
$p \in \hom(A,B)$ as postcomposition and precomposition, $\hom(f,g)(p) = f \circ p \circ g \in \hom(A',B')$.
Partial applications of the functor give rise to

 * $\hom(A,-)$, a covariant functor for any fixed $A \in {\cal C}$ that maps $g \colon B \to B'$
   to the precomposition $- \circ g \colon \hom(A,B) \to \hom(A,B')$;

 * $\hom(-,B)$, a contravariant functor for any fixed $B \in {\cal C}$ that maps $f \colon A \to A'$
   to the postcomposition $f\circ - \colon \hom(A',B) \to \hom(A,B)$.

Note that this is a well-defined bifunctor by virtue of Proposition
[[prop-existence-bifunctor]] and the fact that $(-\circ g)\circ(f\circ -) = (f\circ -)\circ(-\circ g)$
by associativity. This kind of functor, contravariant on the first variable
and covariant on the second, is usually called a *profunctor*.
#+END_exampleth

*** Functor categories
Given two categories ${\cal B},{\cal C}$, the *functor category* ${\cal B}^{{\cal C}}$ has all functors
from ${\cal C}$ to ${\cal B}$ as objects and natural transformations between them as morphisms.
If we consider the category of small categories $\Cats$, there is
a hom-profunctor $-^{-} \colon \Cats^{op} \times \Cats \to \Cats$ sending any two categories
${\cal B}$ and ${\cal C}$ to their functor category ${\cal B}^{{\cal C}}$. Many mathematical constructions
are examples of functor catgeories.

**** Category of graphs                                           :ignore:
In cite:lawvere09, multiple examples of usual mathematical
constructions in terms of functor categories can be found.
Graphs, for instance, can be seen as functors; and graphs
homomorphisms as the natural transformations between them.

#+ATTR_LATEX: :options [Graphs as functors]
#+BEGIN_exampleth
<<example-functor-graphs>>
We consider the category given by two objects and two non-identity
morphisms,
\[\begin{tikzcd}
\cdot
\rar[bend left]
\rar[bend right,swap] & 
\cdot
\end{tikzcd}\]
usually called $\downarrow\downarrow$. To define a functor from this category to $\Sets$
amounts to choose two sets $E,V$ (not necessarily different) called
the set of /edges/ and the set of /vertices/; and two functions $s,t \colon E \to V$,
called /source/ and /target/. That is, our usual definition of directed
multigraph,
\[\begin{tikzcd}
E
\rar[bend left]{s}
\rar[bend right,swap]{t} & 
V
\end{tikzcd}\]
can be seen as an object in the category $\Sets^{\downarrow\downarrow}$. Note how a natural transformation
between two graphs $(E,V)$ and $(E',V')$ is a pair of morphisms $\alpha_E \colon E \to E'$
and $\alpha_V \colon V \to V'$ such that $s \circ \alpha_E = \alpha_V \circ s$ and $t \circ \alpha_E = \alpha_V \circ t$.
This provides a convenient notion of graph homomorphism: a pair of morphisms
preserving the incidence of edges. We can call $\mathtt{Graph}$ to this functor category.
#+END_exampleth

**** Dynamical systems and continuous dynamical systems           :ignore:
#+ATTR_LATEX: :options [Dynamical systems as functors]
#+BEGIN_exampleth
<<example-dynamical>>
A set endowed with an endomorphism $(S,\alpha)$ can be regarded as a /dynamical/
/system/ in an informal way. Each state of the system is represented
by an element of the set and and the transition function is represented
by the endomorphism. That is, if we start at an initial state $s \in S$ and
the transition function is given by $\alpha \colon S \to S$, the evolution of the
system will be given by
\[
s,\ \alpha(s),\ \alpha(\alpha(s)),\ \alpha(\alpha(\alpha(s))),\dots
\]
and we could say that it evolves discretely over time, being $\alpha^t(s)$ the
state of the system at the instant $t$.

This structure can be described as a functor from the monoid of natural
numbers with addition, seen as a category.  Note that any functor $D\colon\mathbb{N} \to \Set$ has to choose a
set $S$, and an image for the morphism $(1+) : \mathbb{N} \to \mathbb{N}$, of the form $\alpha \colon S \to S$.
The image of any natural number $n$ is now determined by the image of $(1+)$
because the functor must preserve composition and identities; if $D(1+) = \alpha$,
it follows that $D(t+) = \alpha^t$, where $\alpha^0 = \id$.

Once the structure has been described as a functor, the homomorphisms
preserving this kind of structure can be described as natural
transformations. A natural transformation between two functors
$D,D' \colon \mathbb{N} \to \Set$ describing two dynamic systems $(S,\alpha), (T,\beta)$ is given
by a function $f \colon S \to T$ such that the following diagram commutes
\[\begin{tikzcd}
S\rar{f} \dar[swap]{\alpha^n} & 
T\dar{\beta^n} \\
S\rar{f} &
T
\end{tikzcd}\]
that is, $f \circ \alpha = \beta \circ f$. A natural notion of homomorphism has arisen from
the categorical interpretation of the structure.

A further generalization is now possible: if we want to consider
continuously-evolving dynamical systems, we can define functors from the
monoid of real numbers under adition, that is, functors $\mathbb{R} \to \Set$.
Note that these functors are given by a set $S$ and a family
of morphisms $\{\alpha_r\}_{r \in \mathbb{R}}$ such that $\alpha_r \circ \alpha_s = \alpha_{r+s}$ 
for all $r,s \in \mathbb{R}$. This example is discussed in cite:lawvere09.
#+END_exampleth

** Universality and limits
*** Universal arrows
A *universal property* is commonly given in mathematics by some
conditions of existence and uniqueness on morphisms, representing some
sort of natural isomorphism. They can be used to define certain
constructions up to isomorphism and to operate with them in an
abstract setting. We will formally introduce universal properties
using /universal arrows/ from an object $C$ to a functor $G$; the
property of these arrows is that every arrow of the form $C \to GD$
will factor uniquely through the universal arrow.

\\

**** Universal arrow                                              :ignore:
A *universal arrow* from $C \in {\cal C}$ to $G \colon {\cal D} \to {\cal C}$ is a morphism $u \colon C \to GD_0$
such that for every $g \colon C \to GD$ exists a unique morphism $f \colon D_0 \to D$
making the following diagram commute.
\[\begin{tikzcd}
& 
GD &
D \\
C \rar[swap]{u}\urar{g} &
GD_0 \uar[swap,dashed]{Gf} & 
D_0 \uar[dashed,swap]{\exists! f}
\end{tikzcd}\]
Note how an universal arrow is, equivalently, the initial object of
the comma category $(C \downarrow G)$. Thus, universal arrows must be unique up
to isomorphism.

**** Universality in terms of hom-sets                            :ignore:
#+attr_latex: :options [Universality in terms of hom-sets]
#+begin_proposition
<<prop-universality-homsets>>
The arrow $u \colon C \to GD_0$ is universal if and only if $f \mapsto Gf \circ u$ is a bijection
$\hom(D_0,D) \cong \hom(C,GD)$ natural in $D$. Any natural bijection of this
kind is determined by a unique universal arrow.
#+end_proposition
#+begin_proof
On the one hand, given an universal arrow, bijectivity follows
from the definition of universal arrow; and naturality follows from
the fact that $G(g\circ f)\circ u = Gg \circ Gf \circ u$.
On the other hand, given a bijection $\varphi$, we define $u = \varphi(\id_{D_0})$.
By naturality, we have the bijection $\varphi(f) = Gf \circ u$; and every arrow
can be written in this form.
#+end_proof

**** Couniversal arrows                                           :ignore:
The categorical dual of an universal arrow from an object to a functor
is the notion of universal arrow from a functor to an object. Note how,
in this case, we avoid the name /couniversal arrow/; as both arrows are
representing what we usually call a /universal property/.

A /dual/ *universal arrow* from $G$ to $C$ is a morphism $v \colon GD_0 \to C$ such that
for every $g \colon GD \to C$ exists a unique morphism $f \colon D \to D_0$ making the
following diagram commute.
\[\begin{tikzcd}
D\dar[dashed,swap]{\exists! f} & GD \dar[swap,dashed]{Sf}\drar{g} & \\
D_0 & GD_0 \rar[swap]{v} & C
\end{tikzcd}\]

# TODO Universal from a functor to another
**** TODO Examples
# TODO Equivalence relations
*** Representability
A *representation* of a functor from a locally small category to the
category of sets, $K \colon {\cal D} \to \Sets$, is a natural
isomorphism $\psi\colon \hom_{{\cal D}}(r,-) \cong K$ making it
isomorphic to a partially applied hom-functor. A functor is
/representable/ if it has a representation and the object $r$ used
in the representation is called its /representing object/.

#+attr_latex: :options [Representations in terms of universal arrows]
#+begin_proposition
If $u \colon 1 \to Kr$ is a universal arrow for a functor $K\colon {\cal D} \to \Sets$, then
the map $f \mapsto Kf(u(\ast))$ is a representation. Every representation is
obtained in this way.
#+end_proposition
#+begin_proof
There is a trivial natural isomorphism $\hom_{\Set}(1, X) \tonat X$ for each $X$; in particular
$\hom_{\Set}(1, K-) \tonat K-$ is a natural isomorphism. Every representation is then
built as
\[
\hom_{{\cal D}}(r,-) \cong \hom_{\Set}(1,K-) \cong K,
\]
using universality of $u$. Moreover, every natural isomorphism $\hom_{{\cal D}}(r,-) \cong K$
determines an natural isomorphism $\hom_{{\cal D}}(r,-) \cong \hom_{\Set}(1,K-)$, which in
turn determines a universal arrow by Proposition [[prop-universality-homsets]].
#+end_proof
# TODO: Check this proof

*** Yoneda Lemma
**** Motivation                                                                          :ignore:
The Yoneda lemma is one of the first results in pure category theory.
It allows us to embed any small category into a functor category over
the category of sets. It will be very useful when studying presheaves and
algebraic theories (see Section [[sec-lawveretheories]]) to create models
of these theories.

**** Statement of the Yoneda Lemma                                                       :ignore:
#+attr_latex: :options [Yoneda Lemma]
#+begin_lemma
<<lemma-yoneda>>
For any $K\colon {\cal D} \to \Sets$ and $r \in {\cal D}$, there is a bijection
$y \colon \mathrm{Nat}(\hom_{{\cal D}}(r,-), K) \cong Kr$
sending any natural transformation $\alpha \colon \hom_{{\cal D}}(r,-) \tonat K$ to 
its image on the identity, $\alpha_r(\id_r)$.
#+end_lemma
#+begin_proof
The complete natural transformation $\alpha$ is determined by $\alpha_r(\id_r)$.
By naturality, given any $f \colon r \to s$, it must be the case that
$\alpha_s(f) = Kf(\alpha_r(\id_r))$.
\[\begin{tikzcd}[row sep={8mm,between origins},column sep={12mm,between origins}]
\hom(r,r) \arrow{rrrr}{\alpha_r} \arrow[swap]{ddd}{f \circ -}
    & & & & Kr \arrow{ddd}{Kf} \\  
    & \id_r \arrow[rr, |->] \arrow[d, |->] & & \alpha_r(\id_r) \arrow[d, |->] & \\[1cm]
    & f \arrow[rr, |->] & & \alpha_s(f) \\
\hom(r,s) \arrow[swap]{rrrr}{\alpha_s} & & & & Ks\\  
\end{tikzcd}\qedhere\]
#+end_proof

**** Natural transformations between representable functors                              :ignore:
#+attr_latex: :options [Characterization of natural transformations between representable functors]
#+begin_corollary
Given $r,s \in {\cal D}$, any natural transformation $\hom(r,-) \tonat \hom(s,-)$ is
of the form $- \circ h$ for a unique morphism $h\colon s \to r$.
#+end_corollary
#+begin_proof
Using Yoneda Lemma (Lemma [[lemma-yoneda]]), we know that
\[
\mathrm{Nat}(\hom_{\cal D}(r,-), \hom_{\cal D}(s,-)) \cong \hom_{\cal D}(s,r),
\]
sending the natural transformation to a morphism $\alpha(id_r) = h \colon s \to r$. The
rest of the natural transformation is determined as $- \circ h$ by naturality.
#+end_proof

**** Naturality of the Yoneda Lemma                                                      :ignore:
#+attr_latex: :options [Naturality of the Yoneda Lemma]
#+begin_proposition
<<lemma-yoneda-natural>>
The bijection on the Yoneda Lemma (Lemma [[lemma-yoneda]]),
$y \colon \mathrm{Nat}(\hom_{{\cal D}}(r,-), K) \cong Kr$,
is a natural isomorphism between two functors $\Sets^{\cal D} \times {\cal D} \to \Sets$.
#+end_proposition
#+begin_proof
We define $N \colon \Sets^{\cal D} \times {\cal D} \to \Sets$ on objects as $N\pair{r,K} = \Nat(\hom(r,-),K)$.
Given $f \colon r \to r'$ and $F \colon K \tonat K'$, the functor is defined on morphisms as
\[
N\pair{f,F}(\alpha) =
F \circ \alpha \circ (- \circ f) \in
\Nat(\hom(r',-),K),
\]

where $\alpha \in \Nat(\hom(r,-),K)$. We define $E \colon \Sets^{\cal D} \times {\cal D} \to \Sets$ on
objects as $E\pair{r,K} = Kr$. Given $f \colon r \to r'$ and $F \colon K \tonat K'$, the
functor is defined on morphisms as
\[
E\pair{f,F}(a) = F(Kf(a)) = K'f(Fa) \in K'r',
\]
where $a \in Kr$, and the equality holds because of the naturality
of $F$. The naturality of $y$ is equivalent to the commutativity of the
following diagram
\[\begin{tikzcd}[column sep=huge]
\Nat(\hom(r,-),K) \rar{y}\dar[swap]{N\pair{f,F}}&
Kr \dar{E\pair{f,F}} \\
\Nat(\hom(r',-),K') \rar{y} &
K'r'
\end{tikzcd}\]
where, given any $\alpha \in \Nat(\hom(r,-),K)$, it follows from naturality
of $\alpha$ that
\[\begin{aligned}
y\big(N\pair{f,F}(\alpha)\big)
&= y\big (F \circ \alpha \circ (- \circ f) \big)
= F \circ \alpha \circ (- \circ f) (\id_{r'})
= F(\alpha(f)) \\
&= F(\alpha(\id_{r'} \circ f))
= F(Kf(\alpha_r(\id_r)))
= E\pair{f,F}\alpha_r(\id_{r}) \\
&= E\pair{f,F}\big(y (\alpha)\big).\qedhere
\end{aligned}\]
#+end_proof

**** Yoneda functor                                                                      :ignore:
#+begin_definition
<<def-yoneda-functor>>
In the conditions of the Yoneda Lemma (Lemma [[lemma-yoneda]]) the *Yoneda functor*,
$Y \colon {\cal D}^{op} \to \Sets^{{\cal D}}$, is defined with the arrow function
\[
\left(f \colon A \to B\right) \mapsto 
\Big(\hom_{\cal D}(f,-) \colon \hom_{\cal D}(B,-) \to \hom_{\cal D}(A,-)\Big).
\]
It can be also written as $Y\colon {\cal D} \to \Sets^{{\cal D}^{op}}$. By the Yoneda Lemma, there
is a bijection $y \colon \Nat(\hom(B,-), \hom(A,-)) \cong \hom(A,B)$ given by
$Y(\hom(f,-)) = f$; making the Yoneda functor full and faithful.
#+end_definition

***** OLD Full and faithful as proposition                                              :ignore:
#+begin_proposition
The Yoneda functor is full and faithful.
#+end_proposition
#+begin_proof
By Yoneda Lemma (Lemma [[lemma-yoneda]]), we know that
\[
y \colon \Nat(\hom(r,-), \hom(s,-)) \cong \hom(s,r)
\]
is a bijection, where
#+end_proof
# TODO: The Yoneda functor is a currying of the hom functor.

*** Limits
# TODO: Limpiar toda esta parte
**** Motivation: products                                         :ignore:
In the definition of product, we chose two objects of the category, we
considered all possible /cones/ over two objects and we picked the
universal one.
\[\begin{tikzcd}[column sep=tiny]
&&&&& 
D \dar[dashed]{\exists!} \ar[bend left,color=myred]{ddr}\ar[bend right,swap,color=myred]{ddl} &\\& 
C \drar[color=myred]\dlar[color=myred] &&&&
A \times B \drar[color=myred]\dlar[color=myred] & \\
A && 
B &\phantom{gap}& 
A && 
B
\end{tikzcd}\]
In this previous commutative diagram, $C$ is a cone and $A \times B$
is the universal one: every cone factorizes through it. In this
particular case, the base of each cone is given by two objects; or, in
other words, by the image of a functor from the discrete category with
only two objects, called the /index category/.

We will be able to create new constructions on categories by formalizing
the notion of cone and generalizing to arbitrary bases, given as functors
from arbitrary index categories. Constant functors are the first step into
formalizing the notion of /cone/.

**** Constant functors                                            :ignore:
#+ATTR_LATEX: :options [Constant functor]
#+BEGIN_definition
The *constant functor* $\Delta \colon {\cal C} \to {\cal C}^{{\cal J}}$ sends each object $c \in {\cal C}$ to a
constant functor $\Delta c \colon {\cal J} \to {\cal C}$ defined as

 * the constantly-$c$ function for objects, $\Delta(j) = c$;
 * and the constantly-$\id_c$ function for morphisms, $\Delta(f) = \id_{c}$.

The constant functor sends a morphism $g \colon c \to c'$ to a natural
transformation $\Delta g \colon \Delta c \to \Delta c'$ whose components are all $g$.
#+END_definition

We could say that $\Delta c$ compresses the whole category ${\cal J}$ into $c$. A
natural transformation from this functor to some other $F \colon {\cal J} \to {\cal C}$
should be regarded as a */\red{cone}/* from the object $c$ to a copy
of ${\cal J}$ inside the category ${\cal C}$; as the following diagram exemplifies
\[\begin{tikzcd}[column sep=tiny, row sep=tiny]
&&& &&& & c \ar[color=myred]{dd}\ar[bend left, color=myred]{ddr}\ar[bend right, color=myred]{dddl}\ar[bend left, color=myred]{dddrr} &&\\
&\phantom{gap}&& &&& & \phantom{gap} &&\\
& \cdot \ar{ld}\ar{r}\ar{drr} & \cdot \ar{dr}  & \ar[Rightarrow, shorten <= 3mm, shorten >= 14mm]{uurrrr}[xshift=-3mm]{\Delta}  &&&
& \cdot \ar{ld}\ar{r}\ar{drr} & \cdot \ar{dr} & \\
\cdot \arrow{rrr}[description, yshift=-5mm]{\big{\cal J}} &&& 
\cdot \ar[Rightarrow, yshift=3mm,swap, shorten <= 2mm, shorten >= 2mm]{rrr}{F}
&\phantom{gap}&&
\cdot \arrow{rrr}[description, yshift=-5mm]{\big{F \cal J}}  &   &   & \cdot \\
%&{\cal J}&& &&& &F{\cal J}&&
\end{tikzcd}\]
The components of the natural transformation appear highlighted in
the diagram. The naturality of the transformation implies that each
triangle
\[\begin{tikzcd}[column sep=tiny,row sep=small]
&\cdot
\drar[color=myred, shorten >= -1.5mm, shorten <= -2mm]
\dlar[color=myred, shorten >= -1.5mm, shorten <= -2mm] &\\
\cdot 
\ar[shorten >= -1mm, shorten <= -1mm]{rr} &&
\cdot
\end{tikzcd}\]
on that cone must be commutative. Thus, natural transformations are
a way to recover all the information of an arbitrary /*index category*/ ${\cal J}$ that
was encoded in $c$ by the constant functor. As we did with products,
we want to find the cone that best encodes that information; a universal
cone, such that every other cone factorizes through it. Diagramatically
an $r$ such that, for each $d$,
\[\begin{tikzcd}[column sep=tiny, row sep=tiny]
&d 
\ar[color=myred,bend right]{dddd}
\ar[bend left, color=myred]{ddddr}
\ar[bend right, color=myred]{dddddl}
\ar[bend left, color=myred]{dddddrr}
\ar[dashed]{dd}{\exists!} &&\\
&&\phantom{d}&\\
& r \ar[color=myred]{dd}\ar[bend left, color=myred]{ddr}\ar[bend right, color=myred]{dddl}\ar[bend left, color=myred]{dddrr} &&\\
& \phantom{gap} &&\\
& \cdot \ar{ld}\ar{r}\ar{drr} & \cdot \ar{dr} & \\
\cdot \ar{rrr} &   &   & \cdot \\
\end{tikzcd}\]
That factorization will be represented in the formal definition of
limit by a universal natural transformation between the two constant
functors.

**** Definition of limit                                          :ignore:
#+BEGIN_definition
The *limit* of a functor $F \colon {\cal J} \to {\cal C}$ is an object $r \in {\cal C}$ such that
there exists a universal arrow $v \colon \Delta r \tonat F$ from $\Delta$ to $F$. It is
usually written as $r = \lim F$.
#+END_definition

That is, for every natural transformation $w \colon \Delta d \tonat F$, there is a unique
morphism $f \colon d \to r$ such that
\[\begin{tikzcd}
d\dar[dashed,swap]{\exists! f} & \Delta d \dar[swap,dashed]{\Delta f}\drar{w} & \\
r & \Delta r \rar[swap]{v} & F
\end{tikzcd}\]
commutes. This reflects directly on the universality of the cone we described
earlier and proves that limits are unique up to isomorphism.

By choosing different index categories, we will be able to define multiple
different constructions on categories as limits.

*** Examples of limits
**** Equalizers                                                                          :ignore:
For our first example, we will take the following category,
called $\downarrow\downarrow$ as index category,
\[\begin{tikzcd}
\cdot
\rar[bend left]
\rar[bend right] & 
\cdot
\end{tikzcd}\]
A functor $F \colon \downarrow\downarrow \to {\cal C}$ is a pair of parallel arrows in ${\cal C}$.
Limits of functors from this category are called /equalizers/.
With this definition, the *equalizer* of two parallel arrows
$f,g \colon A \to B$ is an object $\mathrm{eq}(f,g)$ with a morphism
$e \colon \mathrm{eq}(f,g) \to A$ such that $f \circ e = g \circ e$; and such that
any other object with a similar morphism factorizes uniquely
through it
\[\begin{tikzcd}[column sep=tiny]
&
D
\dar[dashed]{\exists!}
\arrow[bend right, swap, color=myred]{ddl}{e'}
\arrow[bend left, color=myred]{ddr}  &\\& 
\operatorname{eq}(f,g)
\drar[color=myred]
\dlar[swap, color=myred]{e} &\\
A 
\arrow[bend left=15]{rr}{f}
\arrow[bend right=15, swap]{rr}{g} &&
B
\end{tikzcd}\]
note how the right part of the cone is completely determined
as $f \circ e$. Because of this, equalizers can be written without
specifying it, and the diagram can be simplified to the
following one.
\[\begin{tikzcd}
\mathrm{eq}(f,g) 
\rar{e} & 
A 
\arrow[bend left=15]{r}{f}
\arrow[bend right=15, swap]{r}{g} &
B \\
D 
\ar[swap]{ur}{e'} 
\ar[dashed]{u}{\exists!} &&&
\end{tikzcd}\]

**** Equalizers in Sets                                                                  :ignore:
#+ATTR_LATEX: :options [Equalizers in the category of sets]
#+BEGIN_exampleth
The equalizer of two parallel functions $f,g \colon A \to B$ in $\Sets$ 
is $\left\{ x \in A \mid f(a) = g(a) \right\}$
with the inclusion morphism. Given any other function $h \colon D \to A$
such that $f \circ h = g \circ h$, we know that $f(h(d)) = g(h(d))$ for
any $d \in D$. Thus, $h$ can be factorized through the equalizer.
\[\begin{tikzcd}
\left\{ x \in A \mid f(a) = g(a) \right\}
\rar[hook]{i} & 
A 
\arrow[bend left=15]{r}{f}
\arrow[bend right=15, swap]{r}{g} &
B \\
D 
\ar[swap]{ur}{h} 
\ar[dashed]{u}{\exists!} &&&
\end{tikzcd}\]
#+END_exampleth

**** Kernels                                                                             :ignore:
#+ATTR_LATEX: :options [Kernels]
#+BEGIN_exampleth
In the category of abelian groups, $\mathrm{ker}(f)$, the kernel of a function $f$,
is the equalizer of the functions $f \colon G \to H$ and $z \colon G \to H$, where
$z$ is the function that sends each element to the zero element of $H$.
The same notion of kernel can be defined in the category of $R\text{-Modules}$,
for an arbitrary ring $R$.
#+END_exampleth

**** Pullbacks                                                                           :ignore:
*Pullbacks* are defined as limits whose index category is $\cdot \to \cdot \gets \cdot$.
Any functor from that category is a pair of arrows with a common
codomain; and the pullback is the universal cone over them.
\[\begin{tikzcd}
& D
\arrow[bend right,swap,color=myred]{ddl}{p'}
\arrow[bend left,color=myred]{ddr}{q'}
\arrow[bend right,color=myred]{dd}
\arrow[dashed]{d}{\exists!} &\\
& A
\drar[bend left,swap,color=myred]{q}
\dlar[bend right,color=myred]{p}
\arrow[color=myred]{d} & \\
X\rar[swap]{f} & Z & Y\lar{g} \\
\end{tikzcd}\]
Again, the central arrow of the diagram is determined as
$f \circ q = g \circ p$; so it can be ommited in the diagram. The usual
definition of a pullback for two morphisms $f \colon X \to Z$ and
$g \colon Y \to Z$ is the universal pair of morphisms $p \colon A \to X$ and $q \colon A \to Y$
such that $f \circ q = g \circ p$, that is, given any pair of morphisms
$p' \colon D \to X$ and $q' \colon D \to Y$, there exists a unique $u \colon D \to A$ making
the diagram commute.  Usually we write the pullback object as $X \times_Z Y$
and we write this property diagramatically as
\[\begin{tikzcd}
D
\ar[dashed]{dr}{\exists! u} 
\ar[bend left]{drr}{p'} 
\ar[swap,bend right]{ddr}{q'} &&\\
& X \times_z Y
\dar[swap]{q}
\rar{p} &
X
\dar{f} \\
& Y
\rar[swap]{g} &
Z
\end{tikzcd}\]
The square in this diagram is usually called a /pullback square/,
and the pullback object is sometimes called a /fibered product/.
Pullbacks will be a central notion when developing semantics for
dependent types in Section [[sec-locallydependent]].

# TODO: Example of pullback
# TODO: Equalizers are a particular example of pullbacks

**** Pullbacks in Sets                                                                   :ignore:
#+ATTR_LATEX: :options [Pullbacks in the category of sets]
#+BEGIN_exampleth
Given two functions $f \colon A \to C$ and $g \colon B \to C$ in the category $\Set$,
their pullback is given by the subset of the catesian product $A \times B$
determined by those pairs of elements whose two images under $f$ and $g$
coincide. That is, $A \times_C B = \left\{ (a,b) \in A \times B \mid f(a) = g(b) \right\}$ with
the usual projections. Note that any function making the pullback
square commute factorizes uniquely though this set.
#+END_exampleth

**** TODO Arbitrary products                                                             :ignore:
**** TODO Powers                                                                         :ignore:
**** TODO Posets
*** Colimits
# TODO: Ahorrarse los colimits por dualidad
**** Cocones                                                      :ignore:
A colimit is the dual notion of a limit. We could consider 
cocones to be the dual of cones and pick the universal one.
Once an index category ${\cal J}$ and a base category ${\cal C}$ are fixed,
a /cocone/ is a natural transformation from a functor on the
base category to a constant functor. Diagramatically,
\[\begin{tikzcd}[column sep=tiny, row sep=tiny]
&&& &&& & c &&\\
&\phantom{gap}&& &&& & \phantom{gap} &&\\
& \cdot \ar{ld}\ar{r}\ar{drr} & \cdot \ar{dr}  & \ar[Rightarrow, shorten <= 3mm, shorten >= 14mm]{uurrrr}[xshift=-3mm]{\Delta}  &&&
& \cdot \ar{ld}\ar{r}\ar{drr}\ar[color=myblue]{uu} & \cdot \ar{dr} \ar[color=myblue,bend right]{uul} & \\
\cdot \arrow{rrr}[description, yshift=-5mm]{\big{\cal J}} &&& 
\cdot \ar[Rightarrow, yshift=3mm,swap, shorten <= 2mm, shorten >= 2mm]{rrr}{F}
&\phantom{gap}&&
\cdot \arrow[color=myblue, bend left]{uuur} \arrow{rrr}[description, yshift=-5mm]{\big{F \cal J}} &&&
\cdot \arrow[color=myblue, bend right]{uuull}\\
\end{tikzcd}\]
is an example of a cocone, and the universal one would be the
$r$, such that, for each cone $d$,
\[\begin{tikzcd}[column sep=tiny, row sep=tiny]
&d  &&\\
&&\phantom{d}&\\
& r \ar[dashed,swap]{uu}{\exists!}
&&\\
& \phantom{gap} &&\\
& \cdot 
\ar{ld}\ar{r}\ar{drr} 
\ar[color=myblue,bend left]{uuuu}
\ar[color=myblue]{uu}&
\cdot \ar{dr} 
\ar[bend right, color=myblue]{uuuul} \ar[color=myblue,bend right]{uul}& \\
\cdot \ar{rrr} 
\ar[bend left, color=myblue]{uuuuur}
\ar[bend left, color=myblue]{uuur} &&& 
\cdot
\ar[bend right, color=myblue]{uuull}
\ar[bend right, color=myblue]{uuuuull} \\
\end{tikzcd}\]
and naturality implies that each triangle of the following form commutes.
\[\begin{tikzcd}[column sep=tiny,row sep=small]
&\cdot &\\
\cdot
\ar[color=myblue, shorten >= -1.5mm, shorten <= -2mm]{ur}
\ar[shorten >= -1mm, shorten <= -1mm]{rr} &&
\cdot
\ar[color=myblue, shorten >= -1.5mm, shorten <= -2mm]{ul}
\end{tikzcd}\]

**** Definition of colimits                                       :ignore:
#+begin_definition
The *colimit* of a functor $F \colon J \to {\cal C}$ is an object $r \in {\cal C}$ such that there exists
a universal arrow $u \colon F \tonat \Delta r$ from $F$ to $\Delta$. It is usually written as $r = \Colimit F$.
#+end_definition

That is, for every natural transformation $w \colon F \tonat \Delta d$, there is a unique
morphism $f \colon r \to d$ such that
\[\begin{tikzcd}
d & \Delta d  & \\
r\uar[dashed]{\exists! f} &
\Delta r \uar[dashed]{\Delta f} &
F \lar{v}\ular[swap]{w}
\end{tikzcd}\]
commutes. This reflects directly on the universality of the cocone we described
earlier and proves that colimits are unique up to isomorphism.

*** Examples of colimits
**** Coequalizers                                                 :ignore:
*Coequalizers* are the dual of /equalizers/; colimits of functors
from $\downarrow\downarrow$. The coequalizer of two parallel arrows is an object
$\mathrm{coeq}(f,g)$ with a morphism $e \colon b \to \mathrm{coeq}(f,g)$ such that $e \circ f = e \circ g$;
and such that any other object with a similar morphism factorizes uniquely
through it.
\[\begin{tikzcd}[column sep=tiny]
&
d &\\& 
\operatorname{coeq}(f,g)
\uar[dashed]{\exists!} &\\
a
\ar[bend left, color=myblue, swap]{uur}
\ar[color=myblue]{ur}
\arrow[bend left=15]{rr}{f}
\arrow[bend right=15, swap]{rr}{g} &&
b
\ar[color=myblue, swap]{ul}{e}
\ar[color=myblue, bend right, swap]{uul}{e'}
\end{tikzcd}\]
As the arrows on the right of the cocone are completely determined by
the fact that the diagram must be commutative, we can simplify the diagram
as follows.
\[\begin{tikzcd}
a 
\ar[bend left=15]{r}{f}
\ar[bend right=15, swap]{r}{g} &
b
\ar{r}{e}
\ar[swap]{dr}{e'}&
\mathrm{coeq}(f,g) \ar[dashed]{d}{\exists!} \\
&&
d 
\end{tikzcd}\]

#+ATTR_LATEX: :options [Coequalizers in Sets]
#+BEGIN_exampleth
The coequalizer of two parallel functions $f,g \colon A \to B$ in
$\Sets$ is $B /(\sim_{f=g})$, where $\sim_{f = g}$ is the minimal equivalence
relation for which we have $f(a) \sim g(a)$ for each $a \in A$.
Given any other function $h \colon B \to D$ such that $h(f(a)) = h(g(a))$,
the universal property precisely states that it can be factorized in a
unique way by $h' \colon B/\sim_{f=g} \to D$.
\[\begin{tikzcd}
A
\ar[bend left=15]{r}{f}
\ar[bend right=15, swap]{r}{g} &
B
\ar{r}{e}
\ar[swap]{dr}{e'}&
B/(\sim_{f=g}) \ar[dashed]{d}{\exists!} \\
&&
D 
\end{tikzcd}\]
#+END_exampleth
**** Pushouts                                                     :ignore:
*Pushouts* are the dual of pullbacks; colimits whose index category
is $\cdot \gets \cdot \to \cdot$, that is, the dual of the index category for pullbacks.
\[\begin{tikzcd}
& d
&\\
& a
\arrow[dashed,swap]{u}{\exists!} & \\
x 
\urar[bend left,color=myblue]{p}
\arrow[bend left,color=myblue]{uur}{p'} & 
z 
\lar{f}
\rar[swap]{g}
\arrow[color=myblue]{u}
\arrow[bend left,color=myblue]{uu} &
y
\ular[bend right,swap,color=myblue]{q}
\arrow[bend right,swap,color=myblue]{uul}{q'} \\
\end{tikzcd}\]
We can define the pushout of two morphisms $f \colon z \to x$ and
$g \colon z \to y$ as a pair of morphisms $p \colon x \to a$ and $q \colon y \to a$ such
that $p \circ f = q \circ g$ which are also universal, that is, given any
pair of morphisms $p' \colon x \to d$ and $q' \colon y \to d$, there exists a unique
$u \colon a \to d$ making the following diagram commute.
\[\begin{tikzcd}
z
\rar{g}
\dar[swap]{f} & 
y \dar{q}\ar[bend left]{rdd}{q'} & \\
x \rar{p}\ar[bend right,swap]{drr}{p'} &
x \amalg_z y \ar[dashed,swap]{dr}{\exists! u} & \\
& & d
\end{tikzcd}\]
The square in this diagram is usually called a 
/pushout square/, and the pullback object is sometimes called a
/fibered coproduct/.

# TODO Seifert Van-Kampen
**** TODO Arbitrary coproducts                                    :ignore:
**** TODO Copowers                                                :ignore:
**** TODO Posets                                                  :ignore:
** Adjoints, monads and algebras
*** Adjunctions
**** Definition of adjunction                                     :ignore:
An *adjunction* from categories ${\cal X}$ to ${\cal Y}$ is a pair of functors
$F\colon {\cal X} \to {\cal Y}$, $G\colon {\cal Y} \to {\cal X}$ with a bijection
$\varphi \colon \hom(FX,Y) \cong \hom(X,GY)$,
natural in both $X\in {\cal X}$ and $Y \in {\cal Y}$. We say that $F$ is /left-adjoint/ to
$G$ and that $G$ is /right-adjoint/ to $F$ and we denote this as $F \dashv G$.

Naturality of $\varphi$, by Proposition [[prop-naturality-bifunctor]], means that both
\[\begin{tikzcd}
\hom(FX,Y)
\rar{\varphi}
\dar[swap]{- \circ Fh} & 
\hom(X,GY)
\dar{- \circ h} & 
\hom(FX,Y)
\rar{\varphi}
\dar[swap]{k \circ -} &
\hom(X,GY)
\dar{Gk \circ -} \\
\hom(FX',Y) 
\rar[swap]{\varphi} &
\hom(X',GY) &
\hom(FX,Y')
\rar[swap]{\varphi} &
\hom(X,GY')
\end{tikzcd}\]
commute for every $h \colon X \to X'$ and $k \colon Y \to Y'$. That is, for every $f \colon FX \to Y$,
we have $\varphi(f) \circ h = \varphi(f \circ Fh)$ and $Gk \circ \varphi(f) = \varphi(k \circ f)$. Equivalently, $\varphi^{-1}$ is natural,
and that means that, for every $g \colon X \to GY$, we have $k \circ \varphi^{-1}(g) = \varphi^{-1}(Gk \circ g)$ and
$\varphi^{-1}(g) \circ Fh = \varphi^{-1}(g \circ h)$.

\\

**** Lawvere's notation                                           :ignore:
A different and maybe more intuitive way to write adjunctions is by
logical diagrams (see cite:lawvere309). An adjunction $F\dashv G$ can be
written as
#+latex: \\[-20pt]
\begin{prooftree}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&] FX \rar{f}\& Y \end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&] X \rar{\varphi{(f)}}\& GY \end{tikzcd}}
\end{prooftree}
to emphasize that, for each morphism $f\colon FX \to Y$, there exists a unique
morphism $\varphi(f)\colon X \to GY$; written in a way that resembles bidirectional
logical inference rules.
Naturality, in this setting, means that precomposition and postcomposition
of arrows are preserved by the /inference rule/. Given morphisms $h \colon X' \to X$
and $k \colon Y \to Y'$, we know by naturality that the composed arrows of the
following diagrams are adjoint to one another.
\begin{prooftree}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&] 
FX' \ar[bend left=45]{rr}{f \circ Fh} \rar{Fh}\& 
FX \rar{f}\& 
Y
\end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&]
X' \ar[bend right=45]{rr}[swap]{\varphi(f) \circ h} \rar[swap]{h}\& 
X \rar[swap]{\varphi(f)}\&
GY 
\end{tikzcd}}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&]
FX \ar[bend left=45]{rr}{k \circ f} \rar{f}\&
Y \rar{k}\&
Y' \end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&]
X \ar[bend right=45]{rr}[swap]{Gk \circ \varphi(f)} \rar[swap]{\varphi(f)}\&
GY \rar[swap]{Gk}\&
GY'\end{tikzcd}}
\noLine
\BIC{}
\end{prooftree}
In other words, $\varphi(f) \circ h = \varphi(f \circ Fh)$ and $Gk \circ \varphi(f) = \varphi(k \circ f)$,
as we wrote earlier.

**** Unit and counit of an adjunction                             :ignore:
In the following two propositions, we will characterize all this
information in terms of natural transformations made up of universal
arrows. Given an adjunction $F \dashv G$, we define

 * the *unit* $\eta$ as the family of morphisms $\eta_X = \varphi(\id_{FX}) \colon X \to GFX$,
   for each $X$;
 * the *counit* $\varepsilon$ as the family of morphisms $\varepsilon_Y = \varphi^{-1}(\id_{GY}) \colon FGY \to Y$,
   for each $Y$.

Diagramatically, they can be obtained by taking $Y$ to be $FX$ and $X$ to be $GY$,
respectively, in the definition of adjunction.
#+latex: \\[-20pt]
\begin{prooftree}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&] FX \rar{\id}\& FX \end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&] X \rar{\eta_{x}}\& GFX \end{tikzcd}}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&] FGY \rar{\varepsilon_{y}}\& Y \end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&] GY \rar{\id}\& GY \end{tikzcd}}
\noLine
\BIC{}
\end{prooftree}

**** Units and counits are natural transformations                                       :ignore:
#+attr_latex: :options [Units and counits are natural transformations]
#+begin_proposition
The *unit* and the *counit* are natural transformations such that

 1) for each $f \colon FX \to Y$, $\varphi(f) = Gf \circ \eta_x$;
 2) for each $g \colon X \to GY$, $\varphi^{-1}(g) = \varepsilon_y \circ Fg$.

Moreover, they follow the *triangle identities*, $G \varepsilon \circ \eta G = \id_G$ and $\varepsilon F \circ F\eta = \id_{F}$.
\[\begin{tikzcd}
G \drar[equal] \rar{\eta G} & GFG \dar{G \varepsilon} &
FGF \dar[swap]{\varepsilon F} & F \lar[swap]{F\eta} \dlar[equal] \\
& G & F &
\end{tikzcd}\]
#+end_proposition
#+BEGIN_proof
The right and left adjunct formulas are particular instances of the naturality
equations we gave in the definition of $\varphi$;

 * $Gf \circ \eta = Gf \circ \varphi(\id) = \varphi(f \circ \id) = \varphi(f)$;
 * $\varepsilon_y \circ Fg = \varphi^{-1}(\id) \circ Fg = \varphi^{-1}(\id \circ g) = \varphi^{-1}(g)$;

diagramatically,
#+latex: \\[-20pt]
\begin{prooftree}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&] 
FX \ar[bend left=45]{rr}{\varepsilon \circ Fg} \rar{Fg}\& 
FGY \rar{\varepsilon_Y}\& 
Y 
\end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&]
X \ar[bend right=45]{rr}[swap]{g} \rar[swap]{g}\& 
GY \rar[swap]{\id}\&
GY 
\end{tikzcd}}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&]
FX \ar[bend left=45]{rr}{f} \rar{\id}\&
FX \rar{f}\&
Y \end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&]
X \ar[bend right=45]{rr}[swap]{Gf \circ \eta_X} \rar[swap]{\eta_X}\&
GFX \rar[swap]{Gf}\&
GY \end{tikzcd}}
\noLine
\BIC{}
\end{prooftree}
The naturality of $\eta$ and $\varepsilon$ can be deduced again from the naturality of $\varphi$;
given any two functions $h \colon X \to X'$ and $k \colon Y \to Y'$,
# TODO: note they are in different categories, x x' y y' is the correct notation!!

 * $GFh \circ \eta_X = GFh \circ \varphi(\id_{FX}) = \varphi(Fh) = \varphi(\id_{FX'}) \circ h = \eta_{X'} \circ h$;
 * $\varepsilon_{Y'} \circ FGk = \varphi^{-1}(\id_{GY'}) \circ FGk = \varphi^{-1}(Gk) = k \circ \varphi^{-1}(\id_{GY}) = k \circ \varepsilon_Y$;

diagramatically, we can prove that the adjunct of $Fh$ is $GFh \circ \eta_X$ and $\eta_X' \circ h$
at the same time; while the adjunct of $Gk$ is $k \circ \varepsilon_Y$ and $\varepsilon_{Y'} \circ FGk$ at the same
time.
#+latex: \\[-40pt]
\begin{prooftree}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&] 
\phantom{Fx}\&
X \rar{h}\& 
Y \rar{\eta}\& 
GFY
\end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&] 
FX \rar{\id}\& 
FX \rar{Fh}\& 
FY \rar{\id}\& 
FY 
\end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&]
X \rar{\eta}\& 
GFX \rar{GFh}\&
GFY \&
\phantom{Gy}
\end{tikzcd}}

\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&] 
FGX \rar{\varepsilon} \&
X \rar{k}\& 
Y \& 
\phantom{GFy}
\end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&]
GX \rar{\id}\&
GX \rar{Gk}\&
GY \rar{\id} \&
GY
\end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&]
\phantom{Gx}\&
FGx \rar{FGk}\&
FGy \rar{\varepsilon}\&
y \end{tikzcd}}
\noLine
\BIC{}
\end{prooftree}
Finally, the triangle identities follow directly from the previous ones:
we have $\id &= \varphi(\varepsilon) = G\varepsilon \circ \eta$ and $\id &= \varphi^{-1}(\eta) = \varepsilon \circ F\eta$.
#+END_proof

**** Characterization of adjunctions                                                     :ignore:
#+attr_latex: :options [Characterization of adjunctions]
#+begin_proposition
<<prop-characterize-adjunctions>>
Each adjunction is $F \dashv G$ between categories ${\cal X}$ and ${\cal Y}$ is completely determined
by any of the following data,

 1) functors $F,G$ and $\eta\colon 1 \tonat GF$ where $\eta_X\colon X \to GFX$ is universal to $G$.
 2) functor $G$ and universals $\eta_X \colon X \to GF_0 X$, where $F_0X \in {\cal Y}$, creating a functor $F$.
 3) functors $F,G$ and $\varepsilon\colon FG \tonat 1$ where $\varepsilon_Y\colon FGY \to Y$ is universal from $F$.
 4) functor $F$ and universals $\varepsilon_Y\colon FG_0Y \to Y$,  where $G_0Y \in {\cal X}$, creating a functor $G$.
 5) functors $F,G$, with natural transformations satisfiying the triangle
    identities $G\varepsilon \circ \eta G = \id$ and $\varepsilon F \circ F\eta = \id$.
#+end_proposition
#+begin_proof
/1./ Universality of $\eta_X$ gives a isomorphism $\varphi \colon \hom(FX,Y) \cong \hom(X,GY)$ between 
the arrows in the following diagram
\[\begin{tikzcd}
& GY & Y \\
X \rar[swap]{\eta_x}\urar{f} & GFX \uar[swap,dashed]{Gg} & FX \uar[dashed,swap]{\exists! g}
\end{tikzcd}\]
defined as $\varphi(g) = Gg \circ \eta_X$. This isomorphism is natural in $X$; for every
$h \colon X' \to X$ we know by naturality of $\eta$ that $Gg \circ \eta \circ h = G(g \circ Fh) \circ \eta$.
The isomorphism is also natural in $Y$; for every $k \colon Y \to Y'$ we know by
functoriality of $G$ that $Gh\circ Gg \circ \eta = G(h \circ g) \circ \eta$.

/2./ We can define a functor $F$ on objects as $FX = F_0X$. Given any
$h \colon X \to X'$, we can use the universality of $\eta$ to define
$Fh$ as the unique arrow making this diagram commute
\[\begin{tikzcd}
& GFX' & FX' \\
X \rar[swap]{\eta_X}\urar{\eta_{X'} \circ h} & GFX \uar[swap,dashed]{GFh} &
FX \uar[dashed,swap]{\exists! Fh}
\end{tikzcd}\]
and this choice makes $F$ a functor and $\eta$ a natural transformation,
as it can be checked in the following diagrams using the existence
and uniqueness given by the universality of $\eta$ in both cases.
\[\begin{tikzcd}
&&& X'' \rar{\eta_{X''}}  & GFX''  & FX'' \\
& GFX & FX & X'  \uar{h'} \rar{\eta_{X'}}  & GFX'  \uar[swap]{GFh'}  & 
FX' \uar[dashed]{\exists! Fh'} \\
X \rar[swap]{\eta_X}\urar{\eta_{X}} & GFX \uar[swap,dashed]{\id} & 
FX \uar[dashed,swap]{\id} & 
X \rar{\eta_{X}}\uar{h} & GFX \uar[swap]{GFh} & 
FX \uar[dashed]{\exists! Fh'} \ar[dashed,swap,bend right]{uu}{\exists! F(h' \circ h)}
\end{tikzcd}\]

/3./ The proof is dual to that of /1/.

/4./ The proof is dual to that of /2/.

/5./ We can define two functions $\varphi(f) = Gf \circ \eta_X$ and $\theta(g) = \varepsilon_Y \circ Fg$.
We checked in 1 (and 3) that these functions are natural in both arguments;
now we will see that they are inverses of each other using naturality
and the triangle identities

 * $\varphi(\theta(g)) &= G\varepsilon \circ GFg \circ \eta = G\varepsilon \circ \eta \circ g = g$;
 * $\theta(\varphi(f)) = \varepsilon \circ FGf \circ F\eta = f \circ \varepsilon \circ F\eta = f$.\qedhere
#+end_proof

**** Uniqueness                                                   :ignore:
#+ATTR_LATEX: :options [Essential uniqueness of adjoints]
#+BEGIN_proposition
Two adjoints to the same functor $F,F' \dashv G$ are naturally isomorphic.
#+END_proposition
#+BEGIN_proof
Note that the two different adjunctions give two units $\eta, \eta'$, and for
each $X$ both $\eta_X \colon X \to GFX$ and $\eta_{X'} \colon X \to GF'X$ are universal arrows
from $X$ to $G$. As universal arrows are unique up to isomorphism, we
have a unique isomorphism $\theta_X \colon FX \to F'X$ such that $G\theta_X \circ \eta_X = \eta'_X$.

We know that $\theta$ is natural because there are two arrows, $\theta \circ Ff$ and 
$F'f \circ \theta$, making this universal diagram commute
\[\begin{tikzcd}
Y \rar{\eta'} & GF'Y & F'Y\\
X \rar{\eta}\uar{f} & GFX \uar[dashed,swap]{} & FX \uar[dashed]{\exists!}
\end{tikzcd}\]
because

 * $G(\theta \circ Ff) \circ \eta = G\theta \circ GFf \circ \eta = G\theta \circ \eta \circ f = \eta' \circ f$;
 * $G(F'f \circ \theta) \circ \eta = GF'f \circ G\theta \circ \eta = GF'f \circ \eta' = \eta' \circ f$;

thus, they must be equal, $\theta \circ Ff = F'f \circ \theta$.
#+END_proof

# TODO: Proof using Yoneda
**** Composition of adjoints                                      :ignore:
# Theorem 1 pag 103
#+ATTR_LATEX: :options [Composition of adjunctions]
#+BEGIN_theorem
Given two adjunctions $\varphi \colon F \dashv G$ and $\theta \colon F' \dashv G'$ between categories ${\cal X},{\cal Y}$
and ${\cal Y},{\cal Z}$ respectively, the composite functors yield a composite adjunction
$\varphi \cdot \theta \colon F'\circ F \dashv G\circ G'$. Let the unit and counit of $\varphi$ be $\pair{\eta,\varepsilon}$ and the unit
and counit of $\theta$ be $\pair{\eta',\varepsilon'}$; the unit and counit of the composite adjunction
are $\pair{G \eta' F \circ \eta,\ \varepsilon' \circ F' \varepsilon G'}$.
#+END_theorem
#+BEGIN_proof
We see that the vertical composition of two natural isomorphisms is itself
an natural isomorphism because the composition of isomorphisms is itself an
isomorphism. We compose as in the following diagram.
#+latex: \\[-20pt]
\begin{prooftree}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&]
F'FX \rar{f}\& Y
\end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&]
FX \rar{\theta(f)}\& G'Y
\end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&]
X \rar{\varphi\theta(f)}\& GG'Y
\end{tikzcd}}
\end{prooftree}
If we apply the two natural isomorphisms to the identity, we find the unit
and the counit of the adjunction.
#+latex: \\[-40pt]
\begin{prooftree}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&] 
\phantom{FX}\&
F'FX \rar{\id}\& 
F'FX 
\end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&] 
FX \rar{\id}\& 
FX \rar{\eta'_{FX}}\& 
G'F'FX
\end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&]
X \rar[swap]{\eta}\& 
GFX \rar[swap]{G\eta'_{FX}}\&
GG'F'FX
\end{tikzcd}}

\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&] 
GG'Z \rar{\id} \&
GG'Z \& 
\phantom{FFGy}
\end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&]
FGG'Z \rar{\varepsilon_{G'Z}}\&
G'Z \rar{\id}\&
G'Z \end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&]
F'FGG'Z  \rar[swap]{F'\varepsilon_{G'Z}}\&
F'G'Z \rar[swap]{\varepsilon'}\&
Z \end{tikzcd}}
\noLine
\BIC{}
\end{prooftree}
#+END_proof

**** TODO Bicategory of adjoints
*** Examples of adjoints
**** Product and coproduct                                        :ignore:
#+ATTR_LATEX: :options [Product and coproduct as adjoints]
#+BEGIN_exampleth
Given any category ${\cal C}$, we define a *diagonal functor* to a product
category $\Delta \colon {\cal C} \to {\cal C} \times {\cal C}$, sending every object $X$ to a pair $(X,X)$,
and each morphism $f : X \to Y$ to the pair $\pair{f,f} \colon (X,X) \to (Y,Y)$.

The right adjoint to this functor will be the categorical product
$\times \colon {\cal C} \times {\cal C} \to {\cal C}$, sending each pair of objects to their product and
each pair of morphisms to their unique product. The left adjoint to
this functor will be the categorical sum, $+ \colon {\cal C}\times {\cal C} \to {\cal C}$, sending
each pair of objects to their sum and each pair of morphisms to their
unique sum. That is, we have the following chain of adjoints,
\[+ \dashv \Delta \dashv \times.\]
More precisely, knowing that a morphism $(X,X') \to (Y,Z)$ is actually
pair of morphisms $X \to Y$ and $X' \to Z$, the adjoint properties for the
diagonal functor
#+latex: \\[-40pt]
\begin{prooftree}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&]
\Delta X \rar\& (Y,Z) \end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&]
X \rar\& \times(Y,Z) \end{tikzcd}}

\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&]
+(X,Y) \rar\& Z \end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&]
(X,Y) \rar\& \Delta Z \end{tikzcd}}

\noLine
\BIC{}
\end{prooftree}
can be rewritten as bidirectional inference rules with two premises
#+latex: \\[-40pt]
\begin{prooftree}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&]
X \to Y \& X \to Z \end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&]
X \rar\& Y \times Z \end{tikzcd}}

\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&]
X + Y \rar\& Z \end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&]
X \to Z \& Y \to Z \end{tikzcd}}

\noLine
\BIC{}
\end{prooftree}
which are exactly the universal properties of the product and the sum.
The necessary natural isomorphism is given by the existence and uniqueness
provided by the inference rule.
#+END_exampleth

# TODO:
# Naturality?
# Product: What's the unit? Diagonal. What's the counit? Projections.
# Sum: What's the unit? Diagonal. What's the counit? Projections.

**** Free and forgetful functors                                  :ignore:
#+ATTR_LATEX: :options [Free and forgetful functors]
#+BEGIN_exampleth
Let $\mathsf{Mon}$ be the category of monoids with monoid homomorphisms.
A functor $U \colon \mathsf{Mon} \to \Set$ can be defined by sending each morphism to
its underlying set and each monoid homomorphism to its underlying
function between sets. Funtors of this kind are called *forgetful*
*functors*, as they simply /forget/ part of the algebraic structure.

Left adjoints to forgetful functors are called *free functors*. In
this case, the functor $F \colon \mathsf{Set} \to \mathsf{Mon}$ taking each set to the free
monoid over it and each function to its unique extension to the free
monoid. Note how it preserves identities and composition.
The adjunction can be seen diagramatically as
\begin{prooftree}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&] FA \rar{\overline{f}}\& M \end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&] A \rar{f}\& UM \end{tikzcd}}
\end{prooftree}
where each monoid homormorphism from the free monoid, $FA \to M$ can
be seen as the unique extension of a function from the set
of generators $f \colon A \to UM$ to a full monoid homomorphism,
$\overline{f} \colon FA \to M$.

Note how, while this characterizes the notion of free monoid, it does
not provide an explicit construction. Indeed, given $f \colon A \to UM$,
we can take the free monoid $FA$ to consist on the words over the elements of
$A$ endowed with the concatenation operator; the only way to extend $f$ to
an homomorphism is to define
\[
\overline{f}(a_1a_2\dots a_n) = f(a_1)f(a_2)\dots f(a_n).
\]
Note also that every homomorphism from the free monoid is determined
by how it acts on the generator set. This notion of forgetful and free
functors can be generalized to algebraic structures other than
monoids.
#+END_exampleth

**** TODO Hom-tensor                                              :ignore:
**** TODO Limits in general?                                      :ignore:
**** TODO Equivalence of categories                               :ignore:
**** TODO Adjoints for preorders (Galois connections)             :ignore:
*** Monads
<<sec-monads>>
**** Motivation                                                   :ignore:
The notion of /monads/ is pervasive in category theory. A monad is a
certain type of endofunctor that arises naturally when considering
adjoints. They will be useful to model algebraic notions inside
category theory and to model a variety of effects and contextual
computations in functional programming languages. We will only prove
here that each adjunction gives rise to a monad, but it is also true
that there are multiple ways to turn a monad into an adjunction. With
this result, we aim to illustrate how adjoints capture another
fundamental concept in functional programming.
 
\\

**** Definition of monads                                         :ignore:
A *monad* is a functor $T\colon X \to X$ with natural transformations

 * $\eta\colon \Id \tonat T$, called /unit/; and
 * $\mu \colon T^2 \tonat T$, called /multiplication/;

such that the following two diagrams commute.
\[\begin{tikzcd}
T^3 \rar{T\mu}\dar{\mu T} & T^2\dar{\mu} \\
T^2 \rar{\mu} & T
\end{tikzcd}
\qquad
\begin{tikzcd}
\Id \circ T \rar{\eta T}\drar[swap]{\cong} & T^2\dar{\mu} & \lar[swap]{T\eta}\dlar{\cong} T\circ \Id \\
& T &
\end{tikzcd}\]

The first diagram is encoding some form of associativity of the
multiplication, while the second one is encoding the fact that
$\eta$ creates a neutral element with respect to this multiplication.
These statements will be made precise when we talk about algebraic
theories. A *comonad* is the dual of a monad.

**** Each adjunction gives rise to a monad                        :ignore:
#+begin_proposition
Given an adjunction $F \dashv G$, the composition $GF$ is a monad.
#+end_proposition
#+begin_proof
We take the unit of the adjunction as the monad unit. We define the
product as $\mu = G\varepsilon F$. Associativity follows from
\[\begin{tikzcd}
FGFG\rar{FG\varepsilon} \dar[swap]{\varepsilon FG} & FG \dar{\varepsilon} \\
FG\rar{\varepsilon} & I
\end{tikzcd}
\qquad
\begin{tikzcd}
GFGFGF\rar{GFG\varepsilon F} \dar[swap]{G\varepsilon FGF} & GFGF \dar{G\varepsilon F} \\
GFGF\rar{G\varepsilon F} & GF
\end{tikzcd}\]
where the first diagram is commutative by Proposition [[prop-interchangelaw]]
and the second one is obtained by applying functors $G$ and $F$. Unit laws
follow from the [[*Unit and counit][triangular identities]] after applying $F$ and $G$.
#+end_proof

*** Algebras
<<sec-algebras>>
In category theory, the word /algebra/ denotes certain structures that
can be easily described in terms of endofunctors as universal fixed
points for some functors.  They model inductive constructions in terms
of category theory.

Let $F \colon {\cal C} \to {\cal C}$ be a functor. An $F\textbf{-algebra}$ is an object $X$ with a
map $\mu \colon FX \to X$ called /structure map/. A morphism between two
$F\text{-algebras}$ $\mu \colon FX \to X$ and $\nu \colon FY \to Y$ is a map $h : X \to Y$
such that the following diagram commutes.
\[\begin{tikzcd}
FX \rar{Fh}\dar{\mu} & FY\dar{\nu} \\
X \rar{h} & Y
\end{tikzcd}\]
This defines a category $\mathsf{Alg}_F({\cal C})$. The initial object of this category,
is called the *initial algebra* for $F$; it needs not to exist, but when
it does, it is unique up to isomorphism.

# The theory of combinatorial species [Cite Joyal]

**** Lambek's theorem                                             :ignore:
$F\text{-algebras}$ are closely related to induction principles. The following
theorem states that the initial algebra is a fixed point of the functor,
and, by its initiality property, it maps into any other fixed point.

#+ATTR_LATEX: :options [Lambek's theorem]
#+BEGIN_theorem
The structure map of an initial algebra is an isomorphism. That is,
if $X$ is an initial algebra, $\mu \colon FX \cong X$ (see cite:awodey10).
#+END_theorem
#+BEGIN_proof
Consider the following commutative diagram, where $l \colon X \to FX$ 
is given by initiality of $X$.
\[\begin{tikzcd}
FX\rar{Fl} \dar[swap]{\mu} &
FFX \dar{F\mu} \rar{F\mu} &
FX \dar{\mu} \\
X\rar{l} &
FX\rar{\mu} &
X
\end{tikzcd}\]
By initiality of $X$, we have $\mu \circ l = \id$, and by commutativity
of the left square, $l \circ \mu = F(\mu \circ l) = \id$.
#+END_proof

**** Natural numbers as an initial algebra                        :ignore:
#+ATTR_LATEX: :options [Natural numbers object]
#+BEGIN_exampleth
<<example-naturalnumbersobj>>
Consider the functor $F(X) = 1 + X$ in a category ${\cal C}$ with coproducts
and a terminal object. Its initial algebra is called a *natural numbers object*
due to the fact that, in $\Set$, this initial algebra is precisely the
set of natural numbers $\mathbb{N}$ with the successor function $\mathrm{succ}\colon \mathbb{N} \to \mathbb{N}$
and the zero element given as a morphism from the terminal object, $0 \colon 1 \to \mathbb{N}$.
\[\begin{tikzcd}
1+\mathbb{N}\rar{} \dar[swap]{\pair{0,\mathrm{succ}}} & 
1+X\dar{\pair{x,f}} \\
\mathbb{N}\rar{\varphi} &
X
\end{tikzcd}\]
Let $X$ be an $F\text{-algebra}$ given by $x \colon 1 \to X$ and $f \colon X \to X$; by induction over
the natural numbers we can show that a morphism of algebras $\varphi$ making that diagram
commute must follow $\varphi(0) = x$ and $\varphi(\mathrm{succ}(n)) = f(\varphi(n))$. Thus, in a certain sense, 
initiality captures the principle of induction.

For instance, we can define addition $+ \colon \mathbb{N} \times \mathbb{N} \to \mathbb{N}$, interpreted
as a unary operation $+ \colon \mathbb{N} \to \hom(\mathbb{N},\mathbb{N})$, as the unique morphism $\varphi$
from the initial algebra to the algebra given by $\hom(\mathbb{N},\mathbb{N})$ with $\id$
and postcomposition with $\mathrm{succ}$.
\[\begin{tikzcd}
1+\mathbb{N}\rar{} \dar[swap]{\pair{0,\mathrm{succ}}} & 
1+\hom(\mathbb{N},\mathbb{N}) \dar{\pair{\id, \mathrm{succ}\,\circ\, -}} \\
\mathbb{N}\rar{+} &
\hom(\mathbb{N},\mathbb{N})
\end{tikzcd}\]
This definition immediately implies the equalities $0+m = \id(m) = m$
and $\mathrm{succ}(n) + m = (\mathrm{succ}\circ (n+\_))(m) = \mathrm{succ}(n+m)$.
#+END_exampleth

**** Lists or free monoids                                        :ignore:
#+ATTR_LATEX: :options [Free monoids]
#+BEGIN_exampleth
<<example-listalgebra>>
Fixing a set $A$ and changing the functor slightly to $F(X) = 1 + A \times X$
we get the set of lists of elements of $A$ as the initial algebra.  This
algebra is written as $\mathrm{List}(A)$ with the empty list $\mathrm{nil} \colon 1 \to \mathrm{List}(A)$ and
appending, $\mathrm{cons} \colon A \times \mathrm{List}(A) \to \mathrm{List}(A)$, as the binary operation.
\[\begin{tikzcd}
1+ A \times \mathrm{List}(A) \rar{} \dar[swap]{\pair{\mathrm{nil} , \mathrm{cons}}} & 
1 + A \times X \dar{\pair{x,\bullet}} \\
\mathrm{List}(A) \rar{\varphi} &
X
\end{tikzcd}\]
Given any other $F\text{-algebra}$ $X$, with $x \colon 1 \to X$ and $\bullet \colon A \times X \to X$,
we can show by induction on the length of the list that
the unique morphism $\varphi \colon \mathrm{List}(A) \to X$ making the diagram commute must be such
that $\varphi( \mathrm{nil} ) = x$ and $\varphi( \mathrm{cons}(a,l) ) = a \bullet \varphi(l)$.

# TODO: Example, fold of a list
For instance, fixing $A = \mathbb{N}$, we can define the sum of a list of
naturals $\mathrm{sum}\colon \mathrm{List}(\mathbb{N}) \to \mathbb{N}$ as the unique morphism $\varphi$ from the
initial algebra to the algebra given by $\mathbb{N}$ with zero and the
addition.
\[\begin{tikzcd}
1+ \mathbb{N} \times \mathrm{List}(\mathbb{N}) \rar{} \dar[swap]{\pair{\mathrm{nil} , \mathrm{cons}}} & 
1 + \mathbb{N} \times \mathbb{N} \dar{\pair{0,+}} \\
\mathrm{List}(\mathbb{N}) \rar{\mathrm{sum}} &
\mathbb{N}
\end{tikzcd}\]
This definition immediately implies the equalities $\mathrm{sum}(\mathrm{nil}) = 0$
and $\mathrm{sum}(\mathrm{cons}(m,l)) = m + \mathrm{sum}(l)$.
#+END_exampleth

* Categorical logic
** Presheaves
<<section-presheaves>>
# [Moerdijk]
# TODO: Comma category is equivalent to a presheaf category
# TODO: Pullbacks (in particular, products) always exist on presheaf cats
# TODO: Terminal and pullbacks imply all finite limits

/Presheaves/ can be thought as sets parametrized by a category or as
/generalized sets/. As we will study in the following chapters,
categories of presheaves share a lot of categorical structure with the
category of Sets and can be used as non-standard models of lambda
calculus. 

Specifically, a /presheaf/ on the category ${\cal C}$ is a functor
$S \colon {\cal C}^{op} \to \Sets$ from the opposite category to the category of sets.
The category of presheaves on ${\cal C}$ is a functor category of the
form $\Set^{{\cal C}^{op}}$. In particular, the examples we gave when
talking about functor catgeories (Examples [[example-functor-graphs]] and
[[example-dynamical]]) are presheaf categories. We see that they all 
share some structure with the category of sets;
in the following sections, we will prove stronger results based on these.

*** All small limits exist in Sets                                                        :ignore:
#+BEGIN_proposition
<<prop-alllimitsset>>
All limits given by a functor from a small category exist on $\Set$.
#+END_proposition
#+BEGIN_proof
Let ${\cal J}$ be any small diagram on the category $\Set$, with objects $A_i$
indexed by some $i \in I$ and morphisms $f_j \colon A_{i} \to A_{i'}$ between these,
indexed by some $j \in J$. We can take $\lim {\cal J}$ to be the subset of the
cartesian product $\prod A_i$ of elements $(a_i)_{i \in I}$ such that $f_j(a_{i}) = a_{i'}$
for each $j \in J$. Note that any other cone factorizes through this one
by taking the componentwise image of each element.
#+END_proof

*** Pullbacks, in particular products always exists, thus all finite limits               :ignore:
#+BEGIN_proposition
<<prop-alllimitpresheaf>>
All limits given by a functor from a small category exist on any
presheaf category.
#+END_proposition
#+BEGIN_proof
Let ${\cal J}$ be any small diagram on the category $\Set^{{\cal C}^{op}}$, whose objects
are functors $P_i \colon {\cal C}^{op}\to\Set$ indexed by some $i \in I$ and whose
morphisms are natural transformations $\eta_j \colon P_{i} \to P_{i'}$ indexed by
some $j \in J$. For each $c \in C$, the objects $P_i(c)$ for $i \in I$ with
the morphisms $\eta_j_{(c)} \colon P_i(c) \to P_{i'}(c)$ determine a diagram on the
category $\Set$.  By proposition [[prop-alllimitsset]], a limit for
this diagram exists, which we call $R(c)$.  By definition of
limit, any morphism $g \colon d \to c$ in the category ${\cal C}$ induces a
unique $R(c) \to R(d)$ making each component of the transformation
given by $\left\{ P_i(g) \right\}_{i \in I}$ commute and making the family of projections
from each limit form a natural transformation. Thus, we have created
a functor $R \colon {\cal C}^{op}\to \Set$ with natural transformations to each $P_i$
and such that any other functor factorizes through it componentwise.
#+END_proof

# The product of two functors is the product functor
*** TODO Presheaves
**** TODO Pointed Sets (?)

*** TODO Has \omega-colimits
# Proposition 10.12 in Awodey gives initial algebras for polynomial
# endofunctors in Set.

# Yoneda embedding preserves colimits and limits (?), that is why
# presheaves have colimits. <- This is proved later.
# Yoneda preserves limits but does it preserve colimits?

# Coproducts

** Cartesian closed categories and lambda calculus
<<sec-cartesianclosedlambdacalculus>>
# http://math.ucr.edu/home/baez/qg-fall2006/ccc.html
# http://math.ucr.edu/home/baez/qg-fall2006/index.html#computation

*** Lawvere theories
<<sec-lawveretheories>>
**** Signature to category                                        :ignore:
The usual notion of /algebraic theory/ is given by a set of /k-ary operations/
for each $k \in \mathbb{N}$ and certain axioms between the terms that can be constructed
inductively using free veriables and these operations. For instance, the theory
of groups is given by a binary operation $(\cdot)$, a unary operation $(^{-1})$, and a 
constant or 0-ary operation $e$; satisfying the following axioms
\[
x \cdot x^{-1} = e, \quad
x^{-1} \cdot x = e, \quad
(x \cdot y) \cdot z = x \cdot (y \cdot z), \quad
x \cdot e = x, \quad
e \cdot x = x,
\]
for any free variables $x,y,z$. The problem with this notion of algebraic theory
is that it is not independent from its representation: there may be multiple
formulations for the same theory, with different but equivalent axioms. For
example, cite:mccune91 discusses many single-equation axiomatizations of groups,
such as
\[
x\ /\
\big(((x/x)/y)/z)\ /\ ((x/x)/x)/z\big)
= y
\]
with the binary operation $/$, related to the usual multiplication as $x / y = x \cdot y^{-1}$.
Our solution to this problem will be to capture all the algebraic
information of a theory -- all operations, constants and axioms --
into a category. Differently presented but equivalent axioms will give
rise to the same category.

**** Definition                                                   :ignore:
#+ATTR_LATEX: :options [Lawvere, 1963]
#+BEGIN_definition
<<def-algebraictheory>>
An *algebraic theory* (see cite:bauer17 and cite:lawvere1963funct) is a
category $\mathbb{A}$ with all finite products
whose objects form a sequence $A^0,A^1,A^2, \dots$ such
that $A^m \times A^n = A^{m+n}$ for any $m, n$. From this definition,
it follows that $A^0$ must be the terminal object.
#+END_definition

An algebraic theory can be built from its operations and axioms as
follows: objects represent natural numbers, $A^0,A^1,A^2,\dots$, and morphisms
from $A^n$ to $A^m$ are given by a tuple of $m$ terms $t_1,\dots,t_m$ depending on $n$
free variables $x_1,\dots,x_n$, written as
\[
(x_1\dots x_n \vdash \pair{t_1,\dots,t_k}) \colon
A^n \to A^m.
\]
Composition is defined as componentwise substitution of the terms of the first
morphism into the variables of the second one; that is, given $(x_1\dots x_k \vdash \pair{t_1,\dots,t_m}) \colon A^k \to A^{m}$
and $(x_1\dots x_m \vdash\pair{u_1,\dots,u_n}) \colon A^m \to A^n$, their composition is
$(x_1\dots x_k\vdash \pair{s_1,\dots,s_n})$, where $s_i = u_i[t_1,\dots,t_m / x_1,\dots,x_m]$. Two
morphisms are considered equal, $(x_1\dots x_n \vdash \pair{t_1,\dots,t_k}) = (x_1\dots x_n \vdash \pair{t'_1,\dots,t'_k})$
when componentwise equality of terms, $t_i = t'_i$, follows from the axioms of the theory.
Note that identity is the morphism $(x_1\dots x_n \vdash \pair{x_1,\dots, x_n})$. The kth-projection
from $A^n$ is the term $(x_1\dots x_n \vdash x_k)$, and it is easy to check that these projections
make $A^n$ the n-fold product of $A$. We have built a category with the desired
properties.

**** Models                                                       :ignore:
#+BEGIN_definition
A *model* of an algebraic theory $\mathbb{A}$ in a category ${\cal C}$ is a functor
$M \colon \mathbb{A} \to {\cal C}$ preserving all finite products.
#+END_definition

The /category of models/, $\Mod_{{\cal C}}(\mathbb{A})$, is the subcategory of the functor
category ${\cal C}^{\mathbb{A}}$ containing the functors that preserve all finite products,
with the usual natural transformations between them. We say that a
category is /algebraic/ if it is equivalent to a category of the
form $\Mod_{{\cal C}}(\mathbb{A})$.

**** Examples                                                     :ignore:
#+ATTR_LATEX: :options [The algebraic theory of groups]
#+BEGIN_exampleth
Let $\mathbb{G}$ be the algebraic theory of groups built from its axioms; we
have all the tuples of terms that can be inductively built with
\[(x,y \vdash x \cdot y) \colon G^2 \to G, \qquad
(x \vdash x^{-1}) \colon G \to G, \qquad
(\vdash e) \colon G,\]
and the projections $(x_1\dots x_n \vdash x_k) \colon G^n\to G$, where the usual group
axioms hold. A model of the theory of groups inside some category ${\cal C}$ is given by
a functor $H \colon \mathbb{G} \to {\cal C}$ which is in turn determined by an object
of ${\cal C}$ and some morphisms of the category with the above signature
for which the axioms hold. For instance,

 * a model of $\mathbb{G}$ in $\Set$ is a classical *group*,
   a set with multiplication and inverse functions for which
   the axioms hold;
 * a model of $\mathbb{G}$ in $\Top{}$ is a *topological group*, a topological
   space with continuous multiplication and inverse functions;
 * a model of $\mathbb{G}$ in $\mathsf{Mfd}$, the category of differentiable manifolds
   with smooth functions between them, is a *Lie group*;
 * a model of $\mathbb{G}$ in $\mathsf{Grp}$ is an *abelian group*, by the Eckmann-Hilton
   argument;
 * a model of $\mathbb{G}$ in $\mathsf{CRing}$, the category of commutative rings with
   homomorphisms, is a *Hopf algebra*.

The category of models $\Mod_{\Set}(\mathbb{A})$ is the usual category of groups, $\mathsf{Grp}$;
note that natural transformations on this category are precisely group
homomorphisms, as they have to preserve the unit, product and inverse
of the group in order to be natural.
#+END_exampleth

# a model would be the
# set of integers with the addition $(+)$, opposite $(-)$ and zero $(0)$ as operations. The
# term $(x,y,z \vdash (x \cdot y^{-1}) \cdot (z^{-1} \cdot e))$ would be interpreted as

# Monads are monoids in the category of endofunctors

\\

**** Completeness of algebraic theories                           :ignore:
By construction we know that, if an equation can be proved from the
axioms, it is valid in all models (our semantics are /sound/); but
we would like to also prove that, if every model of the theory
satisfies a particular equation, it can actually be proved from the
axioms of the theory (our semantics are /complete/). In general, we
can actually prove a stronger, but maybe unsatisfying, result.

#+ATTR_LATEX: :options [Universal model]
#+BEGIN_theorem
Given $\mathbb{A}$ an algebraic theory, there exists a category ${\cal A}$ with
a model $U \in \mathrm{Mod}_{{\cal A}}(\mathbb{A})$ such that, for every terms $u,v$, the
equality $u = v$ is true in $U$ if and only if $\mathbb{A}$ proves $u = v$.
A category with this property is called a *universal model*.
#+END_theorem
#+BEGIN_proof
Indeed, taking ${\cal A} = \mathbb{A}$ as a model of itself with the identity functor
$U = \Id$, the equation $u = v$ is trivially satisfied under the identity
functor if and only if it is satisfied in the original category.
# TODO: Is this category really a representation of the equations?
# Yes by construction (x,y \vdash x.y) is a representation
#+END_proof

This proof feels rather disappointing because this trivial model is
not even set-theoretic in general; but we can go further and assert
the existence of a universal model in a presheaf category via the
Yoneda embedding (Definition [[def-yoneda-functor]]).

#+ATTR_LATEX: :options [Completeness on presheaves]
#+BEGIN_corollary 
The Yoneda embedding $Y \colon \mathbb{A} \to \Set^{\mathbb{A}^{op}}$ is a universal model for $\mathbb{A}$.
#+END_corollary
#+BEGIN_proof
Note that the Yoneda embedding preserves all limits. That is, if
a family of morphisms $D \to A_i$ in $\mathbb{A}$ determines a universal cone, that
means that we have a universal cone $\hom(X,D)\to\hom(X,A_i)$
for each $X \in \mathbb{A}$. Then, as we discussed in Definition [[def-yoneda-functor]],
this gives natural transformations $\hom(-,D)\to\hom(-,A_i)$ creating
a new universal cone.
In particular, the Yoneda functor is a model because it preserves all
finite products. As it is a faithful functor, we know that any
equation proved in the model is an equation proved by the theory.
#+END_proof

**** Universal group                                              :ignore:
# TODO: Universal group
#+ATTR_LATEX: :options [Universal group]
#+BEGIN_exampleth
For instance, a universal model of the group would be the Yoneda embedding
of $\mathbb{G}$ in $\Set^{\mathbb{G}^{op}}$. The group object would be the functor $U = \hom_{\mathbb{G}}(-,A^1)$;
which can be thought as a family of sets parametrized over the naturals:
for each $n$ we have $U_n = \hom_{\mathbb{G}}(A^n,A^1)$, which is the set of terms on
$n$ variables under the axioms of a group. In other words, the universal model
for the theory of groups would be the free group on $n$ generators, parametrized
over $n$.
#+END_exampleth

*** Cartesian closed categories
**** Definition                                                                          :ignore:
#+ATTR_LATEX: :options [Cartesian closed category]
#+BEGIN_definition
A *cartesian closed category* is a category ${\cal C}$ in which the terminal,
diagonal and product functors have right adjoints
\[
! \colon {\cal C} \to 1, \qquad
\Delta \colon {\cal C}\times{\cal C} \to {\cal C}, \qquad
(- \times A) \colon {\cal C} \to {\cal C}.
\]
#+END_definition

These adjoints are given by terminal, product and exponential objects
respectively, written as follows.
\begin{prooftree}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&] \ast \rar{}\& \ast \end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&] C \rar{!}\& 1 \end{tikzcd}}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&] C,C \rar{f,g}\& A,B \end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&] C \rar{\pair{f,g}}\& A \times B \end{tikzcd}}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&] C \times A \rar{f}\& B \end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&] C \rar{\widetilde{f}}\& B^A \end{tikzcd}}
\noLine
\TIC{}
\end{prooftree}
In particular, exponentials are characterized by the family of
*evaluation morphisms* $\varepsilon \colon B^A \times A \to B$, which form the counit of
the adjunction.
\begin{prooftree}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&] 
C \times A \ar[bend left=45]{rr}{f} \rar{\widetilde{f} \times \id}\& 
B^A \times A \rar{\varepsilon}\& 
B
\end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&]
C \ar[bend right=45]{rr}[swap]{\widetilde{f}} \rar[swap]{\widetilde{f}}\& 
B^A \rar[swap]{\id}\&
B^A 
\end{tikzcd}}
\end{prooftree}

**** Presheaves and sets are cartesian closed                                            :ignore:
#+BEGIN_proposition
<<proposition-presheaves-ccc>>
Presheaf categories are cartesian closed.
#+END_proposition
#+BEGIN_proof
The category $\Set$ is cartesian closed, with exponentials given by function sets. That
is, the exponential set $B^A$ is the set of functions $A \to B$, and evaluation
is given by function application. In general, any presheaf category $\Set^{{\cal C}^{op}}$ from a
small ${\cal C}$ is cartesian closed. First note that products and terminal objects
exist in any presheaf category (Proposition [[prop-alllimitpresheaf]]), we only
have to show that exponentials exist.

Given any two presheaves $Q,P \colon {\cal C}^{op} \to \Set$,
the image of the exponential presheaf $Q^P \colon {\cal C}^{op}\to \Set$ over any given $A \in {\cal C}$
is determined by the Yoneda Lemma (Lemma [[lemma-yoneda-natural]]) and by the
definition of exponential. The composition of both isomorphisms on the
functor category allows us to write this exponential in terms of $P$ and $Q$.
\[
Q^PA \cong \Nat(\hom(-,A), Q^P) \cong \Nat(\hom(-,A) \times P, Q)
\]
When ${\cal C}$ is small, this is in fact a set of natural transformations. We will
show that this choice in fact creates an adjunction by proving the
existence of a family of universal evaluations and then applying
Proposition [[prop-characterize-adjunctions]], that characterizes adjunctions
in terms of their universal counit morphisms.
A family of evaluation functions $\varepsilon_A \colon \Nat(\hom(-,A) \times P,Q) \times PA \to QA$ can be
defined as $\varepsilon_A(\eta, p) = \eta(\id_A,p)$, where $p \in PA$ and $\eta \colon \hom(-,A) \times P \tonat Q$ is a natural
transformation that can be particularized into a morphism $\eta_A \colon \hom(A,A) \times PA \to QA$.
We now show that each one of these is a universal arrow: given any other
presheaf $R \colon {\cal C}^{op} \to \Set$ endowed with a morphism $n \colon R\times P \tonat Q$,
we will prove that there exists a unique $\phi \colon R \tonat \Nat(\hom(-,A)\times P, Q)$ making
the following diagram commute.
\[\begin{tikzcd}
R \times P \dar[dashed,swap]{\phi \times \Id}\drar{n} & \\
\Nat(\hom(-,A)\times P, Q) \times P \rar[swap]{\varepsilon} & Q
\end{tikzcd}\]
In fact, we know that $\phi_r(\id,p) = \varepsilon_A(\phi_r,p) = n(r,p)$ holds by commutativity;
therefore, the following diagram commutes for any $f \colon B \to A$ by
naturality.
\[\begin{tikzcd}
RA\rar{\phi_A} \dar[swap]{Rf} & 
\Nat(\hom(-,A)\times P,Q)\dar{-\circ ((f \circ -) \times \id)} \\
RB\rar{\phi_B} &
\Nat(\hom(-,B)\times P,Q)
\end{tikzcd}\]
Thus, the complete natural transformation $\phi$ is completely determined
for any given $r \in RA$ and $p \in PA$ as
$\phi(r)(f,p) = \phi(Rf(r))(\id,p) = n(Rfr,p)$.\qedhere
#+END_proof

In general, cartesian-closed categories with functors preserving
products and exponentials form a category called $\mathsf{Ccc}$ that
we show equivalent to a category containing lambda theories in Theorem
[[th-equivalence-ccctl]].

# Example 2.2.10 from Bauer, Awodey
# This is Proposition I.6.1 in "Sheaves in geometry and logic."
# https://mathoverflow.net/questions/10406/general-construction-for-internal-hom-in-a-presheaf-category

*** Simply-typed \lambda-theories
**** Cartesian category                                                                  :ignore:
If we read $\Gamma \vdash a : A$ as a morphism from the context $\Gamma$ to the output
type $A$, the rules of simply-typed lambda calculus with product and
unit types match the adjoints that determine a cartesian closed category.
\begin{prooftree}
\AXC{}
\UIC{$\Gamma \vdash \ast : 1$}
\AXC{$\Gamma \vdash a : A$}
\AXC{$\Gamma \vdash b : B$}
\BIC{$\Gamma \vdash \pair{a,b} : A \times B$}
\AXC{$\Gamma, a : A \vdash b : B$}
\UIC{$\Gamma \vdash (\lambda a.b) : A \to B$}
\noLine
\TIC{}
\end{prooftree}
Note that categorical projections from the product object correspond
to the pair projections we called $\fst$ and $\snd$, and the
evaluation morphism is simply function application in lambda calculus.
This motivates the idea that simply typed \lambda-calculus is a manifestation
of cartesian closed categories in some sense yet to be made explicit.

\\

**** Lambda theories                                                                     :ignore:
A *\lambda-theory* $\mathbb{T}$ is the analog of a Lawvere algebraic theory
(Definition [[def-algebraictheory]])
for cartesian closed categories. It is given by a set of basic types and constants
over the simply-typed lambda calculus and a set of equality axioms,
determining a *definitional equality* $\equiv$, an equivalence relation
preserving the structure of the simply-typed lambda calculus;
that is
\begin{center}\begin{array}{ll}
t \equiv {\ast}, & \mbox{ for each } t : 1; \\
\pair{a,b} \equiv \pair{a',b'}, & \mbox{ for each } a \equiv a',\ b \equiv b' \\
\fst\pair{a,b} \equiv a,\ \snd\pair{a,b}\equiv b, & \mbox{ for each } a : A, b : B; \\
\fst\ m \equiv \fst\ m',\ \snd\ m \equiv \snd\ m', & \mbox{ for each } m \equiv m'; \\
m \equiv \pair{\fst\ m,\snd\ m}, & \mbox{ for each } m : A \times B; \\
f\ x \equiv f'\ x', & \mbox{ for each } f \equiv f', x \equiv x'; \\
(\lambda x.f\ x) \equiv f,  & \mbox{ for each } f : A \to B; \\
(\lambda x.m) \equiv (\lambda x.m'),  & \mbox{ for each } m \equiv m'; \\
(\lambda x.m)\ n \equiv m[n/x] & \mbox{ for each } m : B, n : A. \\
\end{array}\end{center}
Two types are /isomorphic/, $A \cong A'$ if there exist terms $f \colon A \to A'$
and $g \colon A' \to A$ such that $f\ (g\ a) \equiv a$ for each $a {:} A$, and $g\ (f\ a') \equiv a'$
for each $a'{:}A'$.

**** System T                                                                            :ignore:
#+BEGIN_exampleth
<<example-systemt>>
Gödel's *System T* cite:girard89 is defined as a \lambda-theory with the basic types =nat=
and =bool=; the constants $0 : \mathtt{nat}$, $S : \mathtt{nat}\to \mathtt{nat}$, $\mathrm{true} : \mathtt{bool}$, $\mathrm{false} : \mathtt{bool}$,
$\mathrm{ifelse} : \mathtt{bool} \to C \to C \to C$ and $\mathrm{rec} : C\to (\mathtt{nat} \to C \to C) \to \mathtt{nat}\to C$
where $C$ is any type; and the axioms
\begin{center}\arraycolsep=30pt\begin{array}{ll}
\textrm{ifelse}\ \textrm{true}\ a\ b \equiv a,  & \textrm{rec}\ c_0\ c_s\ 0 \equiv c_0, \\
\textrm{ifelse}\ \textrm{false}\ a\ b \equiv b, & \textrm{rec}\ c_0\ c_s\ (S n) \equiv c_s\ n\ (\textrm{rec}\ c_0\ c_s\ n). \\
\end{array}\end{center}
#+END_exampleth

**** Untyped lambda calculus as a theory                                                 :ignore:
#+ATTR_LATEX: :options [Untyped lambda calculus]
#+BEGIN_exampleth
<<example-untypedlambda-theory>>
Untyped \lambda calculus can be recovered as a \lambda theory with a single
basic type $\mathsf{D}$ and a type isomorphism $\mathsf{D} \cong \mathsf{D}\to \mathsf{D}$ given by two constants
$r : \mathsf{D}\to (\mathsf{D} \to \mathsf{D})$ and $s : (\mathsf{D}\to \mathsf{D})\to \mathsf{D}$ such that $r\ (s\ f) \equiv f$ for each
$f : \mathsf{D}\to \mathsf{D}$ and $s\ (r\ x) \equiv x$ for each $x : \mathsf{D}$. We assume that each term of the
untyped calculus is of type $\mathsf{D}$ and apply $r,s$ as needed to construct well-typed
terms.
#+END_exampleth

**** Translations                                                                        :ignore:
#+BEGIN_definition
The reasonable notion of homomorphism between lambda theories is called
a *translation* between \lambda-theories. Given two lambda theories $\mathbb{T}$ and $\mathbb{U}$,
a translation $\tau \colon \mathbb{T} \to \mathbb{U}$ is given by
a function both on types and terms that

  1. preserves type constructors
     \[
     \tau 1 = 1,\qquad
     \tau(A \times B) = \tau A \times \tau B,\qquad
     \tau(A \to B) = \tau A \to \tau B;
     \]

  2. preserves the term structure
     \begin{center}\begin{array}{lll}
     \tau(\texttt{fst}\ m) \equiv \texttt{fst}\ (\tau m), &
     \tau(\texttt{snd}\ m) \equiv \texttt{snd}\ (\tau m), &
     \tau\pair{a,b} \equiv \pair{\tau a, \tau b}, \\
     \tau (f\ x) \equiv (\tau f)\ (\tau x), &
     \tau (\lambda x. m) \equiv \lambda x. (\tau m);
     \end{array}\end{center}
     
  3. and preserves all equations, meaning that $t \equiv u$ implies $\tau t \equiv \tau u$.
#+END_definition

We consider the category $\lambda\mathsf{Thr}$ of \lambda-theories
with translations as morphisms.  Note that the identity is a
translation and that the composition of two translations is again a
translation.  Our goal is to prove that this category is equivalent to
that of cartesian closed categories with functors preserving products
and exponentials.

Apart from the natural definition of isomorphism, we consider the
weaker notion of /equivalence of theories/. Two theories with translations $\tau \colon \mathbb{T} \to \mathbb{U}$
and $\sigma \colon \mathbb{U} \to \mathbb{T}$ are *equivalent* $\mathbb{T} \simeq \mathbb{U}$ if there exist two families of
/type isomorphisms/ $\tau\sigma A \cong A$ and $\sigma\tau B \cong B$ parametrized over the types
$A$ and $B$.

*** Syntactic categories and internal languages
**** Syntactic category                                                                  :ignore:
# Models are functors from the sintactic category
#+BEGIN_proposition
Given a \lambda-theory $\mathbb{T}$, its *syntactic category* ${\cal S}(\mathbb{T})$, has an object
for each type of the theory and a morphism $A \to B$ for each term
$a : A \vdash b : B$. The composition of two morphisms $a : A \vdash b : B$ and
$b' : B \vdash c : C$ is given by $a {:} A \vdash c[b/b'] {:} C$; and any two morphisms
$\Gamma \vdash b : B$ and $\Gamma \vdash b' : A$ are equal if $b \equiv b'$.

The syntactic category is cartesian closed and this induces a functor
${\cal S} \colon \lambda\mathsf{Thr} \to \mathsf{Ccc}$.
#+END_proposition
#+BEGIN_proof
The type $1$ is terminal because every morphism $\Gamma \vdash t {:} 1$ is $t \equiv\, \ast$.
The type $A \times B$ is the product of $A$ and $B$; projections from
a pair morphism are given by $\fst\ \pair{a,b} \equiv a$ and $\snd\ \pair{a,b} \equiv b$.
Any other morphism under the same conditions must be again the
pair morphism because $d \equiv \pair{\fst\ d, \snd\ d} \equiv \pair{a,b}$.

Finally, given two types $A,B$, its exponential is $A \to B$ with
the evaluation morphism
\[
m : (A \to B) \times A \vdash (\fst\ m)\ (\snd\ m) : B.
\]
It is universal: for any $p {:} C \times A \vdash q {:} B$, there exists a morphism
$z {:} C \vdash \lambda x. q[\pair{z,x}/p] : A \to B$ such that
\[
(\lambda x.q[\pair{\fst\ p,x}/p]) (\snd\ p) \equiv
q[\pair{\fst\ p, \snd\ p}/p] \equiv q[p/p] \equiv q;
\]
and if any other morphism $z {:} C \vdash d {:} A \to B$ satisfies
$(d[ \fst\ p /z] (\snd\ p)) \equiv q$ then
\[
\lambda x. q[\pair{z,x}/p] \equiv 
\lambda x. (d[\fst\ p/z]\ (\snd\ p))[\pair{z,x}/p] \equiv
\lambda x. (d[z/z]\ x) &\equiv d.
\]

Given a translation $\tau \colon \mathbb{T} \to \mathbb{U}$, we define a functor ${\cal S}(\tau) \colon {\cal S}(\mathbb{T}) \to {\cal S}(\mathbb{U})$
mapping the object $A \in {\cal S}(\mathbb{T})$ to $\tau A \in {\cal S}(\mathbb{U})$ and any morphism $\vdash b : B$ to
$\vdash \tau b : \tau B$. The complete structure of the functor is then determined because
it must preserve products and exponentials.
#+END_proof

**** Internal language                                                                   :ignore:
#+ATTR_LATEX: :options [Internal language]
#+BEGIN_proposition
Given a cartesian closed category ${\cal C}$, its *internal language* $\mathbb{L}({\cal C})$
is a \lambda-theory with a type $\intl{A}$ for each object $A \in {\cal C}$, a constant
$\intl{f} \colon \intl{A} \to \intl{B}$ for each morphism $f \colon A \to B$, axioms
\begin{center}\arraycolsep=30pt\begin{array}{ll}
\intl{\id}\ x \equiv x, &
\intl{g \circ f}\ x \equiv \intl{g}\ (\intl{f}\ x),
\end{array}\end{center}
and three families of constants
\begin{center}\begin{array}{lll}
\mathtt{T} : 1 \to \intl{1}, &
\mathtt{P}_{AB} : \intl{A}\times \intl{B} \to \intl{A \times B}, &
\mathtt{E}_{AB} : (\intl{A} \to \intl{B}) \to \intl{B^A}, &
\end{array}\end{center}
that act as /type isomorphisms/, which means that they create the following 
pairs of two-side inverses relating the categorical and type-theoretical structures
\begin{center}\begin{array}{ll}
t \equiv \mathtt{T}\ \ast\; & \mbox{ for each } u : \intl{1}, \\
m \equiv \mathtt{P}\ \pair{\intl{\pi_1}\ m, \intl{\pi_2}\ m} & \mbox{ for each } z : \intl{A \times B}, \\
n \equiv \pair{\intl{\pi_0}\ (\mathtt{P}\ n), \intl{\pi_1}\ (\mathtt{P}\ n)} & \mbox{ for each } n : \intl{A} \times \intl{B}, \\
f \equiv \mathtt{E}\ (\lambda x. \intl{e}\ (\mathtt{P}\ \pair{f,x})) & \mbox{ for each } f : \intl{B^A}, \\
g \equiv \lambda x. \intl{e}\ (\mathtt{P}\ \pair{\mathtt{E}\ g, x}) & \mbox{ for each } g : \intl{A} \to \intl{B}. \\
\end{array}\end{center}
This extends to a functor $\mathbb{L} \colon \mathsf{Ccc} \to \lambda\mathsf{Thr}$.
#+END_proposition
#+BEGIN_proof
Given any functor preserving products and exponentials $F \colon {\cal C} \to {\cal D}$, we define
a translation $\mathbb{L}(F) \colon \mathbb{L}({\cal C}) \to \mathbb{L}({\cal D})$ taking each basic type $\intl{A}$ to $\intl{FA}$ and
each constant $\intl{f}$ to $\intl{Ff}$; equations are preserved because $F$ is a functor
and types are preserved up to isomorphism because $F$ preserves products and
exponentials.
#+END_proof

**** Equivalence between CCC and STLC                                                    :ignore:
#+ATTR_LATEX: :options [Equivalence between cartesian closed categories and lambda calculus]
#+BEGIN_theorem
<<th-equivalence-ccctl>>
There exists a equivalence of categories ${\cal C} \simeq {\cal S}(\mathbb{L}({\cal C}))$ for any ${\cal C} \in \Ccc$
and an equivalence of theories $\mathbb{T} \simeq \mathbb{L}({\cal S}(\mathbb{T}))$ for any $\mathbb{T} \in \lambda\mathsf{Thr}$.
#+END_theorem
#+BEGIN_proof
On the one hand, we define $\eta \colon {\cal C} \to {\cal S}(\mathbb{L}({\cal C}))$ as $\eta A = \intl{A}$ in objects and $\eta f = (a : \intl{A} \vdash f\ a : \intl{B})$
for any morphism $f \colon A \to B$. It is a functor because $\intl{\id}\ a \equiv a$ and $\intl{g \circ f}\ a \equiv g\ (f\ a)$.
We define $\theta : {\cal S}(\mathbb{L}({\cal C})) \to {\cal C}$ on types inductively as $\theta(1) = 1$, $\theta(\intl{A}) = A$,
$\theta(B \times C) = \theta(A) \times \theta(C)$ and $\theta(B \to C) = \theta(C)^{\theta(B)}$. Now, there is a natural 
isomorphism $\eta\theta \tonat \Id$, using the isomorphisms induced by the constants $\mathtt{T}, \mathtt{P}, \mathtt{E}$,
\begin{center}\begin{array}{ll}
\eta(\theta \intl{A}) = \eta A = \intl{A}, \\
\eta(\theta 1) = \eta 1 = \intl{1} \cong 1, \\
\eta(\theta (A \times B)) = \intl{\theta(A) \times \theta(B)} \cong \intl{\theta A} \times \intl{\theta B} = \eta\theta A \times \eta\theta B \cong A \times B. \\
\eta(\theta (A \to B)) = \intl{\theta(A) \to \theta(B)} = \intl{\theta B}^{\intl{\theta A}} = (\eta\theta B)^{(\eta \theta A)} = B^A;
\end{array}\end{center}
and a natural isomorphism $\Id \tonat \theta\eta$ which is in fact an identity, $A = \theta\intl{A} = \theta\eta(A)$.
# TODO: Check that \eta is natural

On the other hand, we define a translation $\tau \colon \mathbb{T} \to \mathbb{L}({\cal S}(\mathbb{T}))$ as $\tau A = \intl{A}$ in types
and $\tau(a) = \intl{(\vdash a : \tau A)}$ in constants. We define $\sigma \colon \mathbb{L}({\cal S}(\mathbb{T})) \to \mathbb{T}$ as $\sigma\intl{A} = A$
in types and as
\begin{center}\begin{array}{llll}
\sigma(\intl{a : A \vdash b : B}) = \lambda a.b, &
\sigma \mathtt{T} = \lambda x.x, &
\sigma \mathtt{P} = \lambda x.x, &
\sigma \mathtt{E} = \lambda x.x,
\end{array}\end{center}
in the constants of the internal language.
We have $\sigma(\tau(A)) = A$, so we will check that $\tau(\sigma(A)) \cong A$ by structural induction
on the constructors of the type:

 * if $A = \intl{B}$ is a basic type, we apply structural induction over the type $B$ to get
   
   * if $B$ is a basic type, $\tau\sigma(\intl{B}) = \intl{B}$;

   * if $B = 1$, then $\tau\sigma(\intl{1}) = 1$ and $\intl{1} \cong 1$ thanks
     to the constant $\mathtt{T}$;

   * if $B = C \times D$, then $\tau\sigma(\intl{C \times D}) = \intl{C} \times \intl{D}$
     and $\intl{C \times D} \cong \intl{C} \times \intl{D}$ thanks to the constant $\mathtt{P}$;

   * if $B = D^C$, then $\tau\sigma(\intl{D^C}) = \intl{C} \to \intl{D}$ and $\intl{D^C} \cong \intl{C}\to\intl{D}$
     thanks to the constant $\mathtt{E}$.

 * if $A = 1$, then $\tau\sigma 1 = 1$;

 * if $A = C \times D$, then $\tau\sigma(C \times D) = \tau\sigma(C) \times \tau\sigma(D) \cong C \times D$
   by induction hypothesis;

 * if $A = C \to D$, then $\tau\sigma(C \to D) = \tau\sigma(C) \to \tau\sigma(D) \cong C \to D$
   by induction hypothesis. \qedhere
#+END_proof

**** Semantics                                                                           :ignore:
Thus, we can say that the simply-typed lambda calculus is the internal
language of cartesian closed categories; each lambda theories are
cartesian closed categories.

** Working in cartesian closed categories
*** Diagonal arguments
# https://golem.ph.utexas.edu/category/2006/12/classical_vs_quantum_computati_8.html
# http://tac.mta.ca/tac/reprints/articles/15/tr15abs.html
# http://math.andrej.com/2007/04/08/on-a-proof-of-cantors-theorem/

# Cantor's theorem
# Russell's paradox
# Surjectivity from naturals to lists
# No surjection from R to the Banach space C(R,R)
# Gödel's first incompleteness theorem
# Fixed points in untyped lambda calculus

We can now talk internally about cartesian closed categories using
lambda calculus. Note each closed \lambda term
$\vdash a : A$ can also be seen as a morphism from the terminal object
$1 \to A$. We use this language to provide a simple proof to a
known theorem for catesian closed categories by W. Lawvere
(see cite:lawvere06 for details). The theorem will imply many known
corollaries as particular cases when interpreted in different contexts.

**** Lawvere's fixed point theorem                                                       :ignore:
#+ATTR_LATEX: :options [Lawvere, 1969]
#+BEGIN_theorem
<<th-diagonal>>
We say that a morphism $g : A \to B$ in a cartesian closed category is
*point-surjective* if, for every element $b : B$, there exists an element $a : A$ such that
$g\ a \equiv b$. In any cartesian closed category, if there exists a point-surjective
morphism $d : A \to B^A$, then each morphism $f : B \to B$ has a fixed point $b : B$, such
that $f\ b \equiv b$.
#+END_theorem
#+BEGIN_proof
As $d$ is point-surjective, there exists $x : A$ such that $d\ x \equiv \lambda a. f\ (d\ a\ a)$,
but then, $d\ x\ x \equiv (\lambda a.f\ (d\ a\ a))\ x \equiv f\ (d\ x\ x)$ is a fixed point.
#+END_proof

**** Consequences                                                                        :ignore:
#+ATTR_LATEX: :options [Cantor, 1878]
#+BEGIN_corollary
Let $A$ be a set. The set of all subsets of $A$ has a strictly greater cardinality
than $A$.
#+END_corollary
#+BEGIN_proof
Every subset of $A$ is uniquely determined by a function to the set of
two elements $A \to 2$. As there exists nontrivial permutation of the
two-element set, a point-surjective $A \to 2^A$ cannot exist by virtue
of Theorem [[th-diagonal]].
#+END_proof

#+ATTR_LATEX: :options [Russell, 1901]
#+BEGIN_corollary
<<cor-russellparadox>>
In a naive formulation of set theory, every collection is a set. This
leads to inconsistency.
#+END_corollary
#+BEGIN_proof
We could consider $\mathsf{Sets}$, the class of all sets, and the membership relation
$\in \colon \mathsf{Sets} \to 2^{\mathsf{Sets}}$. This relation would be point-surjective if we assume that
for any property on the class of sets, given as a morphism $P \colon \mathsf{Sets} \to 2$,
there exists a comprehension set $\left\{ y \in \mathsf{Sets} \mid P(y) \right\}$. In that case, again,
any permutation of the two-element set would have a fixed point, which
is false.
#+END_proof

#+BEGIN_corollary
Every term in untyped \lambda-calculus has a fixed point.
#+END_corollary
#+BEGIN_proof
We consider untyped \lambda-calculus as a theory (Example
[[example-untypedlambda-theory]]) where terms can be regarded as
morphisms $D \to D$. There exists a type isomorphism $D \to (D \to D)$,
which is in particular a point-surjection.  Thus, by Theorem
[[th-diagonal]], there exists a fixed point for any term $D \to D$.
Note that the term thus constructed is precisely the fixed point
we defined in Section [[sec-fixed-points]].
#+END_proof

#+ATTR_LATEX: :options [Gödel, Tarski, 1936]
#+BEGIN_corollary
A consistent theory cannot express its own truth. In particular, no
consistent formal system of arithmetic can encode the truth of
arithmetic statements.
#+END_corollary
#+BEGIN_proof
Let our category be a theory (in the sense of Definition [[def-algebraictheory]])
with objects $A^0,A^1,A^2,\dots$ and a supplementary object $2$. We say that the theory is
/consistent/ if there exists a morphism $\mathrm{not} \colon 2 \to 2$ such that $\mathrm{not}\circ \varphi \neq \varphi$ for
every $\varphi : A \to 2$. We say that /truth/ is definable if there exists a 
map $\mathrm{truth} : A \times A \to 2$ such that for every predicate $\varphi \colon A \to 2$, there exists
a /Gödel number/ $c : A$ such that $\mathrm{truth}(c,a) = \varphi(a)$. By Theorem [[th-diagonal]]
we know that if truth is definable in a theory then
it must be inconsistent (in cite:yanofsky03, many other examples of this
proof technique are shown).
#+END_proof

We want to note here how abstracting a seemingly banal theorem
has resulted in a myriad of deep results.  Moreover, Lawvere's
original theorem can be replicated without exponentials in any
category with all products, taking adjoints in $d : A \times A \to
B$.
The condition of $d$ being point-surjective can also be weakened;
we only need, for every $g \colon A \to B$, the existence of some $x :
A$
such that $d\ x\ a \equiv g\ a$ for all $a : A$.

# Turing halting problem from yanofsky follows in a category of computations

# Compactly generated Hausdorff spaces are cartesian closed
# * there is no countinuous surjection from $\mathbb{R}$ to the Banach space ${\cal C}(\mathbb{R},\mathbb{R})$,
#   as the function $(\lambda x, x+1) \colon \mathbb{R} \to \mathbb{R}$ has no fixed point;

*** Bicartesian closed categories
# https://ncatlab.org/nlab/show/bicartesian+closed+category
# https://ncatlab.org/nlab/show/cocartesian+closed+category
# Theorem. Any cocartesian closed category is equivalent to the terminal category.

#+BEGIN_definition
A *bicartesian closed category* is a cartesian closed category in which
the terminal and diagonal functors have left adjoints.
These adjoints are given by initial and coproduct objects, written as
inference rules as follows.
\begin{prooftree}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&] \ast \rar{}\& \ast \end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&] 0 \rar{!}\& C \end{tikzcd}}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&] A,B \rar{f,g}\& C,C \end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&] A + B \rar{f + g}\& C \end{tikzcd}}
\noLine
\BIC{}
\end{prooftree}
#+END_definition

The rules of union and void types in simply-typed lambda calculus can
be rewritten to match the structure of these adjoints.
\begin{prooftree}
\AXC{$$}
\UIC{$\Gamma, z:0 \vdash \mathrm{abort} : C$}
\AXC{$\Gamma, a:A \vdash c : C$}
\AXC{$\Gamma, b:B \vdash c' : C$}
\BIC{$\Gamma, u : A+B \vdash \mathrm{case}\ u\ \mathrm{of}\ c;c' : C$}
\noLine
\BIC{}
\end{prooftree}
In a similar way to how our previous fragment of simply-typed lambda
calculus was the internal language of cartesian closed categories, the
extended version of lambda calculus defined in Section [[sec-extendingstlc]]
is the internal language of bicartesian closed categories.

*** Inductive types
# We get System T when we assume Nats and Bools
The existence of an initial algebra in a cartesian closed category is
equivalent to the existence a type with an elimination rule
representing an induction principle. Types generated by an inductive
rule are called *inductive types* and are common constructs in
functional programming languages. Inductive types and their properties
can be encoded as initial algebras satisfying a certain universal
property. In particular, we will see examples of inductive types and
how all of them can be modeled as initial algebras over a certain
class of functors.

# Note that this definition [of natural numbers as initial algebra]
# actually makes sense in any category E having finite
# products. However, if E is not cartesian closed, then it is better
# to explicitly assume a stronger version of this definition "with
# parameters" (which follows automatically when E is cartesian closed,
# such as when E is a topos).
# https://ncatlab.org/nlab/show/natural+numbers+object#withparams

**** Binary trees                                                 :ignore:
#+ATTR_LATEX: :options [Binary tree data structure]
#+BEGIN_exampleth
<<example-bintree>>
Let $T$ be a type generated by the constructors $\mathsf{nil} : T$ and
$\mathsf{node} : \mathbb{N} \to T \to T \to T$. It can be seen as the data structure
of a binary tree of naturals, where "$\mathsf{nil}$" is an empty leaf and "$\mathsf{node}$"
builds a data structure with a natural number on top and two pointers
to binary trees.
\[\begin{tikzcd}[column sep=tiny]
  &   &   & 5 \ar{dll}\drar &&   \\
  & 3\drar\dlar &   &   & 4\drar & \\
1 &   & 2 &   & & 6
\end{tikzcd}\]
For instance, the above diagram represents the term
\[
\mathsf{node}\ 5\ 
(\mathsf{node}\ 3\ 
(\mathsf{node}\ 1\ \mathsf{nil}\ \mathsf{nil})\ 
(\mathsf{node}\ 2\ \mathsf{nil}\ \mathsf{nil}))\ 
(\mathsf{node}\ 4\ \mathsf{nil}\ (\mathsf{node}\ 6\ \mathsf{nil}\ \mathsf{nil})).
\]
#+END_exampleth

**** Semantics of System T                                        :ignore:
#+ATTR_LATEX: :options [Semantics of System T]
#+BEGIN_exampleth
System T was described in Example [[example-systemt]] as an extension of
the simply typed lambda calculus with natural numbers and booleans.
A cartesian closed category with a natural numbers object given as an
initial algebra (Example [[example-naturalnumbersobj]]) has an internal
language with a type $\mathbb{N}$ and an elimination principle $\mathsf{ind}$ given by the
universal property of the algebra, as in the following diagram.
\begin{center}\begin{array}{lll}
\begin{tikzcd}
1+\mathbb{N}\rar{} \dar[swap]{\pair{0,\mathrm{succ}}} & 
1+C\dar{\pair{x,f}} \\
\mathbb{N}\rar{ \mathsf{ind}\ x\ f} &
C \end{tikzcd} &  \qquad & 
\begin{gathered}
\mathsf{ind} \colon C \to (C \to C) \to (\mathbb{N} \to C)  \\
\mathsf{ind}\ x\ f \ 0 \equiv x \\
\mathsf{ind}\ x\ f\ (S\ n) \equiv f\ (\mathsf{ind}\ x\ f\ n)
\end{gathered}\end{array}\end{center}
\\
It could seem that this induction principle is weaker than the recursion
principle System T offered, $\mathsf{rec} : D\to (\mathbb{N} \to D \to D) \to \mathbb{N} \to D$.
However, the full recursion principle can be recovered using the cartesian closed structure and
taking $C = \mathbb{N} \times D$ when applying the induction principle to define
\[
\mathsf{rec}\ c_0\ c_s\ n \equiv
\pi_1\ (\mathsf{ind}\ \pair{c_0,0}\ (\lambda m.\ \pair{c_s\ m\ d, \mathrm{succ}\ m})\ n).
\]
It can be checked that $\mathsf{rec}$ is such that $\mathsf{rec}\ c_0\ c_s\ 0 \equiv c_0$, and
$\mathsf{rec}\ c_0\ c_s\ (S\ n) \equiv c_s\ n\ (\mathsf{rec}\ c_0\ c_s\ n)$.

Finally, note that $\mathsf{ind}$ can be directly recovered from $\mathsf{rec}$, and the
booleans of System T correspond to the coproduct $1+1$. System T
is thus equivalent to the internal language of a cartesian closed
category with a natural numbers object and a coproduct $1+1$; and
it can take models in any category with this structure.
#+END_exampleth

# TODO: Primitive recursive functions, induction and recursion
#   https://ncatlab.org/nlab/show/natural+numbers+object#withparams
# Mikrokosmos
# Induction principle
# ind = \c.\a.\n.n c a
# mikro> ind id (compose succ) 3 5
# λa.λb.a (a (a (a (a (a (a (a b))))))) ⇒ 8 :: (A → A) → A → A

**** Polynomial endofunctors and well-founded trees               :ignore:
# Wellfounded trees

#+ATTR_LATEX: :options [Polynomial endofunctors]
#+BEGIN_exampleth
Following cite:awodey10 and cite:moerdijk00, we can generalize these
examples to initial algebras over *polynomial endofunctors* of the
form 
\[
P(X) = C_0 + C_1 \times X + C_2 \times X^2 + \dots + C_n \times X^n
\]
for some fixed objects $C_0,\dots,C_n$. Where the initial algebra can be seen to correspond to an inductive
branching type with n-ary nodes of type $C_n$ and leafs of type $C_0$.
Natural numbers $(1+X)$ and lists $(1 + A \times X)$ for a fixed type
$A$, are particular examples of initial algebras of polynomial
endofunctors (as seen in Examples [[example-naturalnumbersobj]] 
and [[example-listalgebra]]). Binary trees, as described in Example [[example-bintree]],
are the initial algebra for the functor $T \mapsto(1 + \mathbb{N} \times T \times T)$.
#+END_exampleth

**** TODO Initial algebras in presheaves                          :ignore:
# TODO: Not all endofunctors exist (powerset in Sets), but all
# polynomial endofunctors exist in Set and in all presheaves.
#  1. Yoneda embedding preserves colimits.
#  2. Sheaves have all w-colimits
#  3. Polynomial functors preserving w-colimits

*** TODO Heyting algebras
# Heyting algebras are bicartesian closed categories. This explains
# the Curry-Howard correspondence we saw earlier.

# Heyting algebras as bicartesian closed posets

# Open subsets of a topological space.

** Locally cartesian closed categories and dependent types
<<sec-locallydependent>>
*** Quantifiers and subsets
**** Logical formulas as subsets                                  :ignore:
The motivation for this section is the interpretation of logical formulas
as subsets. Every predicate $P$ on a set $A$ can be seen as a subset
$\left\{ a \in A \mid P(a) \right\}\hookrightarrow A$
determined by the inclusion monomorphism. Under this interpretation,
logical implication between two propositions, $P \to Q$, can be seen
as a morphism that commutes with the two inclusions; that is,
\[\begin{tikzcd}[column sep=tiny] 
\left\{ a\in A\mid P(a) \right\} \ar{rr}\drar[hook] & & \left\{ a\in A\mid Q(a) \right\}\dlar[hook]
\\ & A & 
\end{tikzcd}\]
$P$ implies $Q$ if and only if each $a \in A$ such that $P(a)$ is also in
the subset of elements such that $Q(a)$. Note how we are working in
a subcategory of the slice category $\Set/A$.
\\

**** Substitution                                                 :ignore:
Given a function $f \colon A \to B$, any property in $B$ induces a property on
$A$ via *substitution* in the relevant logical formula. This
substitution can be encoded categorically as a pullback: the pullback
of a proposition along a function is the proposition induced by
substitution.
\[\begin{tikzcd}
\left\{a \in A \mid P(f(a)) \right\} \rar{} \dar[swap,hook]{} &
\left\{ b \in B \mid P(b) \right\} \dar[hook]{} \\
A \rar{f} & B
\end{tikzcd}\]

**** Weakening                                                    :ignore:
A particular case of a substitution is *logical weakening*: a proposition
on the set $A$ can be seen as a proposition on $A \times B$ where we simply
discard the $B$ component of a pair.
\[\begin{tikzcd}
\left\{(a,b) \in A \times B \mid P(\pi(a,b)) \right\} \rar{} \dar[swap,hook]{} &
\left\{ a \in A \mid P(a) \right\} \dar[hook]{} \\
A \times B \rar{\pi} & A
\end{tikzcd}\]
Although it seems like an uninteresting particular case, once we
formalize this operation as a functor, existential and universal
quantifiers can be obtained as adjoints to weakening.

**** The pullback functor                                         :ignore:
#+ATTR_LATEX: :options [The pullback functor]
#+BEGIN_definition
Given a function $f \colon A \to B$ in any category ${\cal C}$ with all pullbacks, the
*pullback functor* $f^{\ast} \colon {\cal C}/B \to {\cal C}/A$ is defined for any object $y \colon Y \to B$
as the object $f^{\ast}y \colon (f^{\ast}Y) \to A$ such that
\[\begin{tikzcd}
(f^{\ast}Y) \rar{} \dar[swap]{f^{\ast}y} & Y \dar{y} \\
A\rar{f} & B
\end{tikzcd}\]
is a pullback square. The functor is defined on any morphism
$\alpha \colon y \to y'$ between any two objects given by $y \colon Y \to B$ and $y' \colon Y' \to B$
as the only morphism making the following diagram commute.
\[\begin{tikzcd}
f^{\ast}Y \ar{rrr}\ar[dashed]{dr}{\exists! f^{\ast}\alpha} \ar[bend right,swap]{ddr}{f^{\ast}y} &&&
Y \ar{dl}{\alpha}\ar[bend left=60]{ddl}{y} \\
& f^{\ast}Y' \dar[swap]{f^{\ast}y'} \rar & Y' \dar{y'} \\
& A \rar[swap]{f} & B
\end{tikzcd}\]
Note that the pullback functor is only defined up to isomorphism in
objects and well-defined on morphisms by virtue of the universal
property of pullbacks.
#+END_definition

**** Quantifiers as adjoints in sets                              :ignore:
In $\Set$, we can find two adjoints to the particular case of the
weakening functor $\pi^{\ast} \colon {\cal C}/A \to {\cal C}/(A \times B)$. These two adjoints
are $\exists \dashv \pi^{\ast} \dashv \forall$ because

 * proving the implication $P(\pi(a,b)) \to Q(a,b)$ for each pair $(a,b)$ 
   amounts to prove that $P(a) \to \left(\forall b \in B, Q(a,b)\right)$ for each $a$;
   \begin{prooftree}
   \AXC{\begin{tikzcd}[fragile,ampersand replacement=\&, row sep=tiny]
   \& A \times B \& \\
   \left\{ (a,b) \mid P(a) \right\} \urar[hook] \ar{rr} \&\& 
   \left\{ (a,b) \mid Q(a,b) \right\} \ular[hook]
   \end{tikzcd}}
   \doubleLine
   \UIC{\begin{tikzcd}[fragile,ampersand replacement=\&,row sep=tiny]
   \left\{ a \mid P(a) \right\} \drar[hook] \ar{rr} \&\& 
   \left\{ a \mid \forall b\in B, Q(a,b) \right\} \dlar[hook]
   \\
   \& A \&
   \end{tikzcd}}
   \end{prooftree}

 * and proving that $(\exists b\in B, P(a,b)) \to Q(a)$ for each $a$ is the
   same as proving that $P(a,b) \to Q(\pi(a,b))$ for each pair $(a,b)$.
   \begin{prooftree}
   \AXC{\begin{tikzcd}[fragile,ampersand replacement=\&, row sep=tiny]
   \& A \times B \& \\
   \left\{ (a,b) \mid P(a,b) \right\} \urar[hook] \ar{rr} \&\& 
   \left\{ (a,b) \mid Q(a) \right\} \ular[hook]
   \end{tikzcd}}
   \doubleLine
   \UIC{\begin{tikzcd}[fragile,ampersand replacement=\&,row sep=tiny]
   \left\{ a \mid \exists b\in B, P(a,b) \right\} \drar[hook] \ar{rr} \&\& 
   \left\{ a \mid Q(a) \right\} \dlar[hook]
   \\
   \& A \&
   \end{tikzcd}}
   \end{prooftree}

Note how, in this case, we are considering adjunction diagrams in the
slice category. A generalization of this idea to other categories
will extend our categorical logic with quantifiers.

*** Locally cartesian closed categories
**** Left adjoint                                                                        :ignore:
#+ATTR_LATEX: :options [Left adjoint of the pullback functor]
#+BEGIN_proposition
<<prop-leftadjointweak>>
Given any category ${\cal C}$ with all finite limits and a morphism $f \colon A \to B$ between
two objects $A,B \in {\cal C}$, the pullback
functor $f^{\ast} \colon {\cal C}/B \to {\cal C}/A$ has a left adjoint $\Sigma_{f} \colon {\cal C}/A \to {\cal C}/B$ defined
as $\Sigma_f x = f \circ x$ for any object $x \in {\cal C}/A$ and acting trivially on morphisms.
#+END_proposition
#+BEGIN_proof
We must find a natural bijection $\hom(f \circ x, y) \cong \hom(x, f^{\ast}y)$; but,
precisely by the universal property of the pullback, we have a natural
bijection between arrows $k \colon X \to f^{\ast}Y$ such that $x = f^{\ast}y \circ k$ and arrows
$\widetilde{k} \colon X \to Y$ such that $f \circ x = y \circ \widetilde{k}$.
\[\begin{tikzcd}
X \ar[bend right,swap]{ddr}{x} \ar[dashed]{dr}\ar[dashed, bend left]{drr} & & \\
& f^{\ast}Y \rar\dar[swap]{f^{\ast}y} & Y \dar{y} \\
& A \rar{f} & B
\end{tikzcd}\]
#+END_proof

**** Locally cartesian closed category                                                   :ignore:
We define a *locally cartesian closed category* as a category with a
terminal object and pullbacks ${\cal C}$ such that the pullback functor also
has a right adjoint $\Pi_f \colon {\cal C}/A \to {\cal C}/B$. The rationale for this name
becomes apparent in the following characterization.

**** Characterization by slices                                                          :ignore:
# Newstead
#+ATTR_LATEX: :options [Characterization]
#+BEGIN_theorem
<<theorem-characterization-lccc>>
A category ${\cal C}$ with terminal object is locally cartesian closed if and only
if ${\cal C}/A$ is cartesian closed for any object $A$ (see cite:newstead17).
#+END_theorem
#+BEGIN_proof
$(\Rightarrow)$ Suppose ${\cal C}$ be locally cartesian closed. The terminal object of ${\cal C}/A$ is
trivially $\mathrm{id}_A \colon A\to A$, and the product of $x \colon X \to A$ and $y \colon Y \to A$
is given by universal property of the pullback as in the following diagram.
\[\begin{tikzcd}
Z \ar[bend right,swap]{ddr}{} \ar[dashed]{dr}{\exists!} \ar[bend left]{drr} & & \\
& X \times_A Y \drar{x \times y}\rar\dar[swap]{} & X \dar{x} \\
& Y \rar{y} & A
\end{tikzcd}\]
We can notice that multiplying by $- \times y$ is the same as composing
$\Sigma_y \circ y^{\ast} \colon {\cal C}/A \to {\cal C}/A$; and, as we have $\Sigma_y \dashv y^{\ast} \dashv \Pi_y$, for any
$a,b \colon Z \to A$, as we can compute using adjoints,
\begin{prooftree}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&] \Sigma_y (y^{\ast} a) \rar{}\& b \end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&] y^{\ast} a \rar{}\& y^{\ast} b \end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&] a \rar{}\& \Pi_y (y^{\ast} b) \end{tikzcd}}
\end{prooftree}
the product has a right adjoint and the exponential is given by
$a^y = \Pi_y y^{\ast} a$.

$(\Leftarrow)$ Suppose ${\cal C}$ such that ${\cal C}/A$ is always cartesian closed. In particular
the slice on the terminal object is cartesian closed and so is ${\cal C} \cong {\cal C}/1$;
we only need to prove the existence of pullbacks in ${\cal C}$ and a right adjoint
for each pullback functor $f^{\ast}$.

Again, if $f \colon X \to A$ and $g \colon Y \to A$ are objects in the slice category
${\cal C}/A$, their product creates a morphism $X \times_A Y \to A$ in ${\cal C}$ and the
universal property of the product in the slice category is exactly the
universal property of the pullback in ${\cal C}$.

Now, given $f \colon A \to B$, we will define $\Pi_f$. As ${\cal C}/B$ is cartesian closed,
there is a functor $(-)^f$ that we can apply to any $x \colon X \to A$ when seen
as the triangle $x \colon (f \circ x) \to x$ in the slice category. Moreover, the
identity $\id_f \colon f \to f$ has a transpose $h \colon \id_B \to f^f$; so we can compute
the following pullback on ${\cal C}/B$ that defines $\Pi_fx$ as $h^{\ast}(x^f)$.
\[\begin{tikzcd}
\Pi_fX \rar\dar[swap]{\Pi_fx} & X^f \dar{x^f} \ar[bend left]{ddr}{(f \circ x)^f} & \\
B \rar{h} \ar[bend right, swap]{drr}{\id_B} & A^f\drar{f^f} & \\
& & B
\end{tikzcd}\]
Note that $\Pi_f$ is defined in objects as the composition of two functors,
thus, it can be directly extended to morphisms. We only have to prove
that there is a natural bijection $\hom(f^{\ast}y,x) \cong \hom(y,\Pi_fx)$.

By the universal property of the pullback, each $k \colon y \to \Pi_fx$
determines two pullback projections $k_1\colon y \to (f \circ x)^f$ and
$k_2 \colon y \to \id$ such that $x^f \circ k_1 = h \circ k_2$. Applying the adjunction,
in both sides of the equation we see that they are determined by
morphisms $j \colon f^{\ast}Y \to X$ such that $f^{\ast}y = x \circ j$.
#+latex: \\[-40pt]
\[\begin{prooftree}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&] 
y \rar{k_2}\& \id \rar{h} \& f^f \end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&]
f \times y \rar{f^{\ast} y} \& f \rar{\id} \& f \end{tikzcd}}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&] 
y \rar{k_1}\& (f \circ x)^f \rar{x^f} \& f^f \end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&]
f \times y \rar{j} \& f \circ x \rar{x} \& f \end{tikzcd}}
\noLine
\BIC{}
\end{prooftree}\]
#+latex:\\[-40pt]
But those morphisms are precisely morphisms $f^{\ast}y \to x$ in ${\cal C}/A$,
and we have established the natural bijection.
#+latex:\\[-10pt]
\[\begin{tikzcd}
f^{\ast}Y \rar{k} \dar[swap]{f^{\ast}y} & 
X \dar{x} \ar[bend left]{ddr}{f \circ x} & \\
A \rar{\id} \ar[bend right, swap]{drr}{f} & 
A\drar{f} & \\
& & B
\end{tikzcd}\]
#+END_proof

**** Presheaf categories are locally cartesian closed                                    :ignore:
We proved earlier that /generalized sets/, or presheaves, were
cartesian closed (Proposition [[proposition-presheaves-ccc]]); we will now prove
that they are actually locally cartesian closed.

# Proof from [Awodey]

#+ATTR_LATEX: :options [Presheaf categories are locally cartesian closed]
#+BEGIN_theorem
Any presheaf category $\Set^{{\cal C}^{op}}$ from a small category ${\cal C}$ is locally cartesian
closed (see cite:awodey10).
#+END_theorem
#+BEGIN_proof
We will prove that given any $A \in \Set^{{\cal C}^{op}}$, there exists a small category ${\cal D}$
such that there is an equivalence of categories $\Set^{{\cal D}^{op}} \simeq \Set^{{\cal C}^{op}}/A$. Thus,
every slice is cartesian closed as shown in Proposition [[proposition-presheaves-ccc]]
and by the characterization of Theorem [[theorem-characterization-lccc]], the
whole category is locally cartesian closed.

We take ${\cal D}$ as a particular case of a comma category where objects are
arrows $f \colon YC \to A$ in $\Set^{{\cal C}^{op}}$ from the Yoneda embedding (Definition [[def-yoneda-functor]]) of an object
$C \in {\cal C}$ to the fixed object $A$.  Morphisms between two objects
$f \colon YC \to A$ and $f' \colon YC' \to A$ are commutative triangles determined by
arrows $\varphi \colon YC \to YC'$ such that $f' \circ \varphi = f$.
\[\begin{tikzcd}[column sep=tiny]
YC \ar{rr}{\varphi}\drar[swap]{f} && YC'\dlar{f'} \\
& A &
\end{tikzcd}\]
As the Yoneda functor provides a full and faithful embedding,
an arrow $\varphi$ on these conditions must be of the form $\varphi = Yh$ for
a unique $h \colon C \to C'$. Note how this category ${\cal D}$ can be fully and
faithfully embedded inside $\Set^{{\cal C}^{op}}/A$ by simply reinterpreting its
objects as objects of the slice category, this embedding defines a
functor $I \colon {\cal D} \to \Set^{{\cal C}^{op}}/A$.

A functor $\varPhi \colon \Set^{{\cal C}^{op}}/A \to \Set^{{\cal D}^{op}}$ can be now defined on objects
as $\varPhi(q) = \hom_{\Set^{{\cal C}^{op}}/A}(I(-),q)$, which is a composition of functors.
It can be seen that this functor determines an equivalence.
# TODO: Show that it is an equivalence
#+END_proof

*** Dependent types
**** Dependent types                                              :ignore:
In the same way that cartesian closed categories model the types of
the simply typed lambda calculus, locally cartesian closed categories
model *dependent types* that can depend on elements of another type.
Each dependent type $B$ depending on values of type $A$ can be also
seen as a family of types parametrized over the other type $\{B(a)\}_{a : A}$.
This extension of type theory forces us to revisit the notion of
typing context.

# Cite Martin-Lof, Seely, Newstead

**** Contexts                                                     :ignore:
*Typing contexts* for dependent type theory are given as a list of
variables
\[
\Gamma = (a_1 : A_1, a_2 : A_2, \dots, a_n : A_n) 
\]
where each type $A_i$ can depend on the variables $a_1,\dots,a_{i-1}$. The
core syntax of dependent type theory can be expressed in terms of
*substitutions* between contexts. A substitution from a context $\Delta$
to $\Gamma$ is written as $\sigma \colon \Delta \to \Gamma$, and is given by a list of terms
$(t_1,\dots,t_n)$ such that
\[
\Delta \vdash t_1 : A_1,\quad
\Delta \vdash t_2 : A_2[t_1/a_1],\quad
\dots,\quad
\Delta \vdash t_n : A_n[t_1,\dots,t_{n-1}/a_1,\dots,a_{n-1}],
\]
that is, a context can be substituted into another if the list of
terms of the second one can be built from the first one.

**** Categorical interpretation                                   :ignore:
The interpretation of a dependent type theory as a category takes
contexts $\Gamma$ as objects $\intr{\Gamma}$ and substitutions as morphisms. Note how there
exists an identity substitution $\sigma_{\mathrm{id}} \colon \Gamma \to \Gamma$ that simply lists the
variables of the context and how any two substitutions $\tau \colon \Gamma \to \Phi$ 
and $\sigma \colon \Delta \to \Gamma$ can be composed into $\tau \circ \sigma \colon \Delta \to \Phi$, which creates
the terms of $\Gamma$ from $\Delta$ following $\tau$ and uses again these terms to
create the terms of $\Phi$.

# TODO: Explicit substitution

**** Display maps and projections                                 :ignore:
A particular kind of substitutions will be *display maps*. If a term
can be constructed on a given context, $\Gamma \vdash a : A$, the context can be
extended with that term to $\Gamma, a : A$. Display maps are substitutions
of the form $\pi_A \colon \intr{\Gamma, a : A} \to \intr{\Gamma}$ that simply list the variables of $\Gamma$
and discard $a : A$.

This way, each type $A$ in a context $\Gamma$ is represented by the object
$\pi_A \colon \intr{\Gamma, a:A} \to \intr{\Gamma}$ of the slice category ${\cal C}/\intr{\Gamma}$; and each term of the
type, $\Gamma \vdash a : A$ is represented by a morphism from $\id \colon \intr{\Gamma} \to \intr{\Gamma}$, which
is the terminal object of $\Gamma/A$, as in the following diagram.
\[\begin{tikzcd}
\intr{\Gamma} \rar{a} \drar[equal] & \intr{\Gamma, a:A} \dar{\pi_A} \\
& \intr{\Gamma}
\end{tikzcd}\]

# TODO: From Shulman17, not all objects are of this form, but they are
# equivalent to some object of this form.

*** Dependent pairs
The locally cartesian closed structure of a category induces new
type constructors in the type theory: dependent pairs and dependent
functions. Their meaning under the Curry-Howard interpretation is that
of the existential and universal quantifiers, respectively.

*Dependent pair types*, or *\Sigma-types*, can be seen as a
generalized version of product types. Given a family of types parametrized
by another type, $\{B(a)\}_{a : A}$, the elements of $\sum_{a:A}B(a)$
are pairs $\pair{a,b}$ with a first element $a : A$ and a
second element $b : B(a)$; that is, the type of the second
component depends on the first component.  This type is often written
as $\Sigma (a:A), B(a)$ and it corresponds to the intuitionistic
existential quantifier under the /propositions as types/
interpretation. That is, the proof of $\exists (a:A), B(a)$ must be
seen as a pair given by an element $a$ and a proof of $B(a)$.

In a locally closed cartesian category, a type $B$ depending on $\Gamma, a:A$,
can be written as $\pi_B \colon \intr{\Gamma, a:A, b:B} \to \intr{\Gamma, a:A}$; then, the type $\sum_{a:A}B$
is given by the object
\[
\Sigma_{\pi_A}\pi_B \colon \intr{\Gamma, a:A, b:B} \to \intr{\Gamma}.
\]
That is, the sigma type over a type is left adjoint to the
weakening that determines that type; this left adjoint, as we proved
in Proposition [[prop-leftadjointweak]], is given by postcomposition with
$\pi_A$. Thus, categorically, the type $\sum_{a:A} B(a)$ is given in the empty
context by the composition of the projections that give rise to the
type $A$ and to the type $B$ in the context of $A$.
\[\begin{tikzcd}
\intr{x : A, y : B} \rar{\pi_B} & \intr{x : A} \rar{\pi_A} & 1
\end{tikzcd}\]
Thus, elements of this type can be built categorically with an element
of $a : A$, using a pullback to create the context $\intr{B(a)}$ and then providing
an element $b : B(a)$.
\[\begin{tikzcd}
\intr{\Gamma} \rar{b} \drar[equal] \ar[bend left]{rr}{\pair{a,b}} & 
\intr{\Gamma,y : B(a)} \dar\rar &
\intr{\Gamma,x:A,y:B} \dar{\pi_B} \ar[bend left=70]{dd}{\pi_{\Sigma}} \\
& \intr{\Gamma} \rar{a}\drar[equal] & \intr{\Gamma, x : A} \dar{\pi_A} \\
&& \intr{\Gamma}
\end{tikzcd}\]
This can be rewritten as the following introduction rule.
\begin{prooftree}
\AXC{$\Gamma \vdash a : A$}
\AXC{$\Gamma \vdash b : B[a/x]$}
\BIC{$\Gamma \vdash \pair{a,b} : \sum_{x:A}B$}
\end{prooftree}

The adjunction in the slice category can be then particularized
in the following two cases, taking $\delta \colon \intr{\Gamma,A} \to \intr{\Gamma,A,A}$ to be
the substitution that simply duplicates the $A$.
\begin{prooftree}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&,column sep=tiny,row sep=small] 
\& \intr{\Gamma,A} \& \\ 
\intr{\Gamma,A,B} \ar{rr}{\delta\circ \pi_{B}} \urar[bend left] \&\&
\intr{\Gamma,A,A} \ular[bend right]
\end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&,column sep=tiny,row sep=small] 
\intr{\Gamma, \sum_{a:A}B} \ar{rr}{\mathrm{fst}} \drar[bend right] \&\& 
\intr{\Gamma,A} \dlar[bend left] \\
\& \intr{\Gamma} \&
\end{tikzcd}}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&,column sep=tiny,row sep=small] 
\& \intr{\Gamma,A} \& \\
\intr{\Gamma, A, B} \ar{rr}{id} \urar[bend left] \&\&
\intr{\Gamma, A, B} \ular[bend right]
\end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&,column sep=tiny,row sep=small] 
\intr{\Gamma, \sum_{a:A}B} \ar{rr}{\mathrm{snd}} \drar[bend right] \&\&
\intr{\Gamma, A, B} \dlar[bend left] \\
\& \intr{\Gamma} \&
\end{tikzcd}}
\noLine
\BIC{}
\end{prooftree}
These two equalities represent two elimination rules.
\begin{prooftree}
\AXC{$\Gamma \vdash m : \sum_{x:A} C$}
\UIC{$\Gamma \vdash \fst(m) : A$}
\AXC{$\Gamma \vdash m : \sum_{x:A} C$}
\UIC{$\Gamma \vdash \snd(m) : C[\fst(m)/a]$}
\noLine
\BIC{}
\end{prooftree}
We have two beta rules $\fst\pair{a,b} \equiv a$ and $\snd\pair{a,b} \equiv b$, and a uniqueness
rule $m \equiv \pair{\fst(m), \snd(m)}$.

*** Dependent functions
*Dependent function types*, or *\Pi-types*, can be seen as a generalized
version of function types. Given a family of types parametrized by another
type, $\{B(a)\}_{a : A}$, the elements of $\prod_{x:A} B(x)$ are functions
with the type $A$ as domain and a changing codomain $B(x)$, depending on
the specific element $x$ to which the function is applied. This type is often
written also as $\Pi(x:A), B(x)$ to resemble the universal quantifier; under
the /propositions as types/ interpretation, it would correspond to the proof
that a proposition $B$ holds for any $x : A$, that is, $\forall (x : A), B(x)$.

In a locally closed cartesian category, given a type $A$ in a context $\Gamma$, as
$\pi_A \colon \intr{\Gamma, a:A} \to \intr{\Gamma}$; and $B$ a type depending the context $\Gamma, a:A$, as
$\pi_B \colon \intr{\Gamma, a:A, b:B} \to \intr{\Gamma, a:A}$, the type $\prod_{a:A}B$ is given by the object
\[
\Pi_{\pi_A} \pi_{B} \colon \intr{\Gamma, a:A, b:B} \to \intr{\Gamma}.
\]
That is, the dependent function type over a type is right adjoint to
the weakening that determines that type.

Thus, categorically, the type $\prod_{a:A}B(a)$ is given in the empty context as the
adjoint $\pi_A^{\ast} \dashv \Pi_{\pi_A}$ of the morphism representing the type $B$. Elements of this 
type can be built applying the adjunction on the
diagram of any term of type $B$ that assumes $a : A$ in the context.
\[\begin{tikzcd}
\intr{\Gamma, a : A} \rar{b} \drar[equal] &
\intr{\Gamma, a : A, b : B} \dar{\pi_B} &
\intr{\Gamma} \rar{(\lambda a.b)} \drar[equal] &
\intr{\Gamma, z : \prod_{a:A} B} \dar{\pi_{\prod}} \\
& \intr{\Gamma, a : A}
&
& \intr{\Gamma}
\end{tikzcd}\]

That is, we have the following adjunction and counit in the slice
category
\begin{prooftree}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&,column sep=tiny,row sep=small] 
\& \intr{\Gamma,A} \& \\ 
\intr{\Gamma,A} \ar{rr}{b} \urar[bend left] \&\& 
\intr{\Gamma,A,B} \ular[bend right]
\end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&,column sep=tiny,row sep=small] 
\intr{\Gamma} \ar{rr}{(\lambda a.b)} \drar[bend right] \&\& 
\intr{\Gamma, \prod_{a:A}B} \dlar[bend left] \\ 
\& \intr{\Gamma} \&
\end{tikzcd}}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&,column sep=tiny,row sep=small] 
\& \intr{\Gamma,A} \& \\
\intr{\Gamma,A,\prod_{a:A}B} \ar{rr}{app} \urar[bend left] \&\& 
\intr{\Gamma,A,B} \ular[bend right]
\end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&,column sep=tiny,row sep=small] 
\intr{\Gamma, \prod_{a:A}B} \ar{rr}{\mathrm{id}} \drar[bend right] \&\&
\intr{\Gamma, \prod_{a:A}B} \dlar[bend left] \\ 
\& \intr{\Gamma} \&
\end{tikzcd}}
\noLine
\BIC{}
\end{prooftree}
which can be rewritten as introduction and elimination rules.
\begin{prooftree}
\AXC{$\Gamma, a : A \vdash b : B$}
\UIC{$\Gamma \vdash (\lambda a.b) : \prod_{a:A}B$}
\AXC{$\Gamma \vdash a : A$}
\AXC{$\Gamma \vdash f : \prod_{a:A}B$}
\BIC{$\Gamma \vdash f\ a : B(a)$}
\noLine
\BIC{}
\end{prooftree}
We have the equalities $(\lambda a.b)\ a' \equiv b[a'/a]$ and $(\lambda a.f\ a) \equiv f$ as
beta and eta rules.

** Working in locally cartesian closed categories
*** Examples of dependent types
**** Vectors                                                      :ignore:
#+ATTR_LATEX: :options [Vectors]
#+BEGIN_exampleth
A common example of dependent types are vectors of elements of
a fixed type $A$ varying in length. They can be described as a
family of types $\mathrm{Vect}(n)$ depending on a parameter $n \in \mathbb{N}$.
For example, given $a_0,a_1,a_2 : A$, we can construct the element
$(a_0,a_1,a_2) : \mathrm{Vect}(3)$. We will study what it means to give an
element of the types
\[
\sum_{n : {\mathbb{N}}} \mathrm{Vect}(n) 
\quad\text{ and }\quad
\prod_{n : \mathbb{N}} \mathrm{Vect}(n).
\]

In the first case, we can build an element of $\sum_{n:\mathbb{N}} \mathrm{Vect}(n)$
following the characterization of the adjunction.
\[\begin{tikzcd}
\intr{\ast} \rar{w} \drar[equal] \ar[bend left]{rr}{\pair{m,w}} & 
\intr{v : \mathrm{Vect}(m)} \dar\rar &
\intr{n:\mathbb{N}, v : \mathrm{Vect}(n)} \dar{\pi_B} \ar[bend left=70]{dd}{\pi_{\Sigma}} \\
& \intr{\ast} \rar{m}\drar[equal] & \intr{n : \mathbb{N}} \dar{\pi_A} \\
&& \intr{\ast}
\end{tikzcd}\]
That is, we have to provide a morphism from the empty context
to the natural numbers $m : \intr{\ast} \to \intr{n : \mathbb{N}}$, or, in other words, an
element of $\mathbb{N}$. Computing the pullback of the dependent type
of vector over this element gives us the context $\intr{v : \mathrm{Vect}(m)}$
of vectors of length $m$. Now, we only have to provide a
morphism $w \colon \intr{\ast} \to \intr{v : \mathrm{Vect}(m)}$, or, in other words, a
vector of $m$ elements. 

In conclusion, elements of $\sum_{n : \mathbb{N}} \mathrm{Vect}(n)$ are of the form
$\pair{m,w}$, where $m : \mathbb{N}$ and $w : \mathrm{Vect}(m)$. An example would be
$\pair{2,(a_0,a_1)} : \sum_{n : \mathbb{N}} \mathrm{Vect}(n)$.

In the second case, we can build an element of $\prod_{n:\mathbb{N}} \mathrm{Vect}(n)$
following the adjunction.
\[\begin{tikzcd}
\intr{n : \mathbb{N}} \rar{t} \drar[equal] &
\intr{n : \mathbb{N}, v : \mathrm{Vect}(n)} \dar{\pi_{\mathrm{Vect}}} &
\intr{\ast} \rar{(\lambda n.t)} \drar[equal] &
\intr{v : \prod_{n:\mathbb{N}} \mathrm{Vect}(m)} \dar{\pi_{\prod}} \\
& \intr{n : \mathbb{N}}
&
& \intr{\ast}
\end{tikzcd}\]

That is, we have to provide a morphism $\intr{n : \mathbb{N}}\to \intr{n : \mathbb{N}, v : \mathrm{Vect}(n)}$
making the first diagram commute. This is to build a term $t : \mathrm{Vect}(n)$
assuming a given $n : \mathbb{N}$ in the context; in other words, a function 
sending each $n$ to a vector of $n$ elements. Once it is built, the adjunction
gives us a term $(\lambda n.t) : \prod_{n:\mathbb{N}} \mathrm{Vect}(n)$ in the empty context.

In conclusion, elements of $\prod_{n:\mathbb{N}} \mathrm{Vect}(n)$ are functions sending each
natural to a vector of that length. An example would be a function
$(\lambda m. (a_0,\overset{m}{\dots},a_0))$ sending each $m$ to a vector of repeated $a_0\text{'s}$.
#+END_exampleth

**** Theorem of choice                                            :ignore:
#+ATTR_LATEX: :options [The theorem of choice]
#+BEGIN_exampleth
<<theorem-choice>>
A proposition $P$ could be given as a family of types parametrized
over another type $A$, where $P(a)$ is inhabited if and only if
the proposition holds for $a : A$.

A proof of the existential quantifier $\sum_{a:A}P(a)$ would be given
by a pair $\pair{a,p}$, where $a:A$ would be a fixed element and $p : P(a)$
would be the proof that the proposition holds for $a$. A proof of
the universal quantifier $\prod_{a:A}P(a)$ would be a function sending
each $a:A$ to a proof $p : P(a)$.

As an example, suppose a relation $R$, a family of types parametrized
over two types $A,B$. We will prove the following theorem
\[
\left(\prod_{(a:A)} \sum_{(b : B)} R(a,b)\right) \to 
\left( \sum_{(g : A \to B)}\prod_{(a:A)} R(a,g(a)) \right).
\]

#+begin_proof
In order to prove the implication, we assume that we have a term
$f : \prod_{a:A}\sum_{b:B}R(a,b)$, and construct a term of type
$\sum_{g:A\to B}\prod_{a:A}R(a,g(a))$. The first step is to provide a function
of type $A \to B$, and $g :\equiv \lambda a.\fst(f(a))$ is exactly of this type. The
second step is to provide a term of type $\prod_{a:A}R(a,\fst(f(a)))$, but now
the function $\lambda a.\snd(f(a))$ is exactly of this type.
#+end_proof
# TODO: Annotate each term with its type

Surprisingly, the theorem we have just proved reads clasically as
#+begin_quote
"If for all $a:A$ there exists a $b:B$ such that $R(a,b)$, then
there exists a function $g : A \to B$ such that for each $a:A$,
$R(a,g(a))$."
#+end_quote
and this is a form of the *axiom of choice*. Have we just proved
the axiom of choice? The key insight here is that $\Sigma$ must not be
read as the classical "there exists", but as a constructivist 
existential quantifier that demands not only to merely prove that
something exists but to explicitly construct it. A more accurate
read would be
#+begin_quote
"If for all $a:A$ we have a rule to explicitly construct a $b:B$
such that $R(a,b)$, then we can use that rule to define a function
$g : A \to B$ such that for each $a:A$, $R(a,g(a))$."
#+end_quote
and this trivial-sounding theorem is known as the *theorem of choice*.
The moral of this example is that, when we work in type theory, we
are working inside constructivist mathematics and the existential quantifier
has a fundamentally different meaning. Later, we will see a
technique that will allow us to recreate the classical existential
quantifier.
#+END_exampleth
*** Equality types
<<sec-equalitytypes>>
*Equality* in our theory comes from an adjunction, as was first proposed
in cite:lawvere70. The equality type
between elements of type $A$ will be represented by the diagonal morphism
$\vartriangle \colon A \to A \times A$ as an object of ${\cal C}/(A \times A)$. It is thus a type parametrized
over two elements $x,y:A$, written as $(x = y)$. An element of an equality
type, $p : x = y$ must be read as a proof that $x$ and $y$ are equal.

In general we have that, for any two objects in a slice category, $f \colon B \to A$ 
and $g\colon C \to A$, morphisms $f \to g$ correspond naturally to sections of the
pullback $f^{\ast}(g) \colon f^{\ast}C \to B$; as in the following diagram.
\[\begin{array}{lll}\begin{tikzcd}
f^{\ast}C \rar\dar & C\dar{g} \\
B\rar{f}\uar[dashed,bend left]{\widetilde k} & A
\end{tikzcd} &\qquad& \begin{tikzcd}[column sep=tiny]
B \drar[swap]{f}\ar[dashed]{rr}{k} && C\dlar{g} \\
& A &
\end{tikzcd}\end{array}\]
Given any $k$ in the diagram above, we can construct $\widetilde k$ using the
universal property of the pullback; conversely, the fact that
$\widetilde k$ is a section gives us a $k$ by composition with $f^{\ast}C \to C$.

In particular, let $\pi_C \colon C \to A \times A$ or be a family
of types $C(x,y)$ parametrized by two elements $x,y:A$. We have that any morphism
from the equality type to $C$ corresponds to a section to $\vartriangle^{\ast}\!\! C$, which
is, by substitution, the family of types $C(x,x)$.
\[\begin{array}{lll}\begin{tikzcd}
\phantom{f}\vartriangle^{\ast}\!\! C \rar\dar & C\dar{\pi} \\
A\rar{\vartriangle}\uar[dashed,bend left]{\widetilde k} & A\times A
\end{tikzcd} &\qquad& \begin{tikzcd}[column sep=tiny]
A \drar[swap]{\vartriangle}\ar[dashed]{rr}{k} && C\dlar{\pi} \\
& A\times A &
\end{tikzcd}\end{array}\]
A section $\widetilde k$ of this form is precisely a term $x :A \vdash c : C(x,x)$,
while a map $k$ is a term $x:A,y:A,p:x=y \vdash c:C(x,y)$. Thus,
we have the following elimination rule for equality types, called
*J-eliminator* in type theory literature. See cite:shulman17 for details.
\begin{prooftree}
\AXC{$\Gamma \vdash a : A$}
\noLine
\UIC{$\Gamma, x : A \vdash c:C(x,x)$}
\AXC{$\Gamma \vdash b : A$}
\noLine
\UIC{$\Gamma \vdash p : a = b$}
\BIC{$\Gamma \vdash \J_C(c,p) : C(a,b)$}
\end{prooftree}
The rule informally says that, if we want to prove some property
$C(a,b)$ for each $a,b : A$, and we have $a = b$, we only need to prove
$C(x,x)$ for each $x:A$. Moreover, if we consider the unit of the
adjunction, as shown in the following diagram,
\[\begin{array}{lll}\begin{tikzcd}
\phantom{f}\vartriangle^{\ast}\!\! A \rar\dar & A\dar{\vartriangle} \\
A\rar{\vartriangle}\uar[dashed,bend left]{\refl} & A\times A
\end{tikzcd} &\qquad& \begin{tikzcd}[column sep=tiny]
A \drar[swap]{\vartriangle}\ar[dashed]{rr}{\id} && C\dlar{\vartriangle} \\
& A\times A &
\end{tikzcd}\end{array}\]
we have a section $\refl \colon A \to \vartriangle^{\ast}\!\!A$ that expresses reflexivity, $x = x$
for each $x:A$, and corresponds to the following introduction rule.
\begin{prooftree}
\AXC{$\Gamma \vdash a : A$}
\UIC{$\Gamma \vdash \refl_a : a = a$}
\end{prooftree}
Introduction and elimination rules are related by $\J_C(c,\refl_a) \equiv c[x/a]$;
that is, the J-eliminator can return $c$ in the reflexivity case.

We can still generalize the rule to allow $C$ to be a family of types also
parametrized over $p$, of the form $C(x,y,p)$.
\begin{prooftree}
\AXC{$\Gamma \vdash a : A$}
\noLine
\UIC{$\Gamma, x : A \vdash c:C(x,x,\refl_x)$}
\AXC{$\Gamma \vdash b : A$}
\noLine
\UIC{$\Gamma \vdash p : a = b$}
\BIC{$\Gamma \vdash \J_C(c,p) : C(a,b,p)$}
\end{prooftree}
The corresponding computation rule would be $\J_C(c,\refl)\equiv c[a/x]$.

*** Subobject classifier and propositions
<<sec-subobject-propositions>>
# [[https://www.youtube.com/watch?v=zUPBEQe4Ti8][Internal Languages for Higher Toposes - Michael Shulman - YouTube]]

# TODO: Rewrite this as "Subobject classifiers are ..."
A *subobject classifier* is an object $\Omega$ with a monomorphism $\mathrm{true} \colon 1 \to \Omega$
such that, for every monomorphism $m : S \to X$, there exists a unique $\chi$
such that
\[\begin{tikzcd}
S\rar{} \dar[swap, hook]{m} & 
1 \dar{\mathrm{true}} \\
X\rar[dashed]{\chi} & \Omega
\end{tikzcd}\]
is a pullback square.

# Characteristic function; notion of sets. Subobject classifiers do not need to exist.

Now, if we have a type given by a monomorphism, $\intr{\Gamma , x : P} \to \intr{\Gamma}$,
by the defining property of the subobject classifier,
we have a unique characteristic morphism $P \colon \intr{\Gamma} \to \intr{\Omega}$, which can
be read as $\Gamma \vdash P \colon \Omega$, meaning that $\Omega$ is a type whose elements are
themselves types (see cite:shulman17).
\[\begin{tikzcd}
\intr{\Gamma , x : P}\rar{} \dar[swap, hook]{} & 
1 \dar{\mathrm{true}} \\
\intr{\Gamma} \rar[dashed]{\chi_P} & \intr{\Omega}
\end{tikzcd}\]
A type $P$ determined by a monomorphism, by definition, must have any
two of its elements are equal. Thus, the elements of $\Omega$ are the
types with at most one element; these types are usually called
*propositions* in type theory. This can be expressed by the
following rule.
\begin{prooftree}
\AXC{$\Gamma \vdash P : \Omega$}
\AXC{$\Gamma \vdash a : P$}
\AXC{$\Gamma \vdash b : P$}
\TIC{$\Gamma \vdash \mathrm{isProp}_P(a,b) : a = b$}
\end{prooftree} 
Any two proofs of a proposition (in the sense of type theory) must be
equal, and thus, propositions allow us to reintroduce the notion of
proof irrelevance.

*** Propositional truncation
<<sec-proptrunc>>
Propositions are types, but not all types are propositions; a type $A$
may have multiple distinct elements, witnessing different proofs of
the same fact. We could, however, /truncate/ a type into a proposition
$\|A\|$ by postulating that any two of its proofs $p,q : \|A\|$ should be equal,
$p = q$. In this case, to provide an element of $A$ would mean to explicitly
construct a proof of $A$; whereas to provide an element of $\|A\|$ would mean
to witness that $A$ can be proved, without constructing any proof.

For instance, there are four distinct elements of
\[
\sum_{(n,m) : \mathbb{N} \times \mathbb{N}} (n + m = 3),
\]
each one of them providing an ordered pair of natural numbers that add up to $3$.
In contrast, there is a unique element of
\[
\left\|\sum_{(n,m) : \mathbb{N} \times \mathbb{N}} (n + m = 3) \right\|,
\]
that simply witnesses the existence of some pair of naturals that add
up to $3$, without explicitly pointing to it. In this sense, the truncated
version resembles more the existential quantifier of classical logic; while
the untrucated version demands the explicit construction of an example.

# Because of this, we write the combination $\| \sum \dots \|$ as $\exists \dots$, like in 
# \[
# \bigexists_{(n,m) :\mathbb{N} \times \mathbb{N}} (n + m = 3).
# \]

#+begin_exampleth
<<example-type-axiom-of-choice>>
As a second example, we can reformulate a nontrivial version of the
axiom of choice we discussed previously in Example [[theorem-choice]].
Note that
\[
\left(\prod_{(a:A)} \left\|\sum_{(b : B)} R(a,b) \right\|\right) \to 
\left\| \sum_{(g : A \to B)}\prod_{(a:A)} R(a,g(a)) \right\|,
\]
now represents the fact that we want to obtain evidence of the existence
of a function only knowing that for each $a$ there exists an element $b$ related
to it, but (crucially) without knowing which $b$ is related to $a$. This
new version of the Axiom of Choice is indeed independent of our theory
(see Chapter 3 of cite:hottbook).
#+end_exampleth

How should we represent truncations inside our theory? It can be proved (see cite:awodey04)
that propositional truncation is the left adjoint to the inclusion of propositions
into general types; and, if we assume the existence of this adjoint into the category
we are working into, we can use propositional truncations. That is, if $P$ is a
proposition and $A$ is an arbitrary type, we have the following adjunction
\begin{prooftree}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&] A \rar{}\& P \end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&] \|A\| \rar{}\& P \end{tikzcd}}
\end{prooftree}
which in practical terms means that, if we want to prove $\|A\| \to P$, where $P$
is a proposition, it suffices to prove $A \to P$, that is, to assume a particular
proof for $A$. Note that this corresponds to usual mathematical practice, where
having a proof of existence can be used to assume that we have explicitly
constructed the element and to prove a different proposition using it, with
the condition that we cannot refer later to the explicit element we used during
the proof.
** Topoi
*** Motivation
*Topoi* (singular /topos/) are category-theoretic models of
constructive mathematics; we can reason in its internal logic and
rebuild large parts of mathematics inside their structure. 
Each topos is thus an universe of mathematics with
different axioms and interpretations cite:bauer2017five; for example,

 * inside the Hayland's *realizability topos*, every function is computable
   and we can study Kleene's realizability theory (see cite:vanoosten08);

 * the *Dubuc topos* provides a non paradoxical formalization of notion of 
   "infinitesimal" used by Newton and Leibniz, and we can study synthetic
   differential geometry inside it (see cite:dubuc89);

 * inside the Johnstone's *topological topos*, we can reason with topological
   spaces and continuous functions between them (see cite:johnstone79), and under
   certain hypothesis, we can assume that all functions we can
   build are automatically continuous (see cite:escardo15).

Topoi are defined as locally cartesian closed categories with
a subobject classifier in which every finite limit exists. Usually,
we will be interested in *W-topoi*, or topoi with a natural numbers
object (in the sense of Example [[example-naturalnumbersobj]]) cite:leinster10.

The study of any of these theories is beyond the scope of this text.
However, as we have been relating type theory to the internal language
of locally closed cartesian categories with enough structure; we know
that type theory (depending on what constructions we assume) will have
models in categories like these. We only describe a particular case
developed by W. Lawvere while trying to provide an axiomatization of the
category of sets.

*** An Elementary Theory of the Category of Sets
Lawvere's Elementary Theory of the Category of Sets cite:lawvere64
provides a foundation for mathematics based on category theory.  It
describes the category $\Set$ in an abstract setting using eight
axioms; and the atomic, undefined notions of the theory are not
memberships and sets, but morphisms and composition. In the original
article some examples on how to do set theory inside the category
are shown.

Using the notation we have developed so far, Lawvere's axioms can be
reduced to the following definition. A model of the Elementary Theory
of the Category of Sets is

 * a /topos/, that is, a locally closed cartesian category with
   all finite limits and a subobject classifier,

 * which is */well-pointed/*, meaning that any two morphisms $f,g \colon A \to B$
   are equal if and only if $f \circ a = g \circ a$ for each $a \colon 1 \to A$; morphisms
   from the terminal object are called /global elements/, and this property
   can be thought as function extensionality;

 * which has a natural numbers object, in the sense of Example
   [[example-naturalnumbersobj]];
   
 * which satisfies the *Axiom of Choice*, meaning that point-surjective
   morphisms have a section; in terms of our previous Example [[example-type-axiom-of-choice]],
   we could translate this internally as

   \[
   \left(\prod_{(a:A)} \left\|\sum_{(b : B)} f(b) = a \right\|\right) \to 
   \left\| \sum_{(g : A \to B)}\prod_{(a:A)} f(g(a)) = a \right\|,
   \]

   for any $f \colon B \to A$.
   
Note that the category $\Set$, under the usual axioms, is a model of
this theory.  This can be seen, then, as an abstraction of set theory.
As we will see later, the Axiom of Choice implies the Law of Excluded
Middle, so we have finally recovered a classical foundation of
mathematics from category theory.

* Type theory
** Martin-Löf type theory
<<sec-mltt>>
In this chapter, we will exclusively work internally in dependent type
theory and use it as a constructive foundation of mathematics.  This
will have the added benefit that every formal proof in the system will
be a closed lambda term and checking that a proof is correct will amount to
typechecking the term.  Explicitly, the type theory we have been
describing in the previous sections corresponds to *Martin-Löf type theory*
cite:nordstrom90. Two libraries of formalized mathematics, correspoding
to two different foundational theories, have been built, containing a
verfied version of all the theorems on this chapter. See Section [[sec-verified]]
for links to the formalized proofs.

*** Programming in Martin-Löf type theory
Martin-Löf type theory and the internal language we have been
describing so far can also be regarded as a programming language in
which is possible to formally specify and prove theorems about the
code itself.  Formal proofs in this theory can be written in any
language with a powerful enough type system; examples of these include

 * *Agda*, a programming language that implements a variant of
   Martin-Löf type theory;

 * *Coq* cite:coq04 was developed in 1984 in INRIA; it implements
   Calculus of Constructions and was used, for example, to check a
   proof of the Four Color Theorem;
   # http://www.ams.org/notices/200811/tx081101382p.pdf
   # https://coq.inria.fr/about-coq

 * *Idris*, a programming language implementing dependent types
   and using a slightly modified version of intensional equality
   types;

 * *NuPRL* cite:nuprl86, a proof assistant implementing Martin-Löf
   /extensional/ Type Theory, which is different from the intensional
   theory in how it defines equality types;

 * *Cubical* cite:cohen16 and *RedPRL* cite:redprl provide
   experimental implementations of Cubical Type Theory, a different
   variant of type theory.

In this text, we will use Agda to write mathematics, taking ideas from
cite:Conor17.  We will check proofs in Martin-Löf type theory using its
type system.

*** Translation between categories and types
**** Dependent products                                                                  :ignore:
We can translate the categorical structure inside Agda as follows.
Dependent products exist naturally as dependent functions of the
language.

\setlength{\columnseprule}{0.4pt}
\begin{multicols}{2}
\begin{prooftree}
\AXC{$\Gamma, a : A \vdash b : B$}
\UIC{$\Gamma \vdash (\lambda a.b) : \prod_{a:A}B$}
\end{prooftree}
\vfill
\columnbreak
\vfill
\centering\ExecuteMetaData[agda-mltt/latex/Snippets.tex]{mlttproduct}
\vfill
\end{multicols}

**** Dependent sums                                                                      :ignore:
Dependent sums must be explicitly specified in the form of
/records/: data structures in which the type of every element
can depend on the previous ones.

\setlength{\columnseprule}{0.4pt}
\begin{multicols}{2}
\vfill
\begin{prooftree}
\AXC{$\Gamma \vdash a : A$}
\AXC{$\Gamma \vdash b : B[a/x]$}
\BIC{$\Gamma \vdash \pair{a,b} : \sum_{x:A}B$}
\end{prooftree}
\columnbreak
\centering\ExecuteMetaData[agda-mltt/latex/Snippets.tex]{mlttsum}
\end{multicols}

**** Naturals                                                                            :ignore:
Naturals, and initial algebras in general, can be defined as inductive
types with the /data/ keyword.  Functions over these types can be
constructed using their universal property, as we did in Example
[[example-naturalnumbersobj]].

\setlength{\columnseprule}{0.4pt}
\begin{multicols}{2}
\vfill
\begin{tikzcd}[fragile]
1+\mathbb{N}\rar{} \dar[swap]{\pair{0,\mathrm{succ}}} & 
1+\hom(\mathbb{N},\mathbb{N}) \dar{\pair{\id, \mathrm{succ}\,\circ\, -}} \\
\mathbb{N}\rar{+} &
\hom(\mathbb{N},\mathbb{N})
\end{tikzcd}
\columnbreak
\vfill
\centering\ExecuteMetaData[agda-mltt/latex/Snippets.tex]{mlttnat}
\end{multicols}

**** Equalities                                                                          :ignore:
Equality types are a particular case of an inductive family of types.
The induction principle over equalities is the /J-eliminator/ we
described in Section [[sec-equalitytypes]].

\setlength{\columnseprule}{0.4pt}
\begin{multicols}{2}
\vfill
\begin{prooftree}
\AXC{$\Gamma \vdash a : A$}
\UIC{$\Gamma \vdash \refl_a : a = a$}
\end{prooftree}
\columnbreak
\vfill
\centering\ExecuteMetaData[agda-mltt/latex/Snippets.tex]{mltteq}
\end{multicols}

**** Examples                                                                            :ignore:
Using all this machinery, we can prove facts about equality by
induction and prove facts about the natural numbers, as in the
following example, where we prove that $a = b$ implies $f(a) = f(b)$
and then use this fact to prove that $n + 0 = n$ for any $n : \mathbb{N}$
by induction.

#+latex: \noindent\rule[0.5ex]{\linewidth}{0.1pt}\small
#+latex: \ExecuteMetaData[agda-mltt/latex/Snippets.tex]{mlttzero}
#+latex: \normalsize\noindent\rule[0.5ex]{\linewidth}{0.1pt}

**** Propositions                                                                        :ignore:
Finally, we can define /propositions/ as those types where any two
elements are equal and postulate that truncations are propositions.
The induction principle for truncated types represents the adjunction
we described in Section [[sec-proptrunc]].

\setlength{\columnseprule}{0.4pt}
\begin{multicols}{2}
\vfill
\begin{prooftree}
\AXC{$\Gamma \vdash P : \Omega$}
\AXC{$\Gamma \vdash a : P$}
\AXC{$\Gamma \vdash b : P$}
\TIC{$\Gamma \vdash \mathrm{isProp}_P(a,b) : a = b$}
\end{prooftree}
\columnbreak
\vfill
\centering\ExecuteMetaData[agda-mltt/latex/Snippets.tex]{isprop}
\end{multicols}

\setlength{\columnseprule}{0.4pt}
\begin{multicols}{2}
\vfill
\begin{prooftree}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&] A \rar{}\& P \end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&] \|A\| \rar{}\& P \end{tikzcd}}
\end{prooftree}
\columnbreak
\vfill
\centering\ExecuteMetaData[agda-mltt/latex/Snippets.tex]{truncrec}
\end{multicols}

*** Excluded middle and constructivism
Using categories, we have strengthen the propositional logic we
described in Section [[sec-naturaldeduction]] to a fully-fledged higher
order logic in which we can construct mathematical proofs.
However, during all this process, we have not accepted the Law of
Excluded Middle; we do not assume that $P \vee \neg P$ for an arbitrary
proposition $P$. Note, however, that we do not negate it, neither: that would
cause a contradiction, as we actually proved $\neg\neg(P \vee \neg P)$ in
general in Section [[section-proof-lem]]. We are /agnostic/ regarding it.

Why are we not simply accepting it, as is common practice? The
Law of Excluded middle would affect the computational properties
of the theory. For instance, whenever we create a natural number
in our theory, we expect it to be a numeral of the form $\mathsf{succ}(\mathsf{succ}(\dots \mathsf{zero} \dots))$
for some number of $\mathsf{succ}$ applications. Inductive definitions
can only compute with natural numbers when they are on this form.  However,
if we were to postulate the Law of Excluded Middle, $\mathsf{LEM}\colon P \vee \neg P$, we should accept
the existence of numbers such as
\[ \mathsf{if}\ \mathsf{LEM}(\mathrm{RiemmanHypothesis})\ \mathsf{then}\ 0\ \mathsf{else}\ 1,\]
but we would not be able to compute them into a numeral.
We say that a type system has the /*canonicity property*/ if
every inhabitant of the $\mathbb{N}$ type is a numeral.

In any case, classical mathematics are a particular case of constructive
mathematics. We can choose to work inside classical mathematics,
although we would lose the computational content. When we choose not
to, we are working in constructive mathematics with a programming
language as it was first proposed by Errett Bishop cite:bishop67.

*** Extensionality and Diaconescu's theorem
<<sec-diaconescuth>>
If we want to recover classical mathematics, we should try to model
the axioms of the Elementary Theory of Sets into our locally closed
cartesian categories.  We already have natural numbers in Martin-Löf
type theory, and /well-pointedness/, for instance, is called /function/
/extensionality/ in type theory literature.

#+BEGIN_axiom
<<axiom-funext>>
*Function extensionality* states that, if any two functions $f,g \colon A \to B$
have the same images under the same arguments, they are, in fact, equal.
That is,
\[
\prod_{x:A}\left(f(x) = g(x)\right) \to (f = g).
\]
#+END_axiom

We postulate this in Agda as follows.

#+latex: \noindent\rule[0.5ex]{\linewidth}{0.1pt}\small
#+latex: \ExecuteMetaData[agda-mltt/latex/Snippets.tex]{wellpointed}
#+latex: \normalsize\noindent\rule[0.5ex]{\linewidth}{0.1pt}

The last ingredient is the Axiom of Choice.  This, like in the case of
the Law of Excluded Middle, will make us lose the computational
content of the theory. In fact, we can prove that, in general, the
Axiom of Choice implies the Law of Excluded Middle. This is the
statement of *Diaconescu's theorem*, for which we provide both a
natural proof and a computer-verified proof.

#+ATTR_LATEX: :options [R. Diaconescu, 1975]
#+BEGIN_theorem
<<th-diaconescu>>
The Axiom of Choice implies the Law of Excluded Middle.
#+END_theorem
#+BEGIN_proof
The proof we present is based in cite:altenkirch17 and cite:bauer2017five. 
Given any proposition $P$, we define $U = \left\{ x \in \left\{ 0,1 \right\} \mid (x = 0) \vee P\right\}$ and
$V = \left\{ x \in \{0,1\} \mid (x = 1) \vee P \right\}$, and we kwow that each one is inhabited.
By the axiom of choice, there exists a function $f \colon \left\{ U,V \right\} \to U \cup V$
such that $f(U) \in U$ and $f(V) \in V$.  We decide if $f(U)$ and
$f(V)$ are equal to $0$ or not by the induction principle. If $f(U) = 1$ or $f(V) = 0$, we
would have that $P$ must be true; and if $f(U) = 0$ and $f(V) = 1$, we
would have $\neg P$, for if $P$ were true, then $U$ would be equal to $V$
and thus, $0 = f(U) = f(V) = 1$.
#+END_proof

This proof has been implemented as follows. Note that we have only
assumed the Axiom of Choice (and therefore, the Law of Excluded
Middle) during this particular section of the text. In the next
section, we return to constructive mathematics, working with the real
numbers and extracting algorithms from proofs.

#+latex: \noindent\rule[0.5ex]{\linewidth}{0.1pt}\small
#+latex: \ExecuteMetaData[agda-mltt/latex/Snippets.tex]{diaconescu}
#+latex: \normalsize\noindent\rule[0.5ex]{\linewidth}{0.1pt}

*** Dedekind reals
<<sec-dedekindreals>>
In =Reals.agda=, we provide a formalized construction of the Dedekind
positive reals in intensional Martin-Löf type theory, implemented in
Agda. This implementation constructs reals as Dedekind cuts over the
*positive dyadic rationals* $D$; that is, over the rationals of the
form $a / 2^b$ for some $a,b : \mathbb{N}$. We also provide a library with all the
necessary lemmas proving that our constructions are well-defined.

Natural numbers are constructed as initial algebras (as described in
Example [[example-naturalnumbersobj]]). Dyadic rationals
are constructed as pairs of naturals endowed with a normalization property:
a fraction $a/2^b$ is /normalized/ if $a$ is an odd number or if $b$ is exactly zero.
\[
D = \sum_{(a,b) : \mathbb{N} \times \mathbb{N}} \left\|\mathrm{odd}(a) + \mathrm{isZero}(b) \right\|
\]
This technique ensures that each dyadic rational will be uniquely
represented by a term of type $D$. Finally, a real number $r : \mathbb{R}^+$ is 
constructed as the sum of the following data.

 * A *Dedekind cut*, $\mathrm{cut}_r : D \to \Omega$, representing a proposition parametrized over
   the positive dyadic rationals. Given $q : D$, the proposition $\mathrm{cut}_r(q)$ 
   is true if and only if $r < q$.

 * A proof $\| \sum_{q : D} \mathrm{cut}_r(q) \|$ witnessing that the Dedekind cut is *inhabited*, that
   is, there exists some $q$ such that $r < q$, providing an upper bound on the real
   number.

 * Two functions that witness that the cut is *round*. 
   That is, a dyadic $q : D$ is in the cut if and only
   if there is a smaller $p : D$ also in the cut. Symbolically,
   \small
   \[
   \left( \prod_{q : D} \mathrm{cut}_r(q) \to 
   \left\| \sum_{p : D} (p < q) \times \mathrm{cut}_r(p) \right\| 
   \right)
   \times
   \left( \prod_{q : D}
   \left\| \sum_{p : D} (p < q) \times \mathrm{cut}_r(p) \right\| \to 
   \mathrm{cut}_r(q) \right).
   \]
   \normalsize

The following code shows the core definition of the Agda
implementation.

#+latex: \noindent\rule[0.5ex]{\linewidth}{0.1pt}\small
#+latex: \ExecuteMetaData[agda-mltt/latex/Snippets.tex]{reals}
#+latex: \normalsize\noindent\rule[0.5ex]{\linewidth}{0.1pt}

Note that, under the intuitionistic interpretation, it is not the case 
in general that $\prod_{q : D} \mathrm{cut}_r(q) + \neg\, \mathrm{cut}_r(q)$ for an arbitrary $r : \mathbb{R}^+$; in fact,
numbers that are neither
equal nor distinct from zero could exist! as we mentioned earlier, a
formalization of infinitesimals is possible using this property, see
cite:bauer13. However, even if we cannot prove it in general, we can
prove $\mathrm{cut}_r(q) + \neg\, \mathrm{cut}_r(q)$ for some particular real numbers. We call these
numbers *located*, and, for these numbers, the computational nature of the
proof provides an algorithm that produces an infinite stream with the digits
of the number.

As a proof of concept, we define square roots, $\sqrt{-} : \mathbb{R}^{+}\to \mathbb{R}^{+}$, as
\[
\mathrm{cut}_{\sqrt{r}}(q) = 
\left\| \sum_{p : D} ( \mathrm{cut}_r(p)) \times \left(p < q^2\right) \right\|.
\]
We prove they are well-defined using several lemmas about the dyadic numbers
and we prove that $\sqrt{2}$ is located.  The Agda compiler is then able to
produce the first binary digits of $\sqrt{2} = 1.01101010000\dots$. Note that
this construction is thus being formalized in any locally cartesian closed
category with enough structure. Explicitly, we use the following Agda code;
it calls to already defined lemmas on the natural numbers when necessary
and it shows how existential elimination is written inside the language
to prove the necessary properties of the Dedekind cut.

#+latex: \noindent\rule[0.5ex]{\linewidth}{0.1pt}\small
#+latex: \ExecuteMetaData[agda-mltt/latex/Snippets.tex]{sqrt}
#+latex: \normalsize\noindent\rule[0.5ex]{\linewidth}{0.1pt}

Dedekind cuts are not the only path we can take in order to define
the real numbers in type theory. Reals can be also defined in terms
of Cauchy sequences, but the resulting construction is not in general
equivalent to ours. Only when we assume excluded middle, both Dedekind
and Cauchy reals become equivalent and the classical notion of real
number is recovered. A detailed discussion can be found in the last
chapters of cite:hottbook.

** Homotopy type theory
<<sec-hott>>
#+begin_quote
/And it soon became clear that the only long-term solution was somehow/
/to make it possible for me to use computers to verify my abstract,/
/logical, and mathematical constructions. When I first started to/
/explore the possibility, computer proof verification was almost a/
/forbidden subject among mathematicians.  The primary challenge that/
/needed to be addressed was that the foundations of mathematics were/
/unprepared for the requirements of the task./

  -- *Vladimir Voevodsky*, cite:voevodsky14.
#+end_quote

*** Homotopy type theory I: Equality
We have already discussed how, given any $x,y:A$, we can interpret
the equality type $(x = y)$, whose terms are witnesses of the equality.
For each $x : A$, there is a reflexivity element, $\refl : x = x$; and the
J-eliminator is interpreted as the following induction principle over
the type.
\[
\prod_{(C : \prod_{(x,y : A)}(x=y) \to {\cal U})} \left(
\left( \prod_{a:A} C(a,a,\mathsf{refl}) \right) \to
\prod_{(x,y : A)}\prod_{(p:x=y)} C(x,y,p)
\right).
\]
This induction principle allows us to prove symmetry, transitivity
and other properties of equality (we explicitly do so in =Base.agda=
and =Equality.agda=). However, it is not posible to prove by path
induction that every path is equal to the reflexivity path, that is,
\[
\prod_{(x : A)}\prod_{(p : x = x)} (p = \refl),
\]
is not derivable from the induction principle. This is equivalent to the
principle of *uniqueness of identity proofs*, it is also equivalent to
Streicher's Axiom K cite:streicher93 and it is independent
from Martin-Löf type theory.

#+ATTR_LATEX: :options [Uniqueness of identity proofs]
#+BEGIN_axiom
<<axiom-uip>>
Given any type $A$, two elements of the type $x,y : A$ and two
proofs of equality between them $p,q \colon (x = y)$, the two proofs
must be equal, $p = q$. In other words, there exists an element
of type
\[
\prod_{x,y:A}\prod_{p,q:(x=y)} p=q.
\]
#+END_axiom

If we do not assume this axiom, we open the possibility to the
existence of multiple different proofs of the same equality.
The structure of these proofs, endowed with symmetry and
transitivity, could be modeled into a groupoid; and this idea
allows us to construct models of type theory where the principle
of uniqueness of identity proofs does not hold (see cite:hofmann98).
If we also consider equalities between proofs of equality,
and equalities between proofs of equalities between equalities,
and so on, we would get a weak \omega-groupoid structure
cite:berg11. Following the *Grothendieck's Homotopy Hypothesis*,
groupoids can be regarded as an homotopical spaces, where equalities are
paths and equalities between equalities are homotopies between paths
(some work on this hypothesis can be read in cite:tamsamani96).

In any case, as the existence of this non-trivial structure is
independent of the theory, we need to introduce new axioms or new types
with nontrivial equalities if we want to profit from this interpretation. 
The introduction of Voevodsky's Univalence Axiom leads to *Homotopy Type theory*, an extension of
Martin-Löf type theory where we can work with this groupoid structure.
Under the identification of higher groupoids and homotopical types,
the new axiom allows us to reason in some sort of synthetic homotopy
theory, where paths and homotopies are primitive notions. For instance,
we can define the *fundamental group* (fundamental groupoid, if we also
want to consider higher structure) of a type $A$ in a point $a : A$ as
the type of loops $\pi_1(A,a) :\equiv a = a$, endowed with reflexivity and
transitivity. The *circle* can be defined as the freely generated
type with a single element $\mathsf{p} : \mathbb{S}^1$ and a nontrivial equality
$\mathsf{loop} : \mathsf{p} = \mathsf{p}$. Because it is freely
generated, we can apply symmetry to get a /different/ proof of $\mathsf{p} = \mathsf{p}$ which we
will call $\mathsf{loop}^{-1}$; moreover,
we can apply transitivity $n$ times to $\mathsf{loop}$ for an arbitrary $n$ to get a new proof
of $\mathsf{p} = \mathsf{p}$ which we will call $\mathsf{loop}^n$; these are the elements
of its fundamental group $\pi_1(\mathbb{S}^1, \mathsf{p})$.

In this setting, results such as the Van Kampen theorem or the
construction of Eilenberg-MacLane spaces have been formalized (see
cite:hottbook).

**** Note on the circle                                         :noexport:
Why isn't the circle a counterexample to Hedberg's theorem? When
we build a function

\[
\prod_{x,y : \mathbb{S}^1} (x = y),
\]

we need to fix a $b : x = y$, and then, we should check

\[\mathrm{transport}(loop)(b) = loop \cdot b = b.\]

But this does not hold, trivially.

*** Homotopy type theory II: Univalence
We say that there is an equivalence between two types $A$ and $B$
and we write it as $(A \simeq B)$ if there
is a /biinvertible/ map between them. Explicitly,
\small
\[
(A \simeq B) = \sum_{f : A \to B} \left(  
\left( \sum_{g : B \to A}\prod_{a : A} g(f(a)) = a \right)
\times
\left( \sum_{g : B \to A}\prod_{b : B} f(g(b)) = b \right)
\right).
\]
\normalsize
It can be shown that, for any pair of types $A$ and $B$, there exists
a function of type $\mathrm{idtoeqv} : (A =_{\cal U} B) \to (A \simeq B)$ that uses
identity functions to construct an equivalence from an equality.
The Univalence axiom states that this function is itself an
equivalence.

#+ATTR_LATEX: :options [Univalence]
#+BEGIN_axiom
<<axiom-univalence>>
For any pair of types $A,B : {\cal U}$, $\mathrm{idtoeqv} : (A = B) \to (A \simeq B)$ is
an equivalence. In particular, $(A = B) \simeq (A \simeq B)$.
#+END_axiom

In practical terms, this implies that isomorphic structures can
be identified. For example, we could consider the type of the
integers $\mathbb{Z}$ with the successor and predecessor functions and
create an equivalence $\mathbb{Z} \simeq \mathbb{Z}$ which can be turned into a nontrivial
equality $\mathbb{Z} = \mathbb{Z}$ via the Univalence axiom, representing that
integers, as a type, are equivalent to themselves after shifting
them by the successor function. In the file =FundGroupCircle.agda=, we
use this fact to prove, inside type theory, that $\mathbb{Z} = \pi_1(\mathbb{S}^1)$, 
(following cite:hottbook and cite:licata13). This result is
a proof, inside this synthetic homotopical setting, of the fact 
that the fundamental group of the circle is $\mathbb{Z}$.

#+latex: \noindent\rule[0.5ex]{\linewidth}{0.1pt}\small
#+latex: \ExecuteMetaData[agda-hott/latex/Snippets.tex]{circle}
#+latex: \normalsize\noindent\rule[0.5ex]{\linewidth}{0.1pt}

**** Note on the proof                                          :noexport:
We could think that this only proves that Z is the free group
over a single generator. After all, this is what the circle
is, when interpreted as a groupoid.

I think that the main problem with that view is that the
groupoid structure is not present inside the theory, it is
only visible from outside. When we prove this we need univalence
to internalize the structure of groupoid inside the theory,
using Z as a bridge.

** Verified formal proofs
<<sec-verified>>
All definitions and theorems from Sections [[sec-mltt]] and [[sec-hott]] have
been formalized into two Agda libraries whose complete code is presented
in navigable HTML format at the following links. Note that each
function name is a link to its definition.

 * https://mroman42.github.io/ctlc/agda-mltt/Total.html
 * https://mroman42.github.io/ctlc/agda-hott/Total.html

On the *Agda-mltt* library, we define the basic types for Martin-Löf
type theory. We have chosen to add propositions and propositional
truncations, as described in [[sec-subobject-propositions]], because of
their expressive power, even if they are not part of the usual presentations
of Martin-Löf type theory. In particular, they allow us to build the
type of Dedekind positive reals (see Section [[sec-dedekindreals]]). We
also prove Diaconescu's theorem and show how a classical setting could
be recovered (see Section [[sec-diaconescuth]]). More than a hundred
propositions about the natural numbers and the dyadic rationals have
been formalized in order to construct the real numbers, each one being
a function in dependently typed lambda calculus.

This first library assumes uniqueness of identity proofs (Axiom
[[axiom-uip]]), which eases some proofs but which is incompatible with
Univalence (Axiom [[axiom-univalence]]). This is why we will need a second
library in order to work with the Univalence axiom; this second
library will not assume uniqueness of identity proofs.  We also assume
well-pointedness in the form of function extensionality (Axiom
[[axiom-funext]]) and, only when working with Diaconescu's theorem
(Theorem [[th-diaconescu]]), we assume the Axiom of Choice.

On the *Agda-hott* library, we define again basic types for Martin-Löf
type theory, we again assume function extensionality (Axiom [[axiom-funext]]),
but this time we also assume Univalence Axiom. A more detailed study
of the notion of equality and equivalence follows, defining multiple
/equivalent/ notions of equivalence. We again define truncations and
relations, the natural numbers, the integers and some algebraic structures.
All this machinery is used while constructing the higher-inductive type
of the circle to prove that its fundamental group is $\mathbb{Z}$.

These two libraries are original developments. They both follow
ideas mainly from the Homotopy Theory book cite:hottbook, but also
from the Univalent Foundations library written with the Coq proof
assistant cite:unimath and the Coq homotopy theory library
cite:bauer17. The definition of the type of propositions follows
cite:escardoagda. Our second library compares to the highly more
complete and more technical cite:hott-in:agda by presenting only the
small subset of type theory necessary to compute the fundamental group
of the circle and thus simplifying the whole structure of the library.

* Conclusions
While proving on the order of a hundred lemmas about the natural
numbers only with the help of the Agda type checker, the need for
automation tools quickly arises.  They are available in the form of
tactic languages in more specialized proof assistants (see for
instance, LTac in Coq, cite:delahaye00); but it would be cleaner to
use the same language both to prove and to automate. Reflection is an
example of a technique that would help to leverage the power of /Agda
as a programming language/ to automate /Agda as a proof checker/; an
example of its usage is described in cite:vanderwalt12.  Maybe, using
these techniques, proving theorems on real analysis encoding more
complex theories such as synthetic differential geometry (cite:kock06)
would be possible in Agda.

It is conceivable that, in the future, mathematicians will be able
to write and check their proofs directly into a computer as part of
their routine. Reaching that stage will require a massive effort into
the study of foundations and implementation of languages, coupled
with the creation of tools and software easing the task for the
working mathematician.

In this text, we have discussed how intuitionistic logic provides
a useful generalization of classical logic with semantics in
cartesian closed categories and a computational interpretation
on simply-typed lambda calculus.  It seems plausible that a
similar discussion on monoidal categories and linear logic
could have been made. Linear logic can be interpreted as
a logic of resources where we can make a distinction
between, for example, two types of conjunctions: $A \otimes B$ means to
have both $A$ and $B$, while $A\& B$ means to have one or the other at
our choice (see cite:lafont95).  Monoidal categories provide
semantics for this logic (see cite:mellies09), we have many monoidal graphical
languages that would be worth exploring (see cite:selinger10), constructive
mathematics can be done with linear logic and it has an
interpretation on quantum computing (see cite:schreiber14 or cite:lago12).


# Automation in Agda
# Linear logic, monoidal categories 
# https://arxiv.org/abs/quant-ph/0312174

* Appendices
** Code
:PROPERTIES:
:UNNUMBERED: t
:END:

The complete code that generates this text, along with the code here
presented can be found at https://github.com/mroman42/ctlc.

The *Mikrokosmos* lambda interpreter has its documented code published
under a GNU General Public License v3.0 at
https://github.com/mroman42/mikrokosmos. Code for a previous stable
version on the Hackage platform can be found at
https://hackage.haskell.org/package/mikrokosmos. An HTML version of
the documented code can be accessed at
https://mroman42.github.io/mikrokosmos/haddock/.

Mikrokosmos has been released along with the following references.

 * A /User's guide/ for the command line interpreter. It details
   the installation procedure and the core functionality. It can be found at
   https://mroman42.github.io/mikrokosmos/userguide.html.

 * The online version of the interpreter, which can be accessed at 
   https://mroman42.github.io/mikrokosmos/.

 * An interactive /Tutorial on the lambda calculus/, following Sections
   [[sec-programming-untyped]] and [[sec-programming-typed]] from a more
   didactic perspective. It can be found at https://mroman42.github.io/mikrokosmos/tutorial.html.

 * The /Javascript interface/ and instructions on how to use it at
   https://github.com/mroman42/mikrokosmos-js.

 * The /IPython/Jupyter Mikrokosmos kernel/, whose code can be found at
   https://github.com/mroman42/jupyter-mikrokosmos. Tutorials in
   Jupyter notebook format can be found at
   https://github.com/mroman42/mikrokosmos-tutorials.

 * The /standard libraries/, which are also part of the interpreter from
   version 0.5.0. The code can be found at
   https://github.com/mroman42/mikrokosmos-lib.

The code for the Agda-mltt and Agda-hott libraries can be downloaded
from the main repository.  The easily-navigable HTML versions can be
found at

 * https://mroman42.github.io/ctlc/agda-mltt/Total.html,
 * https://mroman42.github.io/ctlc/agda-hott/Total.html.


# Mikrokosmos
# Mikrokosmos suite
# Agda-mltt
# Agda-hott

** Acknowlegments
:PROPERTIES:
:UNNUMBERED: t
:END:

\small
The opportunity of devoting my bachelor's thesis to this fascinating
subject has been made possible by Professor Pedro García-Sánchez and
Professor Manuel Bullejos.  They have provided me with corrections and
useful guidelines for the text and they have gone beyond their
obligation in their efforts to instruct me on how to expose these
ideas clearly.  Any deviation from this goal must be attributed to
my own inexperience.

I would like to thank the LibreIM community in general and Ignacio
Cordón, David Charte, Marta Andrés, José Carlos Entrena, Pablo
Baeyens, Antonio Checa, Daniel Pozo, and Sofía Almeida in particular,
for testing the interpreter and providing useful discussion and
questions on the topics of this text. Professor Luis Merino, Professor
Juan Julián Merelo and Braulio Valdivielso have made possible and
participated on the organization of meetings and workshops on these
ideas.

Finally, I would like to express my gratitude to Benedikt Ahrens and
the organizers of the School and Workshop on Univalent Mathematics at
the University of Birmingham, whose effort has given me the
opportunity to learn the fundaments of type theory and the Univalent
Foundations program.

This document has been written with Emacs26 and org-mode 9, using the
=org= file format and LaTeX as intermediate format. The document takes
some configurations forom the =classicthesis= [[http://www.latextemplates.com/templates/theses/2/thesis_2.pdf][template]] by André Miede
and modifications by Adrián Ranea, Alejandro García and David
Charte. The =minted= package has been used for code listings and the
=tikzcd= package has been used for commutative diagrams. The document
is released under a Creative Commons BY-SA 3.0 license, while the
source code can be redistributed under the terms of the GNU General
Public License. 
\normalsize

** Bibliography                                                                            :ignore:
bibliographystyle:alpha
bibliography:Bibliography.bib

** TODO Mikrokosmos complete code
** TODO Mikrokosmos user's guide
** TODO Agda code
* OLD Removed                                                                      :noexport:ignore:
# TODO: Example: quotients

** TODO Soundness up to isomorphism
** OLD Examples of comma categories
*** TODO Pointed sets
*** TODO The category of all categories
*** TODO Sheaves!
# Gluing
** TODO Comma categories
The idea of functor categories leads us to think about categories
whose objects are themselves diagrams on a category. The most relevant
examples, which will be useful in our development of categorical logic,
are the *comma categories*, and specially the particular case of a
*slice categories*.

#+ATTR_LATEX: :options [Comma category]
#+BEGIN_definition
Let ${\cal C},{\cal D},{\cal E}$ be categories with functors $F \colon {\cal C} \to {\cal E}$ and $G \colon {\cal D} \to {\cal E}$.
The *comma category* $(F \downarrow G)$ has

  * morphisms of the form $f \colon FC \to GD$ as objects, for $C \in {\cal C}$
    and $D \in {\cal D}$;
  * and pairs $\pair{k,h} \colon f \to f'$, where $k \colon C \to C'$ and $h \colon D \to D'$ are morphisms
    in ${\cal C}$ and ${\cal D}$ respectively such that $f' \circ Fk = Gh \circ f$.

Diagramatically, a morphism in this category is a commutative diagram
\[\begin{tikzcd}
\color{black!50}{FC} \rar{Fk} \dar[swap,color=black!50]{f} & 
\color{black!50}{FC'}\dar[,color=black!50]{f'} \\
\color{black!50}{GD} \rar{Gh} &
\color{black!50}{GD'}
\end{tikzcd}\]
where the objects of the category are drawn in grey.
#+END_definition

*** Slice category                                                 :ignore:
#+ATTR_LATEX: :options [Slice and coslice categories]
#+BEGIN_definition
A *slice category* is a particular case of a comma category $(F \downarrow G)$
in which $F = \mathrm{Id}$ is the identity functor and $G$ is a functor from the
terminal category, a category with only one object and its identity
morphism.
#+END_definition

A functor from the terminal category simply chooses an object
of the category. If we call $A = G(\ast)$, objects of this category
are morphisms $f \colon C \to A$, where $C \in {\cal C}$; and morphisms are $\pair{k} \colon f \to f'$,
where $k \colon C \to C'$ such that $f' \circ k = f$, as in the following diagram.
\[\begin{tikzcd}[remember picture, column sep=tiny]
\color{black!50}{C} \ar{rr}{k}\drar[swap,color=black!50]{f} &&
\color{black!50}{C'} \dlar[color=black!50]{f'} \\&
\color{black!50}{A} &
\end{tikzcd}\]
This slice category is conventionally written as ${\cal C}/A$. In general,
we can write $(F \downarrow A)$ when $G$ is a functor from the terminal category
picking an object $A$.

\\

**** TODO Old notation                                          :noexport:
This slice category is conventionally written as $({\cal C} \downarrow A)$. In
general, we write $(F \downarrow A)$ when $G$ is a functor from the terminal
category picking an object $A$; and we write $({\cal C} \downarrow G)$ when $F$ is
the identity functor.

*** Coslice category                                               :ignore:
*Coslice categories* are the categorical dual of slice categories.
Objects of this category are morphisms $f \colon C \to A$, where $C \in {\cal C}$;
and morphisms are $\pair{k} \colon f \to f'$, where $k \colon C \to C'$ such that $k \circ f' = f$,
as in the following diagram.
\[\begin{tikzcd}[remember picture, column sep=tiny]
& \color{black!50}{A} \drar[color=black!50]{f}\dlar[swap,color=black!50]{f'} &\\
\color{black!50}{C} \ar{rr}{k} & & \color{black!50}{C'}
\end{tikzcd}\]
This coslice category is conventionally written as $(A \setminus {\cal C})$.
In general, we can write $(A \downarrow G)$ when $F$ is a functor
from the terminal category picking an object $A$.

*** OLD Arrow category                                             :ignore:
#+ATTR_LATEX: :options [Arrow category]
#+BEGIN_definition
*Arrow categories* are a particular case of comma categories $(F \downarrow G)$
in which both functors are the identity. They are usually written as ${\cal C}^{\to}$.
Objects in this category are morphisms in ${\cal C}$, and morphisms in this
category are commutative squares in ${\cal C}$ as in the following diagram.
\[\begin{tikzcd}
\color{black!50}{A}\rar{k}\dar[swap,color=black!50]{f} & 
\color{black!50}{B} \dar[color=black!50]{f'} \\
\color{black!50}{A'}\rar{h} &
\color{black!50}{B'}
\end{tikzcd}\]
#+END_definition

** TODO Eta rule                                                                  :ignore:noexport:
\[\begin{prooftree}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&,row sep=small] 
\& \Gamma,A \& \\ C,A \ar{r}{a,f} \urar[bend left] \& \prod_{a:A}B(a), A \rar{app} \& B \ular[bend right]
\end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&,row sep=small] 
\Gamma \ar{r}{f} \drar[bend right] \& \prod_{a:A}B(a) \rar{id}\& \prod_{a:A}B \dlar[bend left] \\ \& \Gamma \&
\end{tikzcd}}
\end{prooftree}\]

** TODO A note on structural induction
http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.184.4173
** TODO Quotes
# These quotes can be placed on the partial abstracts or in the general one.

"" [Shulman17]

** TODO Homotopy type theory II: Sets
Can we do usual set-theoretical mathematics inside Homotopy Type
Theory? A type $A$ is a *h-set* or simply a *set* if every two parallel paths
are equal. That is,
\[
\mathsf{isSet}(A) :\equiv \prod_{(x,y : A)}\prod_{(p,q: x=y)} p=q.
\]
With the homotopical interpretation, sets are precisely discrete
homotopical spaces in which all homotopy groups are trivial.

** TODO [#C] Examples of product categories
** TODO Concrete categories                                         :ignore:
** TODO Automorphisms                                               :ignore:
We call *automorphisms* to the morphisms which are both endomorphisms
and isomorphisms.

** OLD Type theory
# The connection between constructivity, computability and continuity
# goes back to Brower. (Shulman 17)

# Types vs sets, la pertenencia a un tipo es juzgamental. Es la
# perspectiva de etcs, estructural en vez de material.

# TODO: Diccionario categorías/agda

*** TODO Beyond locally cartesian closed categories
**** TODO Table of correspondences                                :ignore:
[[https://ncatlab.org/nlab/show/relation+between+type+theory+and+category+theory][relation between type theory and category theory in nLab]]

More complex and more sophisticated languages can express a wider
range of theories, but the class of categories in which it makes sense
to take models for these languages is narrower.

|------------------------------------+------------------------------------------------|
| Type theory                        | Category theory                                |
|------------------------------------+------------------------------------------------|
| Simply typed lambda calculus       | Cartesian closed categories                    |
| Extensional dependent type theory  | Locally cartesian closed categories            |
| Martin-Löf intensional type theory | Locally cartesian closed (\infty,1)-categories |
| Homotopy type theory               | Elementary (\infty,1)-topos                    |
|------------------------------------+------------------------------------------------|

*** TODO Topoi
Follows [Leinster] and [Moerdijk]

**** Subobject classifier
***** Definition of subobject classifier                         :ignore:
#+attr_latex: :options [Subobject classifier]
#+begin_definition
A *subobject classifier* is an object $\Omega$ with a monomorphism $\mathrm{true} \colon 1 \to \Omega$
such that, for every monomorphism $m : S \to X$, there exists a unique $\chi$ such that
\[\begin{tikzcd}
S\rar{} \dar[swap, hook]{m} & 
1 \dar{\mathrm{true}} \\
X\rar[dashed]{\chi} & \Omega
\end{tikzcd}\]
forms a pullback square.
#+end_definition

The function $\chi$ is called the *characteristic function* of the
monomorphism $m$.

# TODO: The pullback of a mono is a mono.
# TODO: Every map from 1 is a mono.

***** Subobjects                                                 :ignore:
#+ATTR_LATEX: :options [Subobjects]
#+BEGIN_definition
A *subobject* of an object $X$ is a monomorphism under the equivalence class
given by isomorphism in the slice category ${\cal E}/X$.
#+END_definition

Under this interpretation, each monomorphism represents a subobject, and
two different monomorphisms $m : S \to X$ and $m' : S' \to X$ represent the
same subobject if there exists an isomorphism $\varphi : m \cong m'$ in the slice category
\[\begin{tikzcd}[column sep=tiny]
S\drar[swap]{m}\ar{rr}{\varphi} && S'\dlar{m'} \\
& X &
\end{tikzcd}\]
For instance, subobjects in the category of sets correspond to subsets.

If we call $\Sub( X)$ to the class of subobjects of $X$, every map $f \colon X \to Y$ could
induce a map $f^{\ast} \colon \Sub(Y) \to \Sub(X)$ given by pullback. For example, given any
subobject represented by a monomorphism, $m : S' \to Y$, $f^{\ast}(m) : S \to X$ would be
a monomorphism
\[\begin{tikzcd}
S \rar[dashed]{} \dar[swap,dashed]{f^{\ast}(m)} & 
S' \dar{m} \\
X \rar[swap]{f} &
Y
\end{tikzcd}\]
such that this diagram is a pullback square.
# Two representatives of the same subobject give isomorphic images
# Universal property

When the base category ${\cal E}$ has all pullbacks and each $\Sub( X)$ is in fact a set,
we can define the functor $\Sub : {\cal E}^{op} \to \Set$.
# Representation with the subobject classifier


# Examples of subobject classifier

**** Definition of a topos
#+attr_latex: :options [Topos]
#+begin_definition
An *elementary topos* (plural /topoi/) is a cartesian closed category
with all finite limits and a subobject classifier.
#+end_definition

# Examples of topoi

#+ATTR_LATEX: :options [Logical morphism]
#+BEGIN_definition
A *logical morphism* between two topoi, $F : {\cal E} \to {\cal E}'$ is a functor
preserving finite limits, exponentials and the subobject classifier,
up to isomorphism.
#+END_definition

***** Examples of topoi                                          :ignore:
The category of finite sets and morphisms between them, $\FinSet$,


# https://ncatlab.org/nlab/show/Beck-Chevalley+condition

**** TODO Paré: every topos has colimits
**** Elementary theory of the category of sets
# 1. Well-pointed
# 2. Natural numbers object (definition from initial algebras)
# 3. Axiom of choice

In cite:lawvere64, Lawvere proposed an elementary theory of sets based
on category theory by adjoining a set of axioms to the usual category
theory axioms.

***** Generators                                                 :ignore:
In $\Set$, the terminal object $\{\ast\}$ is a generator. That is, given two
functions $f,g : X \to Y$, if $f \circ x = g \circ x$ for all $x : \{\ast\} \to X$,
then $f = g$. In other words, if $f(x) = g(x)$ for all $x \in X$, then
both functions must be the same.

\\

***** Well-pointed                                               :ignore:
Moreover, the terminal and the initial objects in $\Set$ are not
isomorphic. A category where the terminal object is a generator
and is not a zero object is a *well-pointed* category.

***** TODO Natural numbers                                       :ignore:

***** Choice in a category                                       :ignore:
A category is said to satisfy the *Axiom of choice* if every
epimorphism has a right-side inverse. If we define sets using
ZFC, the category $\Set$ satisfies the axiom of choice, that is,
given any surjective function $f : A \to B$, there exists a 
function $k : B \to A$ such that $f \circ k = \id_B$.

***** ETCS                                                       :ignore:
#+ATTR_LATEX: :options [Category of sets]
#+BEGIN_definition
A *category of sets* is a well-pointed topos with natural numbers
satisfying the Axiom of Choice.
#+END_definition

***** Relation to ZFC                                            :ignore:
# We could take ETCS as our axioms.

ZFC is stronger than ETCS: every provable theorem in ETCS is provable
in ZFC, but the converse is not true. In particular, ETCS is equivalent
to a fragment of ZFC, called /restricted ZFC/. This relation is detailed
in cite:maclane94.

**** TODO The Continuum Hypothesis
**** TODO Reasoning in a topos
# From the nLab: topos
#
# Any result in ordinary mathematics whose proof is finitist and
# constructive automatically holds in any topos. If you remove the
# restriction that the proof be finitist, then the result holds in any
# topos with a natural numbers object; if you remove the restrictions
# that the proof be constructive, then the result holds in any boolean
# topos. On the other hand, if you add the restriction that the proof be
# predicative in the weaker sense used by constructivists, then the
# result may fail in some toposes but holds in any Π-pretopos; if you
# add the restriction that the proof be predicative in a stronger sense,
# then the result holds in any Heyting pretopos.

**** TODO (\infty,1)-toposes
*** TODO Martin-Löf type theory


The type theory we are using in this text is due to Martin-Löf
*Martin-Löf type theory* was developed [...]
Two variants can be considered.

 * *Extensional type theory* is the internal language of locally
   closed cartesian categories taking equalizers as identity types.

 * *Intensional type theory* which defines identity types as a family
   of freely generated inductive types.

We will work in intensional type theory. Proofs will be formalized in
the Agda proof assistant.

***** TODO Types as spaces                                       :ignore:
The connection between constructivity, computability and continuity
goes back to Brower.

*** OLD Universe hierarchy
*** OLD Intensional equality and Equivalences
**** OLD Homotopy type theory III: synthetic topology
# Voevodsky's univalence

Fundamental groups can be defined as truncations
\[
\pi_n(A,a) :\equiv \Big\|\Omega^n(A,a)\Big\|_0.
\]

We will show that the loop space of the sphere is equivalent to the
integers; that is $\Omega(\mathbb{S}^1) \simeq \mathbb{Z}$, and, consequently, $\pi_1(\mathbb{S}^1)$ will be also
$\mathbb{Z}$, as it is a type-theoretical set.

**** Propositional equality
Given any type $A : {\cal U}$ and two elements $x,y : A$, we can consider the
type of proofs of equality between the two, $x = y$. Note that this
*propositional equality* $x = y$ is conceptually different from the
*definitional equality* $x \equiv y$ we have considered before.

Definitional equality, $x \equiv y$, is a judgment that is part of
the theory, and we cannot work internally with it; two terms are
definitionally equal if and only if they are the same term up to
reduction rules. On the other hand, $x = y$ is a type that could
appear inside formulas of the theory, and we can build terms of that
type, $p : x = y$, that would constitute proofs of the equality. These
terms are called *paths*, for reasons that will become apparent as
we study them.

The equality type is freely generated by the *reflexivity* path,
encoded in type theory as
\[
\refl : \prod_{a:A} (a = a).
\]
Therefore, the J-eliminator is called *path induction* and can be
written in type theory as
\[
\prod_{(C : \prod_{(x,y : A)}(x=y) \to {\cal U})} \left(
\left( \prod_{a:A} C(a,a,\mathsf{refl}) \right) \to
\prod_{(x,y : A)}\prod_{(p:x=y)} C(x,y,p)
\right).
\]


***** Symmetry                                                   :ignore:
#+ATTR_LATEX: :options [Symmetry]
#+BEGIN_exampleth
The usual properties of equality can be proved from the principle of
path induction; and each one of them will have a homotopical interpretation
if we read equalities as paths. As a first example, we will prove that
equality is symmetric: given a path $p : x = y$, we can create a
new path $y = x$. This can be done by applying path induction over $p$
and only providing a proof in the case that $p$ is reflexivity and $x$ and $y$ are
actually the same element. In this case, $\refl : x = x$ is of type $y = x$
and we are done.

This way, we have created a function
\[
^{-1} : \prod_{x,y:A} (x = y) \to (y = x)
\]
that inverts paths. Given $p : x =y$, we can construct $p^{-1} : y = x$.
#+END_exampleth

***** Transitivity                                               :ignore:
#+ATTR_LATEX: :options [Transitivity]
#+BEGIN_exampleth
As a second example, we will prove *transitivity of equality*:
given two paths $p : x = y$ and $q : y = z$, how can we build
a new path $p \cdot q : x = z$? We can apply induction over the first equality and
only provide a proof in the case where $x$ and $y$ are actually the same term.
In this case, we only have to provide a term of type $x = z$ and
$q : x = z$ is of exactly that type, so we are done.

This way we have created a function
\[
\cdot : \prod_{x,y,z : A} (x = y) \to (y = z) \to (x = z)
\]
that given two paths $p : x = y$ and $q : y = z$, concatenates them into a
new path $p \cdot q : x = z$.
#+END_exampleth

Using path induction, simple lemmas about path composition can be proved.
In particular, it can be proved that, given any type $A$ with two elements
$x,y : A$,

 * $\prod_{x,y : A}\prod_{p : x = y}\ (p^{-1})^{-1} = p$,
 * $\prod_{x,y : A}\prod_{p : x = y}\ p \cdot p^{-1} = \refl_{x}$,
 * $\prod_{x,y : A}\prod_{p : x = y}\ p^{-1} \cdot p = \refl_y$,
 * $\prod_{(x,y,z,w :A)}\prod_{(p:x=y)}\prod_{(q:y=z)}\prod_{(r:z=w)} (p \cdot q)\cdot r = p \cdot (q \cdot r)$.

The details of these proofs are swept under the rug here, but they are
fully available on the computer formalization.

***** Transport                                                  :ignore:
#+ATTR_LATEX: :options [Transport]
#+BEGIN_exampleth
We want a principle of /indiscernibility of identicals/, that is,
if we have a path $p : x = y$ and a proof of a property $P(x)$, we want to conclude
that $P(y)$. This is called *transport* over the path and notated as
\[
\transport^P(p,-) : P(x) \to  P(y).
\]

This is not a new axiom but a consequence of the path induction principle.
Given the path $p : x = y$, we can apply induction and only worry about the
case where $x$ and $y$ are equal. In this case, the identity function 
$\id : P(x) \to P(x)$ is actually a function $P(x) \to P(y)$, as desired.
We get a function
\[
\transport : \prod_{(P : A \to {\cal U})}\prod_{(x,y:A)}\prod_{(p : x = y)} 
P(x) \to P(y).
\]
#+END_exampleth

***** Functoriality                                              :ignore:
#+ATTR_LATEX: :options [Functoriality]
#+BEGIN_exampleth
Functions can be applied to both sides of equalities, this is known as
*functoriality* of paths. If we have a path $p : x = y$ between two elements
$x,y : A$ and a function $f : A \to B$, we want a path $\ap_f(p) : f\ x = f\ y$.

Again, this path can be constructed by path induction over $p$. Once we
have applied induction, we only have to worry for the case where $x$ and
$y$ are exactly the same, and then $\refl : f\ x = f\ x$ is a valid term of
type $f\ x = f\ y$. We have thus constructed a function,
\[
\ap : \prod_{(f : A \to B)}\prod_{(x,y : A)}\prod_{(p : x = y)} f\ x = f\ y.
\]

The problem with this function is that it does not work in the case of
dependent functions $f : \prod_{a:A}B(a)$. In that case, we would want a path
$f\ x = f\ y$, but note that it is ill-typed! $f\ x : B(x)$ and $f\ y : B(y)$
have different types. We need to transport the element before and create
a type $\mathsf{apd}_f(p) : \transport^{B}(p,f\ x) = f\ y$.

By path induction, we only have to provide an element of type
$\transport^B(\refl, f\ x) = f\ x$, but we know that $\transport$, by
definition, is the identity when applied to reflexivity. That
is, we only have to provide a path $\refl : f\ x = f\ x$. The function
we have constructed is
\[
\apd : \prod_{\left(f : \prod_{(a:A)}B(a)\right)}\prod_{(x,y:A)}\prod_{(p:x=y)} \transport^B(p,f\ x) = f\ y.
\]
#+END_exampleth

***** Uniqueness of identity proofs                              :ignore:
From these examples, it would seem that the path induction principle
is very strong and makes the identity type almost trivial. In particular,
it would seem easy to prove by path induction that every path is equal to
the reflexivity path, that is, given a type $A$,
\[
\prod_{(x : A)}\prod_{(p : x = x)} (p = \refl).
\]
This is called the principle of *uniqueness of identity proofs* and
cannot be actually derived from path induction. The induction principle
explicitely says that the two
endpoints of a path must be independent variables in order to apply
induction. We could still try to prove the more general theorem
\[
\prod_{(x, y : A)}\prod_{(p : x = y)} (p = \refl)
\]
by path induction, hoping to particularize it later; but that term
is ill-typed, $p$ is of type $x = y$ while $\refl$ is of type $x = x$, and 
equalities are only defined between terms of the same type.

In conclusion, every path with two free endpoints can be reduced to
a trivial one, but a path with two fixed equal endopoints cannot be
reduced. This situation resembles homotopy theory in that a path
with two free endpoints can be continuously deformed into a point,
while a loop does not need to be trivial.

# TODO: Image of two loops

# Groupoid model of Hoffman
Is the principle of /uniqueness of identity proof/ independent from
our theory? In 1996, Hofmann and Streicher proposed a model of type
theory in groupoids where this principle does not hold, thus showing
that it is independent (see [Hofmann]). This way, types must be
interpreted not only as disconnected sets where all paths are trivial
but as spaces where there exist paths, paths between paths, paths
between paths between paths, and so on. Types have a homotopical
structure.

**** h-Propositions
In this section, we explore the homotopical structure a type may
present and we will translate some notions from homotopy theory to
type theory.

***** h-Propositions                                             :ignore:
A type $A$ is an *h-proposition* or simply a *proposition* if a path
exists between any two elements of the type. That is,
\[
\mathsf{isProp}(A) :\equiv \prod_{(x,y : A)} x = y.
\]

Under the Curry-Howard interpretation we saw that propositions could
be seen as types; now we see that some types can be seen as
propositions in a more classical sense without proof relevance: any
two proofs of a proposition are equal.

***** Truncation                                                 :ignore:
Once we have defined propositions, a natural notion to consider is
*propositional truncations* that "truncate" each type into a
proposition. Propositional truncations are left adjoints to the
inclusion of propositions into types; that is, given any type $A$
and any proposition $P$, the propositional truncation of $A$, written
as $\|A\|$ is a type such that we have a natural bijection
\begin{prooftree}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&,row sep=small] 
A \rar\& P
\end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&,row sep=small] 
\|A\| \rar\& P
\end{tikzcd}}
\end{prooftree}

In practical terms, this means that $\|A\|$ is a type that is
inhabited if and only if $A$ is; but where any two elements are
equal. To provide a proof of $\|A\|$ is to provide a proof that $A$ is
inhabited without constructing an explicit element of $A$. Thus,
truncations help us to embed classical notions into constructive
logic, as we show in the following example.

#+ATTR_LATEX: :options [Existential quantifier and the axiom of choice]
#+BEGIN_exampleth

#+END_exampleth

***** Diaconescu's theorem                                       :ignore:
# We would need to talk about the category Set of set types in Hott.
# It satisfies the ETCS axioms.

**** h-Sets
***** h-Sets                                                     :ignore:
A type $A$ is a *h-set* or simply a *set* if every two parallel paths
are equal. That is,
\[
\mathsf{isSet}(A) :\equiv \prod_{(x,y : A)}\prod_{(p,q: x=y)} p=q.
\]

Sets can be seen as discrete spaces without any higher dimensional
structure. In the following sections we give examples of sets but also
of types that are not sets.

The *set truncation* of a type can be defined analogously to the
propositional truncation, that is, as the left adjoint to the
inclusion of the sets into the types in general. Given any set $S$ and
an arbitrary type $A$, its set truncation $\|A\|_0$ is defined with
the following adjunction.
\begin{prooftree}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&,row sep=small] 
A \rar\& S
\end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&,row sep=small] 
\|A\|_0 \rar\& S
\end{tikzcd}}
\end{prooftree}

***** Hedberg's theorem                                          :ignore:
What follows is a useful sufficient condition for a type to be a
set.

#+ATTR_LATEX: :options [Hedberg's theorem]
#+BEGIN_theorem
A type $A$ with *decidable equality*, that is, such that
\[
\prod_{x,y:A} (x = y) + \neg (x = y),
\]
is a set.
#+END_theorem
#+BEGIN_proof

#+END_proof

***** Naturals and integers are sets                             :ignore:
#+ATTR_LATEX: :options [Naturals and integers are sets]
#+BEGIN_exampleth

#+END_exampleth

***** Relation to ETCS                                           :ignore:
***** Groupoids and n-types                                      :ignore:
We will classify types into levels parametrized by the
natural numbers, where a n-type will be a type with no nontrivial
equalities above dimension n.
***** Types are groupoids
**** Equivalences

\[
\mathsf{isContrMap}(f) :\equiv \prod_{b:B} \mathsf{isContr}(\mathsf{fib}(f,y)).
\]

It has some nice properties, such as being a proposition, that will
be crucial in the next sections. However, working with this type is
usually very tedious, and so it is better to define the type of
*quasiinverses*, that gives a much more natural notion of what it
means to be an equivalence: namely, having a two-sided inverse.
\[
\mathsf{qinv}(f) :\equiv \sum_{(g : B \to A)} 
\left( \prod_{b : B} f(g(b)) = b \right)
\times
\left( \prod_{a : A} g(f(b)) = a \right)
\]

This type is not a proposition, but we can prove that
$\mathsf{qinv}(f) \to \mathsf{isContrMap}(f)$, and so, it is easier to use it to create
equivalences.
**** Function extensionality and Univalence
*** OLD Synthetic topology
# Synthetic computability: cite Bauer
**** Higher inductive types
A *higher inductive type* is the type freely generated by a set of
constructors and a set of /equalities/ between its freely generated
elements. If inductive types are freely generated, higher inductive
types could be seen as /presentations/ of types. Each one of them
comes with an induction principle that allows to map it into any
type with a similar structure of elements and equalities.

# Detailed discussion

#+ATTR_LATEX: :options [The interval]
#+BEGIN_exampleth
The *interval* is defined as the higher inductive type $I$ with two
constructors $i_0, i_1 : I$ and a path between them $\mathsf{seg} : i_0 = i_1$. This
is a first example of a path that cannot be reduced to reflexivity.

The induction principle for the interval says that, given any type
$A$ with two elements $a_0,a_1 : A$ and a path between them $p : a_0 = a_1$,
there exists a function $f : I \to B$ such that $f(i_0) \equiv a_0$, $f(i_1) \equiv a_1$
and $\ap_f(s) =\mathsf{seg}$. Note how the last equality is only judgmental; 
higher inductive types are easier to formalize in a proof assistant
this way, for a more detailed discussion see [HoTT].
#+END_exampleth

#+ATTR_LATEX: :options [The circle]
#+BEGIN_exampleth
The *circle* is defined as the higher inductive type $\mathbb{S}^1$ with one
constructor $\mathsf{base} : \mathbb{S}^1$ and a path $\mathsf{loop} : \mathbb{S}^1$. Its induction principle
says that, given any type $A$ with an element $a:A$ and a path $s : a = a$,
there exists a function $f : \mathbb{S}^1 \to A$ such that $f(\mathsf{base}) \equiv a$ and
$\ap_f(\mathsf{loop}) = s$.
#+END_exampleth

#+ATTR_LATEX: :options [Quotients]
#+BEGIN_exampleth

#+END_exampleth

**** The fundamental group of the circle
*** OLD Constructive analysis
# Comparar con Coquelicot https://hal.inria.fr/file/index/docid/860648/filename/article.pdf
*** OLD Computer verification
# Sprinkles of extensionality for your vanilla type theory

# Higher inductive types using Dan Licata's trick
** OLD Monoidal and enriched categories
# Linear logic = Monoidal categories = Quantum computation
# Proof net = String diagram = Quantum circuit
*** TODO String diagrams
# Peter Selinger - A survey of graphical languages https://arxiv.org/pdf/0908.3347.pdf
*** Enriched categories
# https://www.youtube.com/watch?v=be7rx29eMr4

**** Motivation                                                   :ignore:
When we defined categories for the first time, we implicitly assumed
a set of morphisms between every two objects, that is, for every two
$a,b \in {\cal C}$, there exists a set $\hom(a,b)$. Composition is
then a function
\[
\circ : \hom(b,c) \times \hom(a,b) \to \hom(a,c),
\]
and the identity morphism can be represented as a function from the
terminal object into the morphisms from an object to itself,
\[
\id : 1 \to \hom(a,a).
\]
Associativity and identity axioms can be expressed as commutative
diagrams,
# TODO: Diagrams

In this definition, we are only using the monoidal structure of the
category $\Set$; thus, we could generalize the notion of a category into
that of an *enriched category* over a monoidal category ${\cal V}$, a category
whose hom-sets would be objects of ${\cal V}$, and the composition and identities
would be morphisms in that category.

**** Definition                                                   :ignore:
**** Example: metric spaces                                       :ignore:
#+ATTR_LATEX: :options [Metric spaces]
#+BEGIN_exampleth
If we consider the ordered set $(\mathbb{R}^{+}, \geq)$ as a category, it
can be given a monoidal structure with the addition of numbers.
Note that, in this category, objects are real numbers $r \in \mathbb{R}$ and
\[
\hom(r,r') = \left\{ \begin{array}{ll}
  \{\ast\} & \mbox{ if } r \geq r', \\
  \varnothing & \mbox{ otherwise; }
\end{array}\right.
\]
thus, morphisms are usually written as $r \leq r'$.

A *metric space* endowed with a distance function $d$ can be defined
as a category enriched over $(\mathbb{R}^+,\geq)$. Note that the composition
must be a morphism of the form
\[
\circ : d(b,c) + d(a,b) \geq d(a,c),
\]
which is the exact statement of the triangle inequality; while,
knowing that $0$ is the initial object of the category, the identity
is of the form
\[
\id : 0 \geq d(a,a),
\]
which is the statement of indiscernibility of identical elements.
The rest of the axioms of the category hold trivially due to the
fact that there is, at most, a unique morphism between any two
objects.
#+END_exampleth

*** TODO Abelian categories
** OLD Kan extensions
*** Dinatural transformations
# Extension of the concept of naturality to a special type of
# bifunctors.
# Natural diagonal between functors.

#+ATTR_LATEX: :options [Dinatural transformation]
#+BEGIN_definition
A *dinatural transformation* between functors $F,G \colon {\cal C}^{op} \times {\cal C} \to {\cal B}$
is a family of morphisms $\alpha_x \colon F(x,x) \to G(x,x)$ for each $x \in {\cal C}$,
called /components/, such that for every $f \colon x \to y$,
\[\begin{tikzcd} &
F(x,x) \rar{\alpha_{x}} &
G(x,x) \drar{G(\id,f)} & \\
F(y,x) \urar{F(f,\id)}\drar[swap]{F(\id,f)} & & &
G(x,y) \\
&
F(y,y) \rar{\alpha_{y}} &
G(y,y) \urar[swap]{G(f,\id)} &
\end{tikzcd}\]

commutes
#+END_definition

# TODO: Every natural transformation gives a dinatural transformation.

**** TODO Natural transformation of covariant to contravariant functor :ignore:
**** Extranatural transformations (wedges)                        :ignore:
#+ATTR_LATEX: :options [Wedge]
#+BEGIN_definition
A *wedge* (also called *extranatural transformation*) is a dinatural
transformation from a constant functor.

That is, given a functor $T \colon {\cal C}^{op} \times {\cal C} \to {\cal B}$, a *wedge* $\alpha \colon x \toddot T$ is a
family of morphisms $\alpha_c \colon x \to T(c,c)$ such that

\[\begin{tikzcd}
x        \dar[swap]{\alpha_{c'}} \rar{\alpha_{c}} &
T(c,c)   \dar{T(\id,f)} \\
T(c',c') \rar[swap]{T(f,\id)} &
T(c,c')
\end{tikzcd}\]

commutes for every $f \colon c \to c'$. 
#+END_definition

# Wedges or cowedges?
# #+ATTR_LATEX: :options [Cowedge]
# #+BEGIN_definition
# A *wedge* (also called *extranatural transformation*) is a dinatural
# transformation from a constant functor. We write wedges as $\alpha \colon F \toddot b$.
# #+END_definition

# That is, given a functor $F \colon {\cal C}^{op} \times {\cal C} \to {\cal B}$, a wedge $\alpha \colon F \toddot b$ is a
# family of morphisms $\alpha_x \colon F(x,x) \to b$ such that

# \[\begin{tikzcd}
# F(y,x)\rar{F(\id,f)} \dar[swap]{F(f,\id)} & F(y,y) \dar{\alpha_{y}} \\
# F(x,x)\rar[swap]{\alpha_{x}} & b
# \end{tikzcd}\]

# commutes for every $f \colon x \to y$. 

**** TODO Examples of dinatural transformations                   :ignore:
*** Ends
**** Definition of Ends                                           :ignore:
#+ATTR_LATEX: :options [End]
#+BEGIN_definition
An *end* of $T \colon {\cal C}^{op} \times {\cal C} \to {\cal B}$ is its universal wedge.
That is, a wedge $\alpha \colon e \toddot T$ such that for every other $\beta \colon k \toddot T$,
there exists a unique $u \colon k \to e$ such that $\alpha_c \circ u = \beta_c$ for
each $c \in {\cal C}$.
#+END_definition

Diagramatically,

\[\begin{tikzcd}
k \ar[dashed]{dr}{\exists! u} \ar[bend left]{drr}{\beta_{c}} \ar[swap,bend right]{ddr}{\beta_{c'}} & &\\
&e        \dar[swap]{\alpha_{c'}} \rar{\alpha_{c}} &
T(c,c)   \dar{T(\id,f)} \\
&T(c',c') \rar[swap]{T(f,\id)} &
T(c,c')
\end{tikzcd}\]


We usually call /end/ to the object $e$, and we use the following integral
notation
\[
e = \int_{c \in {\cal C}} T(c,c).
\]

**** Examples of ends 1                                           :ignore:
We present some examples of Ends, taken mainly from cite:thecatsters.

#+ATTR_LATEX: :options [Natural transformations as Ends]
#+BEGIN_exampleth
Natural transformations are ends; they can be written as
\[
\Nat(F,G) = \int_{c\in {\cal C}} \hom(Fc,Gc)\ .
\]

Take $T = \hom(F-,G-) \colon {\cal C}^{op} \times {\cal C} \to \Sets$, where $F,G \colon {\cal C} \to {\cal E}$ are
two arbitrary functors. A wedge $x \toddot T$ would be defined by a set $x \in \Sets$
and a family of functions $\omega_c \colon x \to \hom(Fc,Gc)$ such that
\[\begin{tikzcd}
x        \dar[swap]{\omega_{c'}} \rar{\omega_{c}} &
\hom(Fc,Gc)   \dar{Gf \circ -} \\
\hom(Fc',Gc') \rar[swap]{- \circ Ff} &
\hom(Fc,Gc')
\end{tikzcd}\]
commutes for each $f \colon c \to c'$. That is, for each element of the
set, $a \in x$, we get $\omega_c(a) \colon Fc \to Gc$ such that $Gf \circ \omega_c(a) = \omega_{c'}(a) \circ Ff$;
in other words, the following square is natural
\[\begin{tikzcd}
Fc \rar{\omega_c(a)}\dar[swap]{Ff} & Gc \dar{Gf} \\
Fc' \rar[swap]{\omega_{c'}(a)} & Gc' \\
\end{tikzcd}\]
and $\omega_c(a)$ is a natural transformation from $F$ to $G$, for each $a \in x$. 

Thus, we have proved that a wedge $x \toddot T$ is a set $x$ mapping to the
set of natural transformations. The universal set with this property
is clearly (it can be seen as the terminal object of the slice
category) the set of natural transformations. That is,
\[
\Nat(F,G) = \int_{c\in {\cal C}} \hom_{{\cal E}}(Fc,Gc)\ .
\]

The particular case
\[
\Nat(\id,\id) = \int_{c\in{\cal C}} \hom_{{\cal C}}(c,c)
\]
is sometimes known as the center of the category.
#+END_exampleth

**** Examples of ends 2                                           :ignore:
#+ATTR_LATEX: :options [Tannakian reconstruction]
#+BEGIN_exampleth
Let $M$ be a monoid in $\Sets$. We consider $M\mhyphen\Sets$, the category of sets
in which $M$ acts; that is, pairs $(S,\sigma)$, where $s$ is an arbitrary
set and $\sigma \colon M \times S \to S$ is an action of the monoid on the set.
Morphisms are of the form $f \colon (S,\sigma) \to (R,\rho)$ where $f \circ \sigma = \rho \circ f$.

There is
a forgetful functor $U \colon M\mhyphen\Sets \to \Sets$ that simply forgets the $M\mhyphen\text{action}$
on the set; and we can recover the monoid from this functor as
\[
\int_{(s,\sigma) \in M\mhyphen\Sets} \hom(U(s,\sigma), U(s,\sigma)) =
\Nat(U,U) = M.
\]
This is a very particular instance of the idea of Tannakian reconstruction,
as described in cite:joyal91.

The forgetful functor $U \colon M\mhyphen\Sets \to \Sets$ is a representable functor;
represented by $(M,\mu) \in M\mhyphen\Sets$. There exists a function
\[
g \colon \hom_{M\mhyphen\Sets}((M,\mu), (S,\sigma)) \to S = U(S,\sigma)
\]
sending $g(f) = f(e)$. Note that $f$ is completely determined by $f(e)$; as
$f(m) = f(\mu(m,e)) = \sigma(m,f(e))$; and this $g$ is a bijection. We have
proved that $U \cong \hom((M,\mu),-)$.

Now, using this fact and the dual Yoneda lemma,
\[\begin{aligned}
\Nat(U,U) &\cong \Nat(\hom((M,\mu),-), \hom((M,\mu),-)) \\
          &= \hom_{M\mhyphen\Sets}((M,\mu),(M,\mu)) = M;
\end{aligned}\]
and the components of the natural transformation are simply
multiplication by $m$ for some fixed $m \in M$. Diagramatically, for
any given $\psi \in \Nat(U,U)$,
\[\begin{tikzcd}[row sep={4mm,between origins},column sep={8mm,between origins}]
(M,\mu) \arrow[rrrr, "\psi_{(S,\sigma)}"] \arrow[ddd, "{\sigma(-,s)}", swap] 
    & & & & (M,\mu) \arrow[ddd, "{\sigma(-,s)}"] \\  
    & e \arrow[rr, |->] \arrow[d, |->] & & m \arrow[d, |->] & \\[1cm]
    & s \arrow[rr, |->] & & \sigma(m,s) \\
(S,\sigma) \arrow[rrrr, "\psi_{(S,\sigma)}", swap] & & & & (S,\sigma)\\  
\end{tikzcd}\]
it must be the case that $\psi_{(S,\sigma)}(s) = ms$.
#+END_exampleth

**** Examples of ends 3                                           :ignore:
#+ATTR_LATEX: :options [Reconstruction of the center]
#+BEGIN_exampleth
A variant on the previous example is to use identity functors
to recover
\[
\int_{(s,\sigma) \in M\mhyphen\Sets} \hom((s,\sigma),(s,\sigma)) = \Nat(\id,\id) = {\cal Z}(M)
\]
the center of the monoid.

If $\psi \in \Nat(\id,\id)$, we can apply the forgetful functor to get
$U\psi \in \Nat(U,U)$. By the previous example, the natural transformation
must be of the form $\psi_{(S,\sigma)}(s) = \sigma(m,s)$ for each $(S,\sigma)$, given some
fixed $m \in M$.

However, further restrictions apply in this case. In particular,
$\psi_{(M,\mu)}$ must be a morphism in $M\mhyphen\Sets$, therefore, for any $n \in M$,
\[
nm = \mu(n,\mu(m,e)) = \mu(m,\mu(n,e)) = mn,
\]
and $m \in {\cal Z}(M)$. The fact that any $m \in {\cal Z}(M)$ defines a natural
transformation follows from the axioms of the $M\mhyphen\Sets$ structure.
#+END_exampleth

*** Coends
*** TODO Profunctors, distributors
# https://ncatlab.org/nlab/show/profunctor
**** Composition
**** Heteromorphisms
**** https://ncatlab.org/nlab/show/anafunctor
*** Kan extensions
** OLD Higher categories
# TODO: Bicategories are weak 2-categories
# TODO: 2-categories are strict 2-categories

*** Strict 2-categories
**** 2-categories: introduction                                   :ignore:
# TODO: The category of two categories
In a 2-category, instead of having sets of morphisms; we have a
category of morphisms between any two objects. It has objects,
called */0-cells/*; morphisms between objects, called */1-cells/*; and
morphisms between morphisms, called */2-cells/*.
\[\begin{tikzcd}
x
&
x \rar{f}&y 
&
x\phantom{y} 
\arrow[bend left=50]{r}[name=U,below]{}{f}
\arrow[bend right=50]{r}[name=D]{}[swap]{g}
& 
\phantom{x}y \arrow[Rightarrow,from=U,to=D]{}{\alpha}
\end{tikzcd}\]
As, morphisms between two objects form a category, morphisms between
morphisms can be composed vertically in their category; 
\[\begin{tikzcd}
x\phantom{y}
\arrow[bend left=80]{rr}[name=U2,below]{}{f}
\arrow[]{rr}[name=C2,below]{}[name=C1,above]{}[above=2mm, left=3mm]{g}
\arrow[bend right=80]{rr}[name=D2]{}[swap]{h}
&& 
\phantom{x}y
\arrow[Rightarrow,from=U2,to=C1]{}{\alpha}
\arrow[Rightarrow,from=C2,to=D2]{}{\beta}
&
x\phantom{y} 
\arrow[bend left=50]{r}[name=U,below]{}{f}
\arrow[bend right=50]{r}[name=D]{}[swap]{h}
& 
\phantom{x}y \arrow[Rightarrow,from=U,to=D]{}{\beta \circ \alpha}
\end{tikzcd}\]
but the 2-category will also provide a horizontal composition of
morphisms between two objects
\[\begin{tikzcd}
\makebox[0pt][l]{$x$}\phantom{y} 
\arrow[bend left=50]{r}[name=U,below]{}{f}
\arrow[bend right=50]{r}[name=D]{}[swap]{f'}
& 
\phantom{}y
\arrow[Rightarrow,from=U,to=D]{}{\alpha}
\arrow[bend left=50]{r}[name=U,below]{}{g}
\arrow[bend right=50]{r}[name=D]{}[swap]{g'}
& 
\makebox[0pt][l]{$z$}\phantom{y}
\arrow[Rightarrow,from=U,to=D]{}{\beta}
&
x
\arrow[bend left=50]{rr}[name=U,below]{}{g \circ f}
\arrow[bend right=50]{rr}[name=D]{}[swap]{g' \circ f'}
&&
z
\arrow[Rightarrow,from=U,to=D]{}{\beta \ast \alpha}
\end{tikzcd}\]
which, as we will formalize, will act functorially with respect to
vertical composition. An interchange law which will act as a
generalization of Proposition <<prop-interchangelaw>> will follow
from functoriality. In fact, the category of small categories, with
functors and natural transformations between them will be an example
of 2-category.

**** 2-category: definition                                       :ignore:
#+ATTR_LATEX: :options [2-category]
#+BEGIN_definition
A *2-category* is given by

  * a collection of objects;
  * a category $T(a,b)$ for every pair of objects $a,b$, called
    /vertical category/ between $a,b$;
  * a identity arrow $U_a \colon 1 \to T(a,a)$ for every object $a$;
  * a horizontal composition functor $K_{a,b,c}\colon T(b,c) \times T(a,b) \to T(a,c)$
    for every triple of objects $a,b,c$;

where we usually write the action of $K$ on morphisms as $K(\beta,\alpha) = \beta \ast \alpha$.
The functor $K_{a,b,c}$ must be associative and $U_a$ must provide a left and
right identity.
#+END_definition

Associativity means that the two following composite functors are
strictly equal,

\[\begin{tikzcd}[row sep=huge, column sep=tiny]
&
T(c,d) \times T(b,c) \times T(a,b)
\ar[bend left=60]{dd}[name=U,left]{}{}
\ar[bend right=60]{dd}[name=D]{}[swap]{}
\drar{K_{a,b,c} \times \id}
\dlar[swap]{K_{b,c,d} \times \id} & \\
T(b,d) \times T(a,b) \drar[swap]{K_{a,b,d}} &&
T(c,d) \times T(a,c) \dlar{K_{a,c,d}} \\
& T(a,d) & 
\arrow[phantom,from=U,to=D]{}{=}
\end{tikzcd}\]

This is a particular case of an *enriched category*.

**** Interchange law                                              :ignore:
#+ATTR_LATEX: :options [Interchange law]
#+BEGIN_proposition
Given any $\alpha,\alpha',\beta,\beta'$ composable 2-cells,
\[
(\beta' \circ \beta) \ast (\alpha' \circ \alpha) =
(\beta' \ast \alpha') \circ (\beta \ast \alpha).
\]
#+END_proposition
#+BEGIN_proof
Unfolding the definition in the product category and applying
the functoriality of $K$, we get
\[\begin{aligned}
(\beta' \circ \beta) \ast (\alpha' \circ \alpha) &=
K(\beta' \circ \beta, \alpha' \circ \alpha)  = K((\beta' , \alpha') \circ (\beta , \alpha)) \\
&= K(\beta', \alpha') \circ K(\beta, \alpha) = (\beta' \ast \alpha') \circ (\beta \ast \alpha).
\end{aligned}\]
#+END_proof

**** TODO 2-cat                                                   :ignore:
# Describe 2-cat as a 3-cat
**** TODO Eckmann-Hilton                                          :ignore:
**** TODO Double categories                                       :ignore:
*** Weak 2-categories
In the definition of strict 2-categories, we have postulated that the
horizontal composition of 2-cells should be associative, but we could
relax this condition and write a similar definition in which the
horizontal composition is not associative but
/associative up to isomorphism/. This new definition gives us the
notion of *bicategories*, which are also called *2-categories*.

**** Formal definition: bicategory                                :ignore:
#+ATTR_LATEX: :options [Bicategory]
#+BEGIN_definition
A *bicategory* is given by

  * a collection of objects;
  * a category $B(a,b)$ for every pair of objects $a,b$, called
    /vertical category/ between $a,b$;
  * a identity arrow $U_a \colon 1 \to T(a,a)$ for every object $a$;
  * a horizontal composition functor $\ast \colon T(b,c) \times T(a,b) \to T(a,c)$
    for every triple of objects $a,b,c$;

such that, whenever we find the following configuration,
\[\begin{tikzcd}[]
a\phantom{b}
\ar[bend left=60]{r}[name=U1,below]{}{}
\ar[bend right=60]{r}[name=U2,above]{}{} &
b\phantom{a}
\ar[bend left=60]{r}[name=V1,below]{}{}
\ar[bend right=60]{r}[name=V2,above]{}{} &
c\phantom{b}
\ar[bend left=60]{r}[name=W1,below]{}{}
\ar[bend right=60]{r}[name=W2,above]{}{} &
d\phantom{c}
\arrow[Rightarrow,from=U1,to=U2]{}{}
\arrow[Rightarrow,from=V1,to=V2]{}{}
\arrow[Rightarrow,from=W1,to=W2]{}{}
\end{tikzcd}\]
associativity holds up to natural isomorphism, that is, there exists
an isomorphism $\alpha$ between the following composite functors
\[\begin{tikzcd}[row sep=huge, column sep=tiny]
&
B(c,d) \times B(b,c) \times B(a,b)
\ar[bend left=60]{dd}[name=U,left]{\phantom{as}}{}
\ar[bend right=60]{dd}[name=D,right]{\phantom{as}}[swap]{}
\drar{\ast \times \id}
\dlar[swap]{\ast \times \id} & \\
B(b,d) \times B(a,b) \drar[swap]{\ast} &&
B(c,d) \times B(a,c) \dlar{\ast} \\
& B(a,d) & 
\arrow[Rightarrow,from=D,to=U]{}{\alpha}
\end{tikzcd}\]
#+END_definition

**** TODO Coherence theorem for bicategories                      :ignore:
# https://ncatlab.org/nlab/show/pentagon+identity
# https://ncatlab.org/nlab/show/bicategory

*** Simplicial sets
# [Goerss], [nLab], [Jardine] and [Riehl]
This section follows cite:goerss09 and cite:riehl11.

# https://golem.ph.utexas.edu/category/2017/08/simplicial_sets_vs_simplicial.html

**** Simplicial sets                                              :ignore:
#+ATTR_LATEX: :options [Simplex category]
#+BEGIN_definition
The *simplex category* $\Delta$ is the category of finite ordinals of the
form
\[
[n] = (0 < \dots < n),
\]
for any $n \in \mathbb{N}$, and order-preserving maps between them.
#+END_definition

All the morphisms simplex category are generated by composition of
morphisms of the following two families:

 * *coface maps*, maps of the form $d^k \colon [n-1] \to [n]$ defined as the
   only injective map not having $k$ in its image; and
 * *codegeneracy maps*, maps of the form $s^k \colon [n+1] \to [n]$ defined as
   the only surjective map such that $k$ has two preimages.

From the definition of these functions, the following equations follow
\begin{aligned}
d^id^j = d^{j+1}d^i, & \quad & \text{for each }\ i \leq j, \\
s^js^i = s^is^{j+1}, & \quad & \text{for each }\ i \leq j, \\
\end{aligned}
\[
s^jd^i =  \left\{
	\begin{array}{ll}
		d^is^{j-1}  & \mbox{if } i < j, \\
		1 & \mbox{if } i = j, \mbox{ or } j+1, \\
                d^{i-1}s^j & \mbox{otherwise}.
	\end{array} \right.
\]

#+ATTR_LATEX: :options [Representation of a morphism]
#+BEGIN_lemma
Any morphism in $\Delta$ can be written as
\[
f = d^{i_k}\dots d^{i_1}s^{j_1} \dots s^{j_k} : [n] \to [n'],
\]
where $0 \leq i_1 < \dots < i_k < n'$ and $0 \leq j_1 < \dots < j_k < n$.
#+END_lemma
#+BEGIN_proof
# TODO
#+END_proof


#+ATTR_LATEX: :options [Simplicial set]
#+BEGIN_definition
A *simplicial set* is a contravariant functor from $\Delta$ to the
category of sets. The category of *simplicial sets*, $\sSets{}$, is the functor
category $\Sets^{\Delta^{op}}$.
#+END_definition

If $X \in \sSets$ is a simplicial set, we call

 * $X_n$ to the image of $[n]$ under the functor $X$;
 * $d_k$ to the *face maps*, the images of the coface maps under the
   contravariant functor $X$;
 * $s_k$ to the *degeneracy maps*, the images of the codegeneracy maps
   under the contravariant functor $X$.

The following identities follow from the previous identities in the
category and the contravariance of the functor
\begin{aligned}
d_jd_i = d_id_{j+1}, & \quad & \text{for each }\ i \leq j, \\
s_is_j = s_{j+1}s_i, & \quad & \text{for each }\ i \leq j, \\
\end{aligned}
\[
d_is_j =  \left\{
	\begin{array}{ll}
		s_{j-1}d_i  & \mbox{if } i < j, \\
		1 & \mbox{if } i = j,\mbox{ or } j+1, \\
                s_jd_{i-1} & \mbox{otherwise}.
	\end{array} \right.
\]

**** Nerve                                                        :ignore:
#+ATTR_LATEX: :options [Nerve of a category]
#+BEGIN_definition
The *nerve* of a category ${\cal C}$ is a simplicial set $N({\cal C}) \in \sSets$ given
by the functor category $N({\cal C})_n = {\cal C}^{[n]}$, where $[n]$ is the ordinal $(0 < \dots < n)$
interpreted as a category, that is, $N({\cal C})_n$ is the set of paths of
composable morphisms of length $n$.
#+END_definition

# Face map

#+ATTR_LATEX: :options [Nerve functor]
#+BEGIN_lemma
The *nerve functor* $N \colon \Cats \to \sSets$ is fully faithful.
#+END_lemma

**** Standard n-simplex                                           :ignore:
#+ATTR_LATEX: :options [Standard n-simplex]
#+BEGIN_definition
The *standard n-simplex*, $\Delta^n$, is defined as the nerve of $[n]$,
$\Delta^n = N([n])$. In fact, it can be seen as the covariant functor
\[
\Delta^n = \hom_{\Delta}(-,[n]).
\]
#+END_definition

# TODO check
By Yoneda Lemma, natural transformations between standard n-simplices
correspond to maps between ordinals
\[
\Nat(\hom(-,[n]), \hom(-,[m])) \cong \hom([n],[m]).
\]
Thus, coface and codegeracy maps can be defined between n-simplices.
In particular, the i-th face of $\Delta^n$, written as $\partial_i \Delta^n$ is defined as the image of
$d^i : \Delta^{n-1} \to \Delta^n$.

**** Boundaries                                                   :ignore:
The boundary is the smallest subsimplicial set of $\Delta^n$
containing all of his faces, that is, the union of the faces 
$\partial_0\Delta^n, \dots, \partial_n\Delta^n$.

From the simplicial identities, it follows that
\[\begin{tikzcd}
\Delta^{n-2}\rar{d^{j-1}} \dar[swap]{d^{i}} & \Delta^{n-1} \dar{d^{i}} \\
\Delta^{n-1}\rar[swap]{d^{j}} & \Delta^{n}
\end{tikzcd}\]
and this is a pullback square. This allows us to define the
boundary of a simplicial set as a coequalizer.

#+ATTR_LATEX: :options [Boundary]
#+BEGIN_definition
The *boundary* of the n-simplex, $\partial \Delta^n$ is the subobject of $\Delta^n$ generated
by its $(n-1)\mhyphen\mathrm{simplices}$. Formally, it is the coequalizer given by the
following diagram
\[\begin{tikzcd}
\bigsqcup_{0 \leq i < j \leq n} \Delta^{n-2} \rar[yshift=0.5ex] \rar[yshift=-0.5ex] &
\bigsqcup_{0 \leq i \leq n} \Delta^{n-1} \rar&
\partial \Delta^n.
\end{tikzcd}\]
#+END_definition

**** Horns                                                        :ignore:
The simplicial horn is the union of all the faces of an n-simplex except
for one. Formally, it can be described as a coequalizer, as we did with
the boundary.

#+ATTR_LATEX: :options [Horns]
#+BEGIN_definition
The *n-horn* $\Lambda^n_k \subset \partial \Delta^n$ for $0 \leq k \leq n$ is defined as the coequalizer
\[\begin{tikzcd}
\bigsqcup_{0 \leq i < j \leq n} \Delta^{n-2} \rar[yshift=0.5ex] \rar[yshift=-0.5ex] &
\bigsqcup_{i \neq k} \Delta^{n-1} \rar&
\Lambda^n_k.
\end{tikzcd}\]
#+END_definition

The horns $\Lambda_k^n$ for $0 < k < n$ are called *inner horns* while $\Lambda_0^n$ and $\Lambda_n^n$
are *outer horns*. For instance, in dimension 2, we have two outer horns
$\Lambda^2_0, \Lambda^2_2$ and one inner horn $\Lambda^2_1$ that can be drawn as
\[\begin{tikzcd}[column sep=tiny]
& \cdot &                    & & \cdot \drar &      & & \cdot \ar{dr} &\\
\cdot \urar \ar{rr} && \cdot & \cdot \urar && \cdot & \cdot \ar{rr} && \cdot
\end{tikzcd}\]
with the inner horn being the one in the middle.

Note that the inner horn can be extended by composition to a
simplex. This property of certain horns is what will define Kan
complexes and \infty-categories.

**** Kan complex                                                  :ignore:
#+ATTR_LATEX: :options [Kan complex]
#+BEGIN_definition
A *Kan complex* is a simplicial set $X \in \sSets$ such that any horn $\Lambda^n_k \to X$
can be extended to an n-simplex $\Delta^n \to X$. That is, the following diagram
has a solution, which needs not to be unique.
\[\begin{tikzcd}
\Lambda^n_k \rar \dar[hook] & X \\
\Delta^n \ar[dashed, swap]{ur}{\exists} & \\
\end{tikzcd}\]
#+END_definition

*** (\infty,1)-categories
# https://ncatlab.org/nlab/show/%28n%2Cr%29-category
# https://ncatlab.org/nlab/show/higher+category+theory
# https://arxiv.org/pdf/1007.2925.pdf Short course on infty-categories

There is no consensus on the definition of a *(\infty,1)-category*
yet, but whenever we talk of (\infty,1)-categories, we expect them to
have

 - a collection of objects;

 - morphisms between objects, invertible 2-morphisms between
   morphisms, invertible 3-morphisms between 2-morphisms, invertible
   morphisms between 4-morphisms, and so forth;

 - composition of morphisms, with suitably associative and identity
   laws.

In general, a *(n,k)-category* has morphisms, 2-morphisms, \dots and
n-morphisms, and all morphisms above the k-th dimension are
invertible. This section will follow cite:groth10.

**** \infty-categories                                            :ignore:
#+ATTR_LATEX: :options [\infty-category]
#+BEGIN_definition
An *\infty-category* is a simplicial set ${\cal C} \in \sSets$ such that every
/inner/ horn $\Lambda^n_k \to {\cal C}$ can be extended to an n-simplex $\Delta^n \to {\cal C}$.
#+END_definition

# Spaces and categories give rise to \infty-categories

In particular, we call 

 - *objects* to the vertices of the simplicial set ${\cal C}_0$;

 - *morphisms* to the 1-simplices $f \in {\cal C}_1$; the /source map/ is given
   by the first face map $d_1 : {\cal C}_1 \to {\cal C}_0$ and the /target map/ is given
   by the second face map $d_2 : {\cal C}_1 \to {\cal C}_0$.

 - *identity map* to the degeneracy map $s_0 \colon {\cal C}_0 \to {\cal C}_1$;
   # it is an endomorphism

 - *composition* of two morphisms $f : x \to y$ and $g : y \to z$ to the morphism
   that we obtain by extending an inner horn $l : \Lambda^2_1 \to {\cal C}$ such that $d_0(l) = g$
   and $d_2(l) = f$ to a 2-simplex $\sigma : \Delta^2 \to {\cal C}$. Note that this, however, does
   not provide a unique candidate for composition.


**** Functors of \infty-categories                                :ignore:
A functor between two \infty-categories ${\cal C},{\cal D}$ is just a map of
simplicial sets between them; a natural transformation is defined
as a map $\Delta^1 \times {\cal C} \to {\cal D}$.

**** \infty-groupoids                                             :ignore:
# http://www.cs.nott.ac.uk/~psztxa/publ/weakomega2.pdf
# https://arxiv.org/pdf/1709.09519.pdf
# https://arxiv.org/pdf/1007.2925.pdf Groth, course on infty-categories

#+ATTR_LATEX: :options [Infinity-groupoids]
#+BEGIN_definition
An *\infty-groupoid* is a \infty-category in which the homotopy category
is a groupoid.
#+END_definition

#+ATTR_LATEX: :options [Characterization of groupoids]
#+BEGIN_theorem
An *\infty-category* is an \infty-groupoid if and only if it is a Kan
complex.
#+END_theorem

**** TODO Fundamental \infty-groupoid                             :ignore:
# Grothendieck homotopy hypothesis

*** TODO Higher-order categories and homotopy
# From chapter 2 of HoTT
*** TODO Weak \infty-groupoids

** OLD First chapters
**** OLD Beta rules for STLC                             :noexport:ignore:
# These rules are not necessary, we are only using function types.

Typeable terms follow the following set of \beta-reduction rules, which include
the untyped \beta-reduction rule defined in Definition [[def-betared]] and
add explicit reduction rules for the new types. Namely,

 * function application, $(\lambda x.M)N \to_{\beta} M[N/x]$;
 * first projection $\pi_{1} (M,N) \to_{\beta} M$; and
 * second projection $\pi_{2}_{} (M,N) \to_{\beta} M$.

These rules govern how can we compute with pair types. With this
rules $\tto_{\beta}$ and $=_{\beta}$ should be redefined accordingly.

** OLD Lawvere theories [Old]                                     :noexport:
This section follows cite:bauer17.

*** Motivation for algebraic theories
We will develop an unified approach to the study of algebraic
structures based on constants, operations and equations; such as
groups, modules or rings.

**** First definition of algebraic theory                         :ignore:
Our *algebraic theories* are usually given by

  * a /signature/, a family of sets $\left\{ \Sigma_k \right\}_{k \in \mathbb{N}}$ whose elements are called
    /k-ary operations/. The /terms/ of a signature are defined inductively,
    being variables or k-ary operations applied to k-tuples of terms;

  * and a set of /axioms/, which are equations between terms.

**** Examples: theory of groups, theory of fields                 :ignore:
For example, the theory of groups is given by a signature containing

 * a /binary operation/ called $\cdot$,
 * a /unary operation/ written as $^{-1}$, and
 * a /nullary operation/ or a /constant/ called $e$.

Satisfiying the following axioms

 * $(x \cdot y) \cdot z = x \cdot (y \cdot z)$,

 * $x \cdot e = x$,

 * $e \cdot x = x$,

 * $x \cdot x^{-1} = e$, and

 * $x^{-1} \cdot x = e$.

Note how quantifiers are not needed here, as we are interpreting
each $x,y,z$ as free variables and the universal quantification is
therefore implicit.
Theories in which the operations are not defined for every possible
term, cannot be expressed in this way. Fields, in which the inverse of
$0$ is not defined, are not expressable in this form; this fact will
be proved formally in Example [[example-fieldsarenotalgebraic]].

\\

**** Interpretations of algebraic theories                        :ignore:
A theory can be *interpreted* on a suitable category ${\cal C}$ as

  * an object of the category, $A \in {\cal C}$;
  * with morphisms $If \colon A^k \to A$ for every k-ary operation $f$.

Any interpretation of the theory induces an interpretation for every
term on a context. That is, a term $t$ can be given in the
variable context $x_1,\dots,x_n$ if all variables that
appear in $t$ appear in $x_1,\dots,x_n$. We write that as
\[
x_1,x_2,\dots,x_n \mid t;
\]
and the *interpretation of the term* $x_1,\dots,x_n \mid t$ *on that context* is a morphism
$I(x_1,\dots,x_n \mid t) \colon A^n \to A}$ defined inductively knowing that

  * the interpretation of the i-th variable is the i-th
    projection
    \[I(x_1,\dots,x_n \mid x_i) = \pi_i : A^n \to A,\]

  * the interpretation of an operation over a term is the
    interpretation of the morphism componsed with the componentwise
    interpretation of subterms
    \[
    I(f \pair{t_1,\dots,t_k}) =
    If \circ \pair{It_1,\dots,It_k}
    \colon A^n \to A.
    \]
    where we implicitly assume the context to be $x_1,\dots,x_n$.

The interpretation of a particular variable depends therefore on the
context. We say that an interpretation *satisfies* an equation $\Gamma \mid u=v$
in a particular given context if the interpretation of both terms of
the equation is the same on that context, $I(\Gamma \mid u) = I(\Gamma \mid v)$.

We usually would like to find interpretations where all the axioms of the
theory were satisfied. These are called *models of the algebraic theory*.

***** TODO [#C] Example, groups                                  :ignore:
# Maybe this example could be written once we have developed
# the categorical definition.

# For instance, the term $(x \cdot y) \cdot z$ in our previously discussed theory of
# groups would be intepreted in a category with finite products and
# a terminal object $1$ as the morphism
# \[\begin{tikzcd}
# A \cong A \times 1 \rar{\pair{\id,!}} & A \times A \rar & A
# \end{tikzcd}\]
# and the axiom $(x \cdot y) \cdot z = x \cdot (y \cdot z)$ would be represented by the following commutative
# square:
**** Notion of representation-free theories                       :ignore:
The problem with this notion of algebraic theory is that it is not
representation-free; it is not independent of the choice of constants,
operations or axioms. There may be multiple formulations of the same
theory, with different but equivalent axioms. For instance,
cite:mccune91 discusses many single-equation axiomatizations of groups, 
such as
\[
x\ /\
\big(((x/x)/y)/z)\ /\ ((x/x)/x)/z\big)
= y
\]

with the binary operation $/$, related to the usual multiplication as $x / y = x \cdot y^{-1}$.

Our solution to this problem will be to capture all the algebraic
information of a theory -- all operations, constants and axioms --
into a category. Differently presented but equivalent theories will
give rise to the same category. This category will have /contexts/
$[x_1,\dots,x_n]$ as objects. A morphism from $[x_1,\dots,x_n]$ to
$[x_1,\dots,x_m]$ will be a tuple of terms
\[ 
\pair{t_1,\dots,t_k}
\colon [x_1,\dots,x_n] \to [x_1,\dots,x_m]
\]
such that every $t_k$ is given in the context $[x_1,\dots,x_n]$. 
Composition is defined componentwise as substitution of the terms of the 
first morphism into the variables of the second one, that is,
\[
\pair{s_1,\dots,s_n} = \pair{u_1,\dots,u_n} \circ \pair{t_1,\dots,t_m},
\]
where
\[ 
s_i = u_i[t_1,\dots,t_m / x_1,\dots,x_m].
\]

Two morphisms in this category $\pair{t_1,\dots,t_n}$ and $\pair{s_1,\dots,s_n}$ are equal if the axioms of
the theory imply the componentwise equality of its terms, that is, $t_i = s_i$.

This interpretation will lead us to our definition of *algebraic*
*theory* as a category with finite products.

Every model $M$ in the previous sense could be seen as a functor from
this category to a given category ${\cal C}$ preserving finite products. Once the
image of $M[x_1] = A$ is chosen, the functor is determined on objects by
\[
M[x_1,\dots,x_n] = A^{k}
\]
and once it is defined for the basic operations, it is inductively determined
on morphisms as

  * $M\pair{x_i} = \pi_i \colon A^k \to A$, for any morphism $\pair{x_i}$;
  * $M\pair{t_1,\dots,t_m} = \pair{Mt_1,\dots,Mt_m} \colon A^m \to A$, the 
    componentwise interpretation of subterms;
  * $M\pair{f\pair{t_1,\dots,t_m}} = Mf \circ \pair{Mt_1,\dots,Mt_{m}} \colon (M\mathbb{A})^m\to M\mathbb{A}$.

The fact that $M$ is a well-defined functor follows from the
assumption that it is a model.

*** Algebraic theories as categories
**** Algebraic theory                                             :ignore:
#+ATTR_LATEX: :options [Lawvere algebraic theory]
#+BEGIN_definition
An *algebraic theory* is a category $\mathbb{A}$ with finite products and objects
forming a sequence $A^0,A^1,A^2,\dots$ such that $A^m \times A^n = A^{m+n}$ for
any $m,n$.
#+END_definition

From this definition, it follows that $A^0$ must be the terminal object.

**** Models as functors                                           :ignore:
#+ATTR_LATEX: :options [Model]
#+BEGIN_definition
A *model* of an algebraic theory $\mathbb{A}$ in a category ${\cal C}$ is a functor
$M \colon \mathbb{A} \to {\cal C}$ preserving all finite products.
#+END_definition

#+ATTR_LATEX: :options [Category of models of a theory]
#+BEGIN_definition
The *category of models* $\mathtt{Mod}_{{\cal C}}(\mathbb{A})$ is the full subcategory of functor
category ${\cal C}^{\mathbb{A}}$ given by the functors preserving all finite products.
Morphisms between models of a theory in a category are natural transformations.
#+END_definition

#+ATTR_LATEX: :options [Algebraic category]
#+BEGIN_definition
An *algebraic category* is category equivalent to a category of the form $\mathtt{Mod}_{{\cal C}}(\mathbb{A})$,
where $\mathbb{A}$ is an algebraic theory.
#+END_definition

**** TODO Example: groups                                         :ignore:
#+ATTR_LATEX: :options [Theory of groups]
#+BEGIN_exampleth
# Groups as algebraic theory
# Category of groups as category of models in Set
# Abelian groups as models in the category Grp
#+END_exampleth

# Antipode in Hopf algebras
# https://www.youtube.com/watch?v=p3kkm5dYH-w

**** Example: fields                                              :ignore:
#+ATTR_LATEX: :options [Fields have no algebraic theory]
#+BEGIN_exampleth
<<example-fieldsarenotalgebraic>>
The category $\mathtt{Fields}$ is not an algebraic category.
Any algebraic category $\mathtt{Mod}_{{\cal C}}(\mathbb{A})$ has a terminal object given by the
constant functor $\Delta_1 : \mathbb{A} \to {\cal C}$ to $1$, the terminal object of ${\cal C}$. Note that
${\cal C}$ must have a terminal object for a model to it to exist, as
models must preserve all finite products. We know that $\Delta_1$ is a
terminal object because, in general, it is the terminal object of the
category of functors ${\cal C}^{\mathbb{A}}$.
However, $\mathtt{Fields}$ has no terminal object.
#+END_exampleth

**** TODO More examples
*** Completeness for algebraic theories
When defining interpretation of algebraic theories as categories we
should ensure the property of */semantic completeness/*. We already
know that, if an equation can be proved from the axioms, it will be
valid in all models; but we will also like to prove that, if every
model of the theory satisfies a particular equation, it can actually
be proved from the axioms of the theory.

#+ATTR_LATEX: :options [Completeness for algebraic theories]
#+BEGIN_theorem
Given $\mathbb{A}$ an algebraic theory, there exists a category ${\cal A}$ with
a model $U \in \mathtt{Mod}_{{\cal A}}(\mathbb{A})$ such that, for every terms $u,v$,
\[
U \text{ satisfies } u = v 
\iff
\mathbb{A} \text{ proves } u = v.
\] 
This is called the *universal model* for $\mathbb{A}$. This theorem
asserts that categorical semantics of algebraic theories are complete.
#+END_theorem
#+BEGIN_proof
Simply taking $\mathbb{A}$ with the identity functor, we have an universal
model for $\mathbb{A}$.
#+END_proof

Note that this universal model needs not to be set-theoretic; but,
even in this situation, we can always find a universal model in a
presheaf category via the Yoneda embedding.

#+ATTR_LATEX: :options [Yoneda embedding as a universal model]
#+BEGIN_proposition
The Yoneda embedding $y \colon \mathbb{A} \to \widehat{\mathbb{A}}$ is a universal model for $\mathbb{A}$.
#+END_proposition
#+BEGIN_proof
It preserves finite products because it preserves all limits, hence
it is a model. As it is a faithful functor, we know that any equation
proved in the model is an eqation proved by the theory.
#+END_proof

*** TODO Examples
**** Monoids on the category of endofunctors

** OLD Cartesian closed categories [Old]                          :noexport:
# Definition of cartesian closed by adjoints

*** Exponential
# Exponential as adjoint

#+ATTR_LATEX: :options [Exponential]
#+BEGIN_definition
An *exponential* of $A$ and $B$ in a category with binary products is an
object $B^A$ with a morphism $e : B^A \times A \to B$ called /evaluation morphism/,
such that, for any $f : C \times A \to B$ exists a unique $\widetilde{f} : C \to B^A$ such that
the following diagram commutes
\[\begin{tikzcd}
B^A & B^A \times A \drar{e} & \\
C \uar[dashed]{\exists! \widetilde f}  & C \times A \rar[swap]{f}\uar{\widetilde f \times id} & B 
\end{tikzcd}\]
#+END_definition

An object $A$ for which the exponentiation $-^A$ is always defined is called
*exponentiable*.

#+ATTR_LATEX: :options [Exponentials as adjoints]
#+BEGIN_proposition
<<prop-exponentialadjoints>>
An object $A$ in a category with binary products ${\cal C}$ is exponentiable if and only if
the functor $(- \times A) : {\cal C} \to {\cal C}$ has a right adjoint.
#+END_proposition
#+BEGIN_proof
# TODO
# Given by the counit
#+END_proof

*** Cartesian category
#+ATTR_LATEX: :options [Cartesian category]
#+BEGIN_definition
A *cartesian category* is a category with all finite products.
#+END_definition
#+ATTR_LATEX: :options [Cartesian closed category]
#+BEGIN_definition
A *cartesian closed category* is a category with all finite products
and exponentials.
#+END_definition

The definition of cartesian closed category can be written in terms of
existence of adjoints.

**** Cartesian closed categories by adjoints                      :ignore:
#+ATTR_LATEX: :options [Cartesian closed categories and adjoints]
#+BEGIN_proposition
Any category ${\cal C}$ is cartesian closed if and only if there exist
right adjoints for the following functors

  * $! \colon {\cal C} \to 1$, the unique functor to the terminal category;
  * $\Delta \colon {\cal C} \to {\cal C} \times {\cal C}$, the diagonal functor;
  * $(- \times A) \colon {\cal C} \to {\cal C}$, the product functor, for each $A \in {\cal C}$.
#+END_proposition
#+BEGIN_proof
# TODO
We know that the product functor of an object has a right adjoint if and
only if the object is exponentiable, as we saw in Proposition [[prop-exponentialadjoints]].
#+END_proof

***** TODO Adjoint diagrams                                      :ignore:
Knowing that $!x = \ast$ and $\Delta(x) = (x,x)$, we write these conditions
as

\begin{prooftree}
\AX$\ast\ \fCenter\to \ast$
\doubleLine
\UI$x\ \fCenter\to \top$
\AX$(x,x)\ \fCenter\to (y,z)$
\doubleLine
\UI$x\ \fCenter\to y \times z$
\AX$x \times a\ \fCenter\to y$
\doubleLine
\UI$x\ \fCenter\to y^a$
\noLine
\TIC{}
\end{prooftree}

**** Category of cartesian closed categories                      :ignore:
#+ATTR_LATEX: :options [Category of small cartesian closed categories]
#+BEGIN_definition
We call $\mathtt{Ccc}$ to the category of (small) cartesian closed
categories with functors preserving finite products and
exponentials as morphisms. These functors are called
*cartesian closed functors*.
#+END_definition

*** Frames and locales
#+ATTR_LATEX: :options [Completeness for posets]
#+BEGIN_proposition
Complete posets are cocomplete. Cocomplete posets are complete.
#+END_proposition
#+BEGIN_proof
# TODO
#+END_proof

#+ATTR_LATEX: :options [Frames]
#+BEGIN_definition
*Frames* are complete cartesian closed posets.
#+END_definition

# TODO: Equivalently A frame is a poset with distributive law.

#+ATTR_LATEX: :options [Frame morphism]
#+BEGIN_definition
A *frame morphism* is a function between frames preserving finite
infima and arbitrary suprema.
#+END_definition

# TODO: Locales

# TODO: Locales as non-pointed topological spaces, from An informal
# introduction to topos theory

** OLD Locally closed cartesian categories
# Clive Newstead - Locally closed cartesian categories and ML-type theory.
# Contar ML aquí y luego contarlo solo desde Agda
# Leer: Awodey - Type theory and homotopy
# Leer: nLab - https://ncatlab.org/nlab/show/relation+between+type+theory+and+category+theory#DependentTypeTheory
# Leer: http://www1.maths.leeds.ac.uk/%7Epmtng/Research/Lectures/lecture3.pdf
# Substitution is pullback http://math.andrej.com/2012/09/28/substitution-is-pullback/

In the same way that cartesian closed categories provide a
categorical interpretation of the simply typed \lambda-calculus,
locally closed cartesian categories will provide an interpretation
of Martin-Löf type theories.

*** Locally closed cartesian category
**** The pullback functor                                         :ignore:
#+ATTR_LATEX: :options [The pullback functor]
#+BEGIN_definition
Given a function $f \colon A \to B$ in any category ${\cal C}$ with all pullbacks, the
*pullback functor* $f^{\ast} \colon {\cal C}/B \to {\cal C}/A$ is defined for any object $y \colon Y \to B$
as the object $f^{\ast}y \colon (f^{\ast}Y) \to A$ such that
\[\begin{tikzcd}
(f^{\ast}Y) \rar{}\drar[phantom, near start, "\ulcorner"] \dar[swap]{f^{\ast}y} & Y \dar{y} \\
A\rar{f} & B
\end{tikzcd}\]
is a pullback square. The functor is defined on any morphism
$\alpha \colon y \to y'$ between two objects $y \colon Y \to B$, $y' \colon Y' \to B$ as
the only morphism making the following diagram commute
\[\begin{tikzcd}
f^{\ast}Y \ar{rrr}\ar[dashed]{dr}{\exists! f^{\ast}\alpha} \ar[bend right,swap]{ddr}{f^{\ast}y} &&&
Y \ar{dl}{\alpha}\ar[bend left=60]{ddl}{y} \\
& f^{\ast}Y' \dar[swap]{f^{\ast}y'} \rar & Y' \dar{y'} \\
& A \rar[swap]{f} & B \\
\end{tikzcd}\]
where $x$ and $x'$ form pullback squares with $y$ and $y'$. Note that the pullback
functor is only defined up to isomorphism in objects and well-defined on
morphisms by virtue of the universal property of pullbacks.
#+END_definition

**** Categorical dependent sum                                    :ignore:
#+ATTR_LATEX: :options [Left adjoint of the pullback functor]
#+BEGIN_proposition
Any pullback functor $f^{\ast} \colon A \to B$ has a left adjoint $\Sigma_{f}$.
#+END_proposition
#+BEGIN_proof
# TODO

\[\hom(\Sigma_f x, y) \cong \hom(x, f^{\ast} y)\]

\[\begin{tikzcd}
X \ar[bend right,swap]{ddr}{x} \ar[dashed]{dr}\ar[dashed, bend left]{drr} & & \\
& f^{\ast}Y \rar\dar{f^{\ast}y} & Y \dar{y} \\
& A \rar & B
\end{tikzcd}\]
#+END_proof

**** Categorical dependent product                                :ignore:
#+ATTR_LATEX: :options [Right adjoint of the pullback functor]
#+BEGIN_definition
A category ${\cal C}$ is locally cartesian closed if and only if the pullback
functor $f^{\ast} \colon {\cal C}/B \to {\cal C}/A$ has a right adjoint, called
$\Pi_f \colon {\cal C}/A \to {\cal C}/B$.
#+END_definition

*** TODO Beck-Chevalley condition
*** TODO Extensional Martin-Löf Type Theory
# http://www.math.mcgill.ca/rags/LCCC/LCCC.pdf
# The Biequivalence of Locally Cartesian Closed Categories and Martin-Löf Type Theories
# http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.646.9598&rep=rep1&type=pdf 

# Extensional theory with universes
**** Dependent sum                                                :ignore:
Introduction rule

\begin{prooftree}
\AXC{$\Gamma \vdash a \colon A$}
\AXC{$\Gamma \vdash b \colon B[a/x]$}
\BIC{$\Gamma \vdash \pair{a,b} \colon \sum_{x:A} B$}
\end{prooftree}

elimination rules

\begin{prooftree}
\AXC{$\Gamma \vdash c \colon \sum_{x:A} B$}
\UIC{$\Gamma \vdash \pi_1(c) \colon A$}
\AXC{$\Gamma \vdash c \colon \sum_{x:A} B$}
\UIC{$\Gamma \vdash \pi_2(c) \colon B[\pi_1(c) / x]$}
\noLine
\BIC{$$}
\end{prooftree}

** OLD Heyting algebras
# Tarski-Stone representation theorem
In this section, we develop the notion of a *Heyting algebra* and show
its differences with a Boolean algebra.

There is a correlation between classical propositional calculus and
the Boolean algebra of the subsets of a given set. If we interpret
a proposition $p$ as a subset of a given universal set $P \subset U$ and
fix an element $u \in U$, propositions can be translated to $u \in P$, 
logical connectives can be translated as

\[\begin{tabular}{cc|cc}
logic &  & &  subsets \\
\hline
$P \land Q$ & and & intersection & $P \cap Q$  \\
$P \lor Q$ & or & union  & $P \cup Q$ \\
$\neg P$ & not & complement & $\overline{P}$ \\
$P \to Q$ & implication & complement union & $\overline{P} \cup Q$
\end{tabular}\]

using crucially that $\neg P \land Q \equiv P \to Q$.

In the same way that Boolean algebras correspond to classical
propositional logic, Heyting algebras correspond to intuitionistic
propositional calculus. Its model on a set-like theory is not the subsets
of a given set, but instead, only the /open/ sets of a given
topological space

\[\begin{tabular}{cc|cc}
logic &  & & open sets \\
\hline
$P \land Q$ & and & intersection & $P \cap Q$  \\
$P \lor Q$ & or & union  & $P \cup Q$ \\
$\neg P$ & not & interior of the complement & $\mathrm{int}\left(\overline{P}\right)$ \\
$P \to Q$ & implication & interior of complement and consequent & $\mathrm{int}(\overline{P} \cup Q)$
\end{tabular}\]

where $\mathrm{int}$ is the topological interior of a set.
# TODO: This definition of the implication does not match with the used
# on Moerdijk. It is equivalent (?) but different.

*** Lattices and Boolean algebras
**** Lattices, definition                                         :ignore:
#+attr_latex: :options [Lattice]
#+begin_definition
A *lattice* is a partially ordered set with all binary products and
coproducts. It is a *bounded lattice* if it has all finite products
and coproducts.
#+end_definition

We will usually work with bounded lattices and simply call them
/lattices/. A bounded lattice can be defined then by the following
bidirectional inference rules

\begin{prooftree}
\AXC{$0 \leq x \leq 1$}
\AXC{$z \leq x$}
\AXC{$z \leq y$}
\doubleLine
\BIC{$z \leq x \land y$}
\AXC{$x \leq z$}
\AXC{$y \leq z$}
\doubleLine
\BIC{$x \lor y \leq z$}
\noLine
\TIC{$$}
\end{prooftree}


meaning that it has a terminal and a final object, in order to have
all finte products and coproducts, and all binary products and
coproducts.

#+ATTR_LATEX: :options [Lattice homomorphism]
#+BEGIN_definition
A lattice homomorphism is a function between lattices preserving
finite products and coproducts. That is, a function $f$ such that

  * $f(0) = 0$, $f(1) = 1$,
  * $f(x \wedge y) = f(x) \land f(y)$,
  * $f(x \vee y) = f(x) \vee f(y)$;

and the category of lattices and lattice homomorphisms is denoted
by $\mathtt{Lat}$.
#+END_definition

A bounded lattice can also be defined as a set with $0,1$ and two binary
operations $\land,\lor$ satisfying

  * $1 \land x = x$, and $0 \lor x = x$;
  * $x \land x = x$, and $x \lor x = x$;
  * $x \land (y \lor x) = x = (x \land y) \lor x$;
  * $x \land y = y \land x$ and $x\lor y = y \lor x$.

This perspective allows us also to define a lattice object in any
category as an object $L$ with morphisms

\[
\land \colon L \times L \to L,
\quad
\lor \colon L \times L \to L,
\quad
0,1 \colon \mathrm{I} \to L,
\]

where $\mathrm{I}$ is the terminal object of the category; and commutative
diagrams encoding the previous equations.

**** Distributive lattices                                        :ignore:
#+attr_latex: :options [Distributive lattice]
#+begin_definition
A *distributive lattice* is a lattice where
\[
x \land (y \lor z) = (x \land y) \lor (x \land z),
\]

holds for all $x,y,z$.
#+end_definition
# TODO: This implies the dual distributive law

**** Complements                                                  :ignore:
#+attr_latex: :options [Complement]
#+begin_definition
A *complement* of $a$ in a bounded lattice is an element $\overline{a}$ such that
\[
a \land \overline{a} = 0, \qquad
a \lor \overline{a} = 1.
\]
#+end_definition

#+attr_latex: :options [The complement in distributive lattices is unique]
#+begin_proposition
If a complement of an element exists in a distributive lattice, it is unique.
#+end_proposition
# TODO: Commutativity is needed on this proof, but it is not stated elsewhere
#+begin_proof
Given $a$ with two complements $x,y$, we have that
\[
x = x \land (a \lor y) = (x \land a) \lor (x \land y) =
(y \land a) \lor (x \land y) = y \lor (x \land a) = y.
\]
#+end_proof

**** Boolean algebras                                             :ignore:
#+attr_latex: :options [Boolean algebra]
#+begin_definition
A *Boolean algebra* is a distributive bounded lattice in which every element
has a complement.
#+end_definition

Boolean algebras satisfy certain known properties such as the DeMorgan laws
and the double negation elimination rule.

# TODO: Every Boolean algebra is the algebra of subsets of some set.
# This is a result by M.H.Stone, cited in pag 50 Moerdijk.

*** Heyting algebras
**** Definition of Heyting algebras                               :ignore:
#+attr_latex: :options [Heyting algebra]
#+begin_definition
A *Heyting algebra*, also called *Brouwerian lattice*, is a bounded lattice
which is cartesian closed as a category; that is, for every pair of elements
$x,y$, the exponential $y^x$ exists.
#+end_definition

The exponential in Heyting algebras is usually written as $x \Rightarrow y$ and is 
characterized by its adjunction with the product
\[
z \leq (x \Rightarrow y) \text{ if and only if } z \land x \leq y,
\]
which can be expressed logically as
\begin{prooftree}
\AXC{$z \land x \leq y$}
\UIC{$z \leq x \Rightarrow y$}
\end{prooftree}

#+ATTR_LATEX: :options [Heyting algebra homomorphism]
#+BEGIN_definition
A *Heyting algebra homomorphism* is a lattice homomorphism between
Heyting algebras which does preserve implication. The category of
Heyting algebras is written as $\mathtt{Heyt}$.
#+END_definition

# TODO: Any complete distributive lattice is a Heyting algebra

**** Boolean algebras are Heyting algebras                        :ignore:
#+attr_latex: :options [Boolean algebras are Heyting algebras]
#+begin_proposition
Every Boolean algebra is a Heyting algebra with exponentials given by
\[
(x \Rightarrow y) = \overline{x} \land y.
\]
#+end_proposition
#+begin_proof
We will prove that
\[
z \leq (\overline{x} \lor y) \text{ if and only if } z \land x \leq y.
\]
If $z \leq (\overline{x} \lor y)$,
\[
z \land x \leq
(\overline{x} \lor y) \land x \leq
(\overline{x} \land x) \lor (y \land x) \leq
y \land x \leq
y;
\]
and if $z \land x \leq y$,
\[
z = 
z \land 1 =
z \land (\overline{x} \lor x) =
(z \land \overline{x}) \lor (z \land x) \leq 
(z \land \overline{x}) \lor y \leq
z \lor y.
\]
#+end_proof

**** Negation on Heyting algebras                                 :ignore:
#+attr_latex: :options [Negation]
#+begin_definition
The *negation* of $x$ in a Heyting algebra is defined as
\[
\neg x = (x \Rightarrow 0).
\]
#+end_definition

In general, we only have that $\neg\neg x \leq x$. An element for which
$\neg\neg x = x$ is called a *regular* element.

# TODO: Regular elements form a Boolean algebra.

# TODO: Frames and Heyting algebras. What are the regular elements?

**** Properties of a Heyting algebra                              :ignore:
#+begin_proposition
In any Heyting algebra,

  1) $x \leq \neg \neg x$,
  2) $x \leq y$ implies $\neg y \leq \neg x$,
  3) $\neg x = \neg\neg\neg x$,
  4) $\neg\neg (x \land y) = \neg \neg x \land \neg \neg y$,
  5) $(x \impl x) = 1$,
  6) $x \land (x \impl y) = x \land y$,
  7) $y \land (x \impl y) = y$,
  8) $x \impl (y \land z) = (x \impl y) \land (x \impl z)$.

Any bounded lattice $L$ with an operation satisfying the last four properties
is a Heyting algebra with this operation as implication.
#+end_proposition
#+begin_proof
We can prove the inequalities using the definition of implication.

  1) By definition, $x \land (x \Rightarrow \bot) \leq \bot$.
  2) Again, by definition, $\neg y \land x \leq \neg y \land y \leq \bot$.
  3) Is a consequence of the first two inequalities.
  4) We know that $x \land y \leq x,y$, and therefore $\neg\neg (x\land y) \leq \neg \neg x \land \neg \neg y$.
     We can prove $\neg\neg x \land \neg\neg y \leq \neg\neg (x \land y)$ using the definition of
     negation to get $\neg\neg x \land \neg\neg y \land \neg (x \land y) \leq \bot$, and then by reversing
     the definition of implication $\neg\neg y \land \neg (x \land y) \leq \neg\neg\neg x = x$. Applying
     the same reasoning to $y$, we finally get $x \land y \land \neg (x \land y) \leq \bot$.
  5) Follows from $x \land 1 \leq x$.
  6) Using the evaluation morphism, we know that $x \land (x \impl y) \leq y \leq x \land y$.
  7) Using the definition of implication $y = y \land y \leq y \land (x \Rightarrow y)$.
  8) The exponential $x \Rightarrow -$ is a right adjoint and it preserves products.
#+end_proof

**** Characterization of Boolean algebras                         :ignore:
#+attr_latex: :options [Complements are negations in Heyting algebras]
#+begin_proposition
If an element has a complement on a Heyting algebra, it must be $\neg x$.
#+end_proposition
#+begin_proof
Let $a$ a complement of $x$. By definition, $x \land a = \bot$ and therefore $a \leq \neg x$.
The reverse inequality can be proven using the lattice properties as
\[
\neg x = \neg x \land (x \lor a) = \neg x \land a.
\]
#+end_proof

#+attr_latex: :options [Characterization of Boolean algebras]
#+begin_proposition
A Heyting algebra is Boolean if and only if $\neg\neg x = x$ for every $x$; 
and if and only if $x \lor \neg x = 1$ for every $x$.
#+end_proposition
#+begin_proof
In a Boolean algebra the complement is unique and $\neg\neg x = x$. Now, 
if $\neg\neg y = y$ for every $y$,
\[
x \lor \neg x = \neg\neg (x \lor \neg x) = \neg (\neg x \land \neg\neg x) = \top;
\]
and then, as $x \lor \neg x = \bot$, $\neg x$ must be the complement of $x$. We have
used the fact that $\neg (x \lor y) = (\neg x) \land (\neg y)$ in any Heyting algebra.
#+end_proof

*** Intuitionistic propositional calculus
#+ATTR_LATEX: :options [Existence of free Heyting algebras]
#+BEGIN_proposition
# TODO
#+END_proposition

#+ATTR_LATEX: :options [Intuitionistic propositional calculus]
#+BEGIN_definition
The *Intuitionistic Propositional Calculus* (IPC) is the free Heyting
algebra over an infinite countable set $\{p_0,p_1,p_2,\dots\}$ of elements 
which are usually called /atomic propositions/.
#+END_definition

**** Classical propositional calculus
#+ATTR_LATEX: :options [Classical propositional calculus]
#+BEGIN_definition
The *Classical Propositional Calculus* (CPC) is the free Boolean
algebra over an infinite countable set $\{p_0,p_1,p_2,\dots\}$.
#+END_definition

# TODO: Law of excluded middle and reductio ad absurdum.

*** Quantifiers as adjoints
# Maybe this could be written before, in the adjoints section.
#+begin_definition
Given a relation between sets $S \subseteq X \times Y$, the functors $\forall_p, \exists_p \colon {\cal P}(X \times Y) \to {\cal P}(Y)$
are defined as

  * $\forall_p S = \left\{ y \mid \forall x: \pair{x,y} \in S \right\}$, and
  * $\exists_p S = \left\{ y \mid \exists x: \pair{x,y} \in S \right\}$.
#+end_definition

#+begin_theorem
The functors $\exists_p,\forall_p$ are the left and right adjoints to the inverse image of the
projection functor, $p^{\ast} \colon {\cal P}(Y) \to {\cal P}(X \times Y)$.
#+end_theorem
#+begin_proof
# TODO: Proof
#+end_proof

#+begin_theorem
Given any function on sets $f \colon Z \to Y$, the inverse image functor $f^{\ast} \colon {\cal P}Y \to {\cal P}Z$
has left and right adjoints, called $\exists_f$ and $\forall_f$.
#+end_theorem
** OLD Simply-typed \lambda-theories                              :noexport:
*** Simply-typed \lambda-theories
We will consider again the previously defined simply typed
\lambda-calculus, but this time, as a theory instead of as a
programming language. Recall that a /context/ was a sequence
of typed variables $x_1,x_2,\dots,x_n$, of the form
\[
\Gamma = x_1:A_1, \dots, x_n:A_n.
\]
And any /typing judgement/ was of the form $\Gamma \vdash a : A$. This time,
the theory will also introduce equations of the form $\Gamma \vdash a = b : A$
as judgments.

In particular, we will work only with a fragment of system that we
defined in "[[*Extending the simply typed \lambda-calculus][Extending the simply typed \lambda-calculus]]", namely, the
fragment containing only arrow types, an unit type and product
types. 

\\

**** Equality in simply-typed \lambda-theories                    :ignore:
Equality must now be defined over these typed terms. We have the
following set of rules for it, clearly inspired by the usual properties
of equivalence relations, \beta-reductions and \eta-reductions.

 1) Any set of assumptions can be weakened
    \begin{prooftree}
    \RightLabel{\textsc{weak}}
    \AXC{$\Gamma \vdash u = v : A$}
    \UIC{$\Gamma, w:B \vdash u = v : A$}
    \end{prooftree}

 2) Equality is an equivalence relation
    \begin{prooftree}
    \RightLabel{\textsc{refl}}
    \AXC{$$}
    \UIC{$\Gamma \vdash u = u : A$}
    \RightLabel{\textsc{symm}}
    \AXC{$\Gamma \vdash u = v : A$}
    \UIC{$\Gamma \vdash v = u : A$}
    \RightLabel{\textsc{trans}}
    \AXC{$\Gamma \vdash u = v : A$}
    \AXC{$\Gamma \vdash v = w : A$}
    \BIC{$\Gamma \vdash u = w : A$}
    \noLine
    \TIC{$$}
    \end{prooftree}

 3) The unit type has only one element
    \begin{prooftree}
    \AXC{$$}
    \UIC{$\Gamma \vdash t = \ast : \top$}
    \end{prooftree}

 4) Product reduction rules define the following equalities on constructors
    \begin{prooftree}
    \AXC{$\Gamma \vdash u = w : A$}
    \AXC{$\Gamma \vdash v = t : B$}
    \BIC{$\Gamma \vdash \pair{u,v} = \pair{w,t} : A \times B$}
    \AXC{$$}
    \UIC{$\Gamma \vdash \fst \pair{u,v} = u : A$}
    \AXC{$$}
    \UIC{$\Gamma \vdash \snd \pair{u,v} = v : B$}
    \noLine
    \TIC{$$}
    \end{prooftree}
    and the following ones on projections
    \begin{prooftree}
    \AXC{$\Gamma \vdash m = n : A \times B$}
    \UIC{$\Gamma \vdash \fst\ m = \fst\ n : A$}
    \AXC{$\Gamma \vdash m = n : A \times B$}
    \UIC{$\Gamma \vdash \snd\ m = \snd\ n : B$}
    \AXC{$$}
    \UIC{$\Gamma \vdash m = \pair{\fst\ m, \snd\ m} : A \times B$}
    \noLine
    \TIC{$$}
    \end{prooftree}

 5) Reduction rules for functions define the following equalities for applications
    \begin{prooftree}
    \AXC{$\Gamma \vdash f = g : A \to B$}
    \AXC{$\Gamma \vdash u = v : A$}
    \BIC{$\Gamma \vdash f\ u = g\ v : B$}
    \AXC{$$}
    \RightLabel{$\beta$-\textsc{rule}}
    \UIC{$\Gamma \vdash (\lambda x. w)\ u = w[u/x] : A$}
    \noLine
    \BIC{$$}
    \end{prooftree}
    and the following ones for abstractions
    \begin{prooftree}
    \AXC{$\Gamma, x:A \vdash w = t : B$}
    \UIC{$\Gamma \vdash (\lambda x.w) = (\lambda x.t) : A \to B$}
    \AXC{$$}
    \RightLabel{$\eta$-\textsc{rule}}
    \UIC{$\Gamma \vdash (\lambda x.f\ x) = f : A \to B$}
    \noLine
    \BIC{$$}
    \end{prooftree}

**** Lambda theories                                              :ignore:
In a \lambda-theory we may want to add a set of additional equations
apart from those defined in the previous set of rules.

#+ATTR_LATEX: :options [Simply typed lambda theory]
#+BEGIN_definition
A simply-typed \lambda-theory is given by

  * a set of /basic types/;
  * a set of /basic constants/ with their types; and
  * a set of /equations/ on those terms, of the form $\Gamma \vdash a = b : A$,
    where $\Gamma$ is the variable context.
#+END_definition

# TODO Any algebraic theory is a lambda theory
# TODO Preorders
# TODO Theory of a reflexive type

# The difference here is that we can now write equalities between
# functions.

*** OLD Interpretation of \lambda-theories
#+ATTR_LATEX: :options [Interpretation of a lambda theory]
#+BEGIN_definition
An *interpretation* of a \lambda-calculus $\mathbb{T}$ in a cartesian
closed category ${\cal C}$ is given by

  1. an object $\intr{A} \in \mathbb{C}$ for every basic type $A$ in $\mathbb{T}$.
  2. a morphism $\intr{c} \colon 1 \to \intr{A}$ for every constant $c : A$.

The interpretation can be extended to all types using the terminal
object, binary products and exponentials

 * $\intr{1} = 1$;
 * $\intr{A \times B} = \intr{A} \times \intr{B}$;
 * $\intr{A \impl B} = \intr{B}^{\intr{A}}$.

Every context $\Gamma = x_1:A_1, \dots,x_n:A_n$ can be interpreted as the
object $\intr{A_1} \times \dots \times \intr{A_n}$.
#+END_definition
# TODO: check definition. Motivation.

*** Syntactic categories
**** Definition of the syntatic category for a lambda theory      :ignore:
#+ATTR_LATEX: :options [Syntactic category]
#+BEGIN_definition
The *syntactic category* of a \lambda-theory, ${\cal S}(\mathbb{T})$, is given by

 * the types of the theory as objects; and
 * the terms in context $x : A \vdash t :B$ as morphisms between $A$ and $B$.

Two morphisms $x:A \vdash u : B$ and $x:A \vdash v : B$ are equal if $x : A \vdash u = v : B$
can be proved inside $\mathbb{T}$. The composition of two morphisms $a : A \vdash b : B$ and
$b' : B \vdash c : C$ is given by $a : A \vdash c[b/b'] : C$.
#+END_definition

**** Syntactic categories of lambda theories are cartesian closed :ignore:
#+ATTR_LATEX: :options [Syntactic categories are cartesian closed]
#+BEGIN_proposition
The syntactic category of a \lambda-theory is cartesian closed.
#+END_proposition
#+BEGIN_proof
We will prove that it has terminal, product and exponential objects.
The terminal object is the unit type $\top$; it has a morphism
$x : A \mid \ast : \top$ from any other type, and it is unique by virtue of
the equality $\Gamma \vdash t = \ast : \top$.

Given two types $A,B$, its product is $A \times B$ with projections
$m : A \times B \vdash \fst\ m : A$ and $m : A \times B \vdash \snd\ m : b$. Its
universal property holds because for any other pair of morphisms
$z : C \vdash a : A$ and $z : C \vdash b : B$, there exists a morphism
\[
z : C \vdash \pair{a,b} : A \times B
\]
satisfying that

 * $z : C \vdash \fst\ \pair{a,b} = a : A$,
 * $z : C \vdash \snd\ \pair{a,b} = b : B$,

and if any other morphism $z : C \vdash d : A \times B$ exists satisfying
these same conditions, then
\[
d = \pair{\fst\ d, \snd\ d} = \pair{a,b}.
\]

Finally, given two types $A,B$, its exponential is $A \to B$ with
the evaluation morphism
\[
m : (A \to B) \times A \vdash (\fst\ m)\ (\snd\ m) : B.
\]
Given any $p : C \times A \vdash q : B$, there exists a morphism
\[
z : C \vdash \lambda x. q[\pair{z,x}/p] : A \to B
\]
such that when we evaluate over any pair $p$ we get
\[
(\lambda x.q[\pair{\fst\ p,x}/p]) (\snd\ p) =
q[\pair{\fst\ p, \snd\ p}/p] = q[p/p] = q;
\]
and if any other morphism $z : C \vdash d : A \to B$ exists satisfying
this same condition, then $(d[ \fst\ p /z] (\snd\ p))$ would equal $q$ and
\[\begin{aligned}
\lambda x. q[\pair{z,x}/p] &= 
\lambda x. (d[\fst\ p/z]\ (\snd\ p))[\pair{z,x}/p] \\ &=
\lambda x. (d[z/z]\ x) \\&= d. & \qedhere
\end{aligned}\]
#+END_proof

**** Models of a lambda-theory                                    :ignore:
#+ATTR_LATEX: :options [Model of a lambda-theory]
#+BEGIN_definition
A *model* of a \lambda-theory $\mathbb{T}$ is a functor $M \colon {\cal S}(\mathbb{T}) \to {\cal C}$ preserving
finite products and exponentials.
#+END_definition

# TODO: Canonical interpretation
As we did with Lawvere theories, we can prove that categorical
semantics for simply typed \lambda-theories is complete. By construction,
given any theory $\mathbb{T}$,
\[
\mathbb{T} \mbox{ proves } \Gamma \vdash x = y : A
\quad\iff\quad
{\cal S}(\mathbb{T}) \mbox{ satisfies } \Gamma \vdash x = y : A.
\]

*** Translations, category of lambda-theories
#+ATTR_LATEX: :options [Translation]
#+BEGIN_definition
A *translation* between \lambda-theories $\tau \colon \mathbb{T} \to \mathbb{U}$ is a model of $\mathbb{T}$
in the syntactic category ${\cal S}(U)$.
#+END_definition

#+ATTR_LATEX: :options [Translation]
#+BEGIN_definition
A *translation* between \lambda-theories $\tau \colon \mathbb{T} \to \mathbb{U}$ is a function on
types and terms

  1. preserving type constructors
     \[
     \tau 1 = 1,\qquad
     \tau(A \times B) = \tau A \times \tau B,\qquad
     \tau(A \to B) = \tau A \to \tau B;
     \]

  2. preserving the term structure
     \begin{center}\begin{array}{lll}
     \tau(\texttt{fst}\ m) = \texttt{fst}\ (\tau m), &
     \tau(\texttt{snd}\ m) = \texttt{snd}\ (\tau m), &
     \tau\pair{a,b} = \pair{\tau a, \tau b}, \\
     \tau (f\ x) = (\tau f)\ (\tau x), &
     \tau (\lambda x. m) = \lambda x. (\tau m);
     \end{array}\end{center}

  3. and preserving all equations, $t \equiv u$ implies $\tau t \equiv \tau u$.
#+END_definition


#+ATTR_LATEX: :options [Category of lambda-theories]
#+BEGIN_definition

#+END_definition


#+ATTR_LATEX: :options [Isomorphism of types]
#+BEGIN_definition
Two types in a \lambda-theory $\mathbb{T}$ are isomorphic if there exist
terms $x:A \mid t:B$ and $y:B \mid u:A$ such that
\[
x:A\mid u[t/y] = x : A, \quad\text{ and }\quad y : B \mid t[u/x] = y : B,
\]
are provable in $\mathbb{T}$.
#+END_definition

#+ATTR_LATEX: :options [Equivalence of theories]
#+BEGIN_definition
Two \lambda-theories $\mathbb{T},\mathbb{U}$ are equivalent if there are a pair of translations
$\tau : \mathbb{T} \to \mathbb{U}$ and $\sigma : \mathbb{U} \to \mathbb{T}$ such that
\[
\sigma(\tau A) \cong A, \quad\text{ and }\quad \tau(\sigma B) \simeq B;
\]
for any given types $A,B$.
#+END_definition

*** Internal language of a category
#+ATTR_LATEX: :options [Internal language]
#+BEGIN_definition
The *internal language* of a small cartesian closed category ${\cal C}$
is a \lambda-theory given by

 1. a /basic type/ $\intl{A }$ for every object $A \in {\cal C}$;

 2. a /constant/ $\intl{f} \colon \intl{A} \to \intl{B}$ for every morphism $f : A \to B$;

 3. the /identity/ axiom 
    \[
    x : \intl{A} \mid \intl{\id}\ x = x : \intl{A}
    \] 
    for every $A$;

 4. the /composition/ axiom
    \[
    x : \intl{A} \mid \intl{g \circ f}\ x = \intl{g}\ (\intl{f}\ x) : \intl{C}
    \]
    for every pair of composable morphisms $f : A \to B$ 
    and $g : B \to C$;

 5. and /constants/
    \[\begin{aligned}
    \texttt{T} &: \texttt{1} \to \intl{1} \\
    \texttt{P}_{A,B} &: \intl{A} \times \intl{B} \to \intl{A \times B} \\
    \texttt{E}_{A,B} &: (\intl{A} \to \intl{B}) \to \intl{B^{A}}
    \end{aligned}\]
    for any $A,B \in {\cal C}$.

Satisfying the following axioms
\[\begin{aligned}
u : \intl{1}                 &\mid \mathtt{T}\ast = u : \intl{1} \\
z : \intl{A \times B}        &\mid \mathtt{P}_{A,B}\pair{\intl{\pi_0} z, \intl{\pi_1} z} = z : \intl{A \times B} \\
w : \intl{A} \times \intl{B} &\mid \pair{\intl{\pi_0}(\mathtt{P}_{A,B}w), \intl{\pi_1}(\mathtt{P}_{A,B}w)} = w : \intl{A} \times \intl{B} \\
f : \intl{B^A}               &\mid \mathtt{E}_{A,B}(\lambda x^{\scriptsize\intl{A}}. \intl{\mathtt{ev}_{A,B}}\ (\mathtt{P}_{A,B}\pair{f,x})) = f : \intl{B^A} \\
g : \intl{A} \to \intl{B}    &\mid \lambda x^{\scriptsize\intl{A}}.\intl{\mathtt{ev_{A,B}}} (\mathtt{P}_{A,B}\pair{\mathtt{E}_{A,B}g,x}) = g : \intl{A} \to \intl{B} \\
\end{aligned}\]
#+END_definition

These axioms ensure the isomorphism between the terminal, product and
exponential types of the category and the language; that is,

 * $\intl{1} \cong 1$,
 * $\intl{A \times B} \cong \intl{A} \times \intl{B}$,
 * $\intl{B^A} \cong \intl{A} \to \intl{B}$.

**** TODO Equivalence of CC categories
** OLD Type theory (abstract)                                       :ignore:
#+LATEX: \ctparttext{\color{black}\begin{center}
This section is mainly based on cite:hottbook and [Course on Hott, Harper].
#+LATEX: \end{center}}

** OLD Type theory
# Bishop: Constructive analysis 1967
# DeBruijn: Automath

*** Martin-Löf Type Theory
Type theory can be seen as an intuitionistic foundation of mathematics.

 * *Martin-Löf Type Theory* (MLTT) can be used as a constructive and computational
   foundation of mathematics. It is not directly based on first-order predicate
   logic, but only interpreted in it via the Curry-Howard isomorphism. It comes
   in two flavours, intensional and extensional.
   
 * *Intensional type theory* (ITT) is an intuitionistic type theory serving as
   the core to many other type theories.
   
 * *Extensional type theory* (ETT) extends Intensional Type Theory with
   equality of reflection and uniqueness of identity proofs. Types behave
   like sets when we interpret them in this setting, and therefore, it
   can be seen as an intuitionistic theory of sets.

The principal difference between types and sets is that 
In Type theory, membership of an element to a type, as in $a : A$, is a
/judgment/ of the theory instead of a /proposition/. In practice, this
means that that we can write things like $\forall a. \left(a \in A \to (a,a) \in A \times A\right)$,
as $a \in A$ *is* a proposition; but we cannot write $\prod_{a : A} (a,a) : A \times A$.
A type declaration is not part of the language.

This section follows [Course on Hott, Harper] and [Hott].

We introduce ITT with Naturals, Sigma, Pi, Identity types and Universes.
[Martin-Löf 73]

# Sets and logic
# Constructivism
# Topos logic vs Curry-Howard logic

**** Contexts and judgments
As we did when we described simply typed \lambda-calculus; we will present
a type theory using contexts, substitutions and some inference rules. We
consider three different kinds of judgments for this formal system, namely,

  * $\Gamma\ \mathtt{ctx}$, expressing that $\Gamma$ is a context;
  * $\Gamma \vdash a : A$, expressing that, from the context $\Gamma$, it follows that $a$ is
    of type $A$; and
  * $\Gamma \vdash a \equiv a' : A$, expressing that, from the context $\Gamma$, it follows that
    $a$ is /definitionally equal/ to $a'$. It is important not to confuse this
    notion of equality with the notion of /propositional equality/ we will
    describe later.

*Contexts*, in particular, will be given by a (possibly empty) list of type
declarations
\[
x_1{:}A_1,\ x_2{:}A_2,\ \dots,\ x_n{:}A_n,
\]
and we will consider as valid the judgment saying that the empty context
is a context ($\cdot\ \mathtt{ctx}$), and the judgment saying that, given a context
$x_1{:}A_1,\ x_2{:}A_2,\ \dots,\e x_{n-1}{:}A_{n-1}$ and any type $A_n$, we can take a new
unused variable to form a new context
\[x_1{:}A_1,\ x_2{:}A_2,\ \dots,\e x_{n-1}{:}A_{n-1}, x_n{:}A_n\ \mathtt{ctx}.\]

***** TODO Admissible rules: weakening and substitution          :ignore:

**** Type universes
If we want to blur the difference between types and terms, we will need
type declarations for types. Types whose elements are types are called
/*universes*/. We would like, then, to define a single universe of all
types ${\cal U}$ containing even itself as an element, ${\cal U} : {\cal U}$; but this leads
to paradoxes. In particular, we can encode a particular version of Russell's
paradox.
# In appendix ?, a mechanized proof in Agda of this fact is shown.

To avoid having to deal with paradoxes, we will postulate a
*/hierarchy of cumulative universes/*; that is, we will consider
a list of inclusions between countably many type universes
\[
{\cal U}_0 : {\cal U}_1 : {\cal U}_2 : \dots
\]
and such that $a : {\cal U}_i$ implies $a : {\cal U}_{i+1}$. The relevant inference rules
are
\begin{prooftree}
\AXC{$$}
\UIC{$\Gamma \vdash {\cal U}_i : {\cal U}_{i+1}$}
\AXC{$\Gamma \vdash A : {\cal U}_i$}
\UIC{$\Gamma \vdash A : {\cal U}_{i+1}$}
\noLine
\BIC{$$}
\end{prooftree}
for each $i$ in the natural numbers.

# Type universes a la Russell, they are different in other presentations of ITT

Universe indices, however, are usually implicitly assumed when writing
ITT; as we will mostly work with types from some fixed universe of the
hierarchy ${\cal U}$ and only refer to higher universes when necessary. This
should not lead to confusion: a derivation will be only valid if we
can assign indices to the universes consistently, even if we do not
explicitly write them.

**** Defining types
Types will be defined by the formation and elimination rules we can
apply to them.  We will follow a general pattern for specifying the
typing rules of ITT. They will be classified into

  * *formation rules*, indicating how to create new types of a
    particular kind;
  * *introduction rules*, indicating how to create new terms of
    a particular type;
  * *elimination rules*, indicating how to use elements of a
    particular type;
  * *\beta-reductions*, indicating how elimination acts on terms;
  * *\eta-reductions*, defining some kind uniqueness principle.

Depending in how the uniqueness principle is defined, we classify types
into negative and positive types.

  * Uniqueness of *negative types* states that every element of
    the type can be reconstructed by applying eliminators to it
    and then applying a constructor. Products are an example of
    negative types.

  * Uniqueness of *positive types* states that every funtion from
    the type is determined by some data. Coproducts are an example
    of positive types.

**** OLD Dependent function types
***** Dependent function types: introduction                     :ignore:
*Dependent function types*, or *\Pi-types*, are the generalized version
of the function types in simply-typed lambda calculus. The elements of $\prod_{x:A} B(x)$ are functions
with the type $A$ as domain and a changing codomain $B(x)$, depending on
the specific element to which the function is applied. This type is often
written also as $\Pi(x:A), B(x)$ to resemble the universal quantifier; under
the /propositions as types/ interpretation, it would correspond to the proof
that a proposition $B$ holds for any $x : A$, that is, $\forall (x : A), B(x)$.

***** Dependent function types: definition                       :ignore:
#+ATTR_LATEX: :options [Dependent function type]
#+BEGIN_definition
The following rules apply for the dependent function type:

  * its formation rule sinthetizes the fact that the codomain
    type can depend on the argument to which the function is applied,
    \begin{prooftree}
    \RightLabel{$\Pi$\textsc{-form}}
    \AXC{$\Gamma \vdash A : {\cal U}_i$}
    \AXC{$\Gamma, x:A \vdash B : U_i$}
    \BIC{$\Gamma \vdash \prod_{x:A}B : {\cal U}_i$}
    \end{prooftree}
    
  * its introduction rule its a generalized version of \lambda-abstraction,
\begin{prooftree}
\RightLabel{$\Pi$\textsc{-intro}}
\AXC{$\Gamma, x:A \vdash b:B$}
\UIC{$\Gamma \vdash \lambda x.b : \prod_{x:A}B$}
\end{prooftree}

  * and its elimination rule generalizes function application,
\begin{prooftree}
\RightLabel{$\Pi$\textsc{-elim}}
\AXC{$\Gamma \vdash f : \prod_{x:A} B$}
\AXC{$\Gamma \vdash a : A$}
\BIC{$\Gamma \vdash f(a) : B[a/x]$}
\end{prooftree}

  * its \beta-rule is similar to simply typed lambda calculus' \beta-rule, with the difference that
    it has to specify a substitution on the type of the codomain
    \begin{prooftree}
    \RightLabel{$\Pi$\textsc{-comp}}
    \AXC{$\Gamma, x:A \vdash b:B$}
    \AXC{$\Gamma \vdash a:A$}
    \BIC{$\Gamma \vdash (\lambda x.b)\ a \equiv b[a/x] : B[a/x]$}
    \end{prooftree}

  * and its \eta-rule is also similar to simply typed lambda calculus' one
    \begin{prooftree}
    \RightLabel{$\Pi$\textsc{-uniq}}
    \AXC{$\Gamma \vdash f : \prod_{x:A} B$}
    \UIC{$\Gamma \vdash f \equiv \lambda x. f(x) : \prod_{x:A} B$}
    \end{prooftree}
#+END_definition

In the particular case in which $x$ does not appear in $B$ so that $B$ is constant
and does not depend on $A$, we obtain our usual *function type*. In ITT, we
define the function type as a particular case of the dependent function type,
$A \to B :\equiv \prod_{x:A} B$.

\\

***** Polymorphism                                               :ignore:
*Polymorphic functions* can be defined in terms of dependent function
types and universes. We can see a polymorphic term as a dependent function
taking a type as its first argument. For example, the identity
function $\mathrm{id} : \prod_{A:{\cal U}} A \to A$ can be defined as $\mathrm{id} :\equiv \lambda (A : {\cal U}). \lambda (x : A). x$.
When applied, the type should be passed as an argument, but it is
a common convention to omit arguments when they are obvious from the
context and only refer to them when typechecking.

***** Composition and implicit arguments                         :ignore:
A more complex example of polymorphic function is /function composition/,
which is also an example of higher-order function. Its type signature
takes three types as arguments and two functions between these types,
\[
\circ : \prod_{A : {\cal U}_i} \prod_{B : {\cal U}_i} \prod_{C : {\cal U}_i} (A \to B) \to (B \to C) \to A \to C
\]
and it is defined as
\[
\circ :\equiv \lambda (A : {\cal U}_i). \lambda (B : {\cal U}_i) . \lambda (C : {\cal U}_i).\ 
\lambda g. \lambda f. \lambda x.\ g(f(x)).
\]
However, we face a notational nuisance here: to explicitly write down
all the types each time we want to notate a function would be very
wordy. Instead, we will allow arguments to be determined
implicitly. Implicit arguments must be inferred by the context and
its supression is not formalized as part of our type theory. At the
same time, we will use infix notation whenever it is easier to read.

Thus, we will write $f \circ g$ instead of $\circ (A,B,C,f,g)$. 

# Sometimes, when defining a function, it will be also useful to write
# it not as a lambda expression but as a function with parentheses.

**** OLD Dependent pair types
***** Dependent pair types: introduction                         :ignore:
*Dependent pair types*, or *\Sigma-types*, can be seen as a
generalized version of the product type, but they can be also
particularized in the union type. The elements of $\sum_{x:A}B(x)$ are
pairs where the first element is of type $A$ and the second element
is of type $B(x)$, where $x$ is the first one; that is, the type of
the second component depends on the first component. This type is
often written as $\Sigma (x:A), B(x)$ and it corresponds to the
intuitionistic existential quantifier under the /propositions as types/
interpretation. That is, the proof of $\exists (x:A), B(x)$ must be seen as
a pair given by an element $x$ and a proof of $B(x)$.

***** Dependent pair types: definition                           :ignore:
#+ATTR_LATEX: :options [Dependent pair type]
#+BEGIN_definition
The following rules apply for the dependent pair type:

 * its formation rule is similar to that of the product
   \begin{prooftree}
   \RightLabel{$\Sigma$\textsc{-form}}
   \AXC{$\Gamma \vdash A \colon {\cal U}_i$}
   \AXC{$\Gamma, x:A \vdash B \colon {\cal U}_i$}
   \BIC{$\Gamma \vdash \sum_{x:A} B : {\cal U}_i$}
   \end{prooftree}

 * a pair can be constructed by its two components
   \begin{prooftree}
   \RightLabel{$\Sigma$\textsc{-intro}}
   \AXC{$\Gamma, x:A \vdash B : {\cal U}_i$}
   \AXC{$\Gamma \vdash a : A$}
   \AXC{$\Gamma \vdash b : B[a/x]$}
   \TIC{$\Gamma \vdash (a,b) : \sum_{x:A} B$}
   \end{prooftree}

 * its elimination rule tell us that we can use a pair using its two
   elements, $x,y$, to create a new one
   \begin{prooftree}
   \RightLabel{$\Sigma$\textsc{-elim}}
   \AXC{$\Gamma, z:\sum_{x:A}B \vdash C : {\cal U}_i$}
   \AXC{$\Gamma, x:A, y:B \vdash g : C[(x,y)/z]$}
   \AXC{$\Gamma \vdash p : \sum_{x:A} B$}
   \TIC{$\Gamma \vdash \mathrm{ind}_{\sum} ([z].C, [x].[y].g, p) : C[p/z]$}
   \end{prooftree}

 * and its \beta-rule substitutes the two elements of the pair onto
   an element
   \begin{prooftree}
   \AXC{$\Gamma, z:\sum_{x:A}B \vdash C : {\cal U}_i$}
   \AXC{$\Gamma, x:A,y:B \vdash g : C[(x,y)/z]$}
   \AXC{$\Gamma \vdash a:A$}
   \noLine
   \UIC{$\Gamma \vdash b : B[a/x]$}
   \RightLabel{$\Sigma$\textsc{-comp}}
   \TIC{$\Gamma \vdash \mathrm{ind}_{\sum} ([z].C, [x].[y].g, (a,b)) \equiv g[a/x][b/y] : C[(a,b)/z]$}
   \end{prooftree}
#+END_definition

Note that we do not postulate an \eta-rule for the dependent pair
type. We will show later that it follows from these rules.

\\

***** Projections                                                :ignore:
The elimination rule says that we can define a function from the
dependent pair type $\prod_{x:A} B$ to an arbitrary type $C$ by
assuming some $x:A$ and $y : B(x)$ and constructing a term of type $C$
with them.

For instance, we can declare of the first projection to be
$\proj_1 :\left(\sum_{x:A} B(x) \right) \to A$ and define it as $\proj_1((a,b)) :\equiv a$.
The second projection is slightly more complex, as it must
be a dependent function
\[
\proj_2 : \prod_{p: \sum_{x:A} B(x)} B(\proj_1(p))
\]
whose type depends on the first projection. It can be again
defined as $\proj_2((a,b)) :\equiv b$.

\\

***** Type-theoretic axiom of choice                             :ignore:
An interesting example arises when we consider a function that builds
a function from a term $R$ that can be regarded as a proof-relevant
binary relation, in that any term of type $R(x,y)$ is a witness of the
relation between some particular $x$ and $y$.
\[
\mathtt{ac} : \left( \prod_{x:A}\sum_{y:B} R(x,y) \right)
\to \left( \sum_{f:A \to B}\prod_{x:A} R(x,f(x)) \right) 
\]
Under the propositions as types interpretation, this type represents
the *axiom of choice*; that is, if for all $x \in A$ there exists a $y \in B$
such that $R(x,y)$, then there exists a function $f : A \to B$ such that
$R(x,f(x))$ for all $x \in A$.

The actual *axiom of choice* can be shown to be independent of
Zermelo-Fraenkel set theory. However, maybe surprisingly, this type
theoretic version can be directly proved from the axioms of our
system. The function $\mathtt{ac}$ can be constructed as
\[
\mathtt{ac} :\equiv \lambda g . \left( \proj_1 \circ g, \proj_2 \circ g \right),
\]
and we can check that, in fact, if $g : \prod_{x:A}\sum_{y:B} R(x,y)$, then

 * $\proj_1 \circ g$ is of type $A \to B$, and
 * $\proj_2 \circ g$ is of type $\prod_{x:A} R(x,\proj_1(g(x)))$;

effectively proving that $\mathtt{ac}(g)$ has type $\sum_{f : A \to B}\prod_{x:A}R(x,f(x))$.

Why the type-theoretic version of the axiom of choice is, instead, a
*theorem of choice*? The crucial notion here is that no choice is
actually involved. The dependent pair $\Sigma$ differs from the classical
existential quantification $\exists$ in that it is constructive, that is,
any witness of $\sum_{a:A}B$ has to actually provide an element of $A$ such
that $B(a)$; while a proof of $\exists a \in A, B$ does not need to point to any
particular element of $A$.

\\

***** Magmas                                                     :ignore:
Algebraic structures can be also described as dependent pairs. For
instance, we can define a *magma* to be a type $A$ endowed with a binary
operation $A \to A \to A$. This can be encoded in a type of magmas as
\[
\mathtt{Magma} :\equiv \sum_{A : {\cal U}} (A \to A \to A).
\]
After we introduce identity types, we will be able to add constraints
to our structures that will allow us to define more complex algebraic
structures such as groups or categories.

**** Unit, empty, coproduct and boolean types
***** Empty type                                                 :ignore:
The *empty* type, $0 \colon {\cal U}$, has no inhabitants and a function $f \colon 0 \to C$
is defined without having to give any equation.

#+ATTR_LATEX: :options [Empty type]
#+BEGIN_definition
The following rules apply for the empty type:

 * it can be formed without any assumption,
   \begin{prooftree}
   \RightLabel{$0$\textsc{-form}}
   \AXC{$$}
   \UIC{$\Gamma \vdash 0 : {\cal U}_i$}
   \end{prooftree}
   
 * and it can be used without any restriction,
   \begin{prooftree}
   \RightLabel{$0$\textsc{-elim}}
   \AXC{$\Gamma, x:0 \vdash C : {\cal U}_i$}
   \AXC{$\Gamma \vdash a : 0$}
   \BIC{$\Gamma \vdash \mathrm{ind}_0([x].C, a) : C[a/x]$}
   \end{prooftree}
#+END_definition

Note that the empty type has no introduction and \beta-rules. We
cannot compute with the empty type and it should not be possible to
create an element of that type.

\\

***** Unit type                                                  :ignore:
The *unit* type, $1 : {\cal U}$ has only one inhabitant. To define a function
$f : 1 \to C$ amounts to choose on element of type $C$.

#+ATTR_LATEX: :options [Unit type]
#+BEGIN_definition
The following rules apply for the unit type:

 * it can be formed without any assumption
   \begin{prooftree}
   \RightLabel{$1$\textsc{-form}}
   \AXC{$$}
   \UIC{$\Gamma \vdash 1 : {\cal U}_i$}
   \end{prooftree}

 * and its only instance can be also introduced without any assumption,
   \begin{prooftree}
   \RightLabel{$1$\textsc{-intro}}
   \AXC{$$}
   \UIC{$\Gamma \vdash \star : 1$}
   \end{prooftree}

 * it can be used to choose an instance of any type
   \begin{prooftree}
   \RightLabel{$1$\textsc{-elim}}
   \AXC{$\Gamma, x:1 \vdash C : {\cal U}_i$}
   \AXC{$\Gamma \vdash c : C[\star / x]$}
   \AXC{$\Gamma \vdash a : 1$}
   \TIC{$\Gamma \vdash \mathrm{ind}_1([x].C,c,a) : C[a/x]$}
   \end{prooftree}

 * and its beta rule computes the element we had chosen
\begin{prooftree}
\RightLabel{$1$\textsc{-comp}}
\AXC{$\Gamma, x:1 \vdash C : {\cal U}_{i}$}
\AXC{$\Gamma \vdash c : C[\star / x]$}
\BIC{$\Gamma \vdash \mathrm{ind}_1([x].C,c,\star) \equiv c : C[\star / x]$}
\end{prooftree}
#+END_definition

# Uniqueness
Uniqueness need not to be postulated, it can be proved using these
axioms.

***** Coproducts: definition                                     :ignore:
#+ATTR_LATEX: :options [Coproduct type]
#+BEGIN_definition
The following rules apply for coproduct types:

 * there is a coproduct type for any two types,
   \begin{prooftree}
   \RightLabel{$+$\textsc{-form}}
   \AXC{$\Gamma \vdash A : {\cal U}_i$}
   \AXC{$\Gamma \vdash B : {\cal U}_i$}
   \BIC{$\Gamma \vdash A + B : {\cal U}_i$}
   \end{prooftree}

 * a term can be introduced in two different ways
   \begin{prooftree}
   \RightLabel{$+$\textsc{-intro1}}
   \AXC{$\Gamma \vdash A : {\cal U}_i$}
   \AXC{$\Gamma \vdash B : {\cal U}_i$}
   \AXC{$\Gamma \vdash a : A$}
   \TIC{$\Gamma \vdash \mathtt{inl}(a) : A + B$}
   \end{prooftree}
   
   \begin{prooftree}
   \RightLabel{$+$\textsc{-intro2}}
   \AXC{$\Gamma \vdash A : {\cal U}_i$}
   \AXC{$\Gamma \vdash B : {\cal U}_i$}
   \AXC{$\Gamma \vdash b : B$}
   \TIC{$\Gamma \vdash \mathtt{inr}(b) : A + B$}
   \end{prooftree}

 * and its elimination rule has to consider both cases
   \begin{prooftree}
   \AXC{$\Gamma, z {:} (A+B) \vdash C : {\cal U}_i$}
   \AXC{$\Gamma, x {:} A \vdash c : C[ \mathtt{inl}(x)/z ]$}
   \noLine
   \UIC{$\Gamma, y {:} B \vdash d : C[ \mathtt{inr}(y)/z ]$}
   \AXC{$\Gamma \vdash e : A + B$}
   \RightLabel{$+$\textsc{-elim}}
   \TIC{$\Gamma \vdash \mathtt{ind}_{A+B}([z].C, [x].c, [y].d, e) : C[e/z]$}
   \end{prooftree}

 * in particular, we have two \beta-rules, each one for each different
   way in which a term can be introduced
   \begin{prooftree}
   \AXC{$\Gamma, z {:} (A+B) \vdash C : {\cal U}_i$}
   \AXC{$\Gamma, x {:} A \vdash c : C[ \mathtt{inl}(x)/z ]$}
   \noLine
   \UIC{$\Gamma, y {:} B \vdash d : C[ \mathtt{inr}(y)/z ]$}
   \AXC{$\Gamma \vdash a : A$}
   \RightLabel{$+$\textsc{-comp1}}
   \TIC{$\Gamma \vdash \mathtt{ind}_{A+B}([z].C, [x].c, [y].d, \mathtt{inl}(a)) \equiv c[a/x] : C[ \mathtt{inl}(a) /z]$}
   \end{prooftree}

   \begin{prooftree}
   \AXC{$\Gamma, z {:} (A+B) \vdash C : {\cal U}_i$}
   \AXC{$\Gamma, x {:} A \vdash c : C[ \mathtt{inl}(x)/z ]$}
   \noLine
   \UIC{$\Gamma, y {:} B \vdash d : C[ \mathtt{inr}(y)/z ]$}
   \AXC{$\Gamma \vdash b : B$}
   \RightLabel{$+$\textsc{-comp2}}
   \TIC{$\Gamma \vdash \mathtt{ind}_{A+B}([z].C, [x].c, [y].d, \mathtt{inr}(b)) \equiv d[b/x] : C[ \mathtt{inr}(b) /z]$}
   \end{prooftree}
#+END_definition

***** Booleans                                                   :ignore:
# Define booleans as 1+1

**** Natural numbers
***** Natural numbers: introduction                              :ignore:
Although we will see later that it can be seen as a particular case of
inductive datatypes, a *natural numbers* type can be directly
defined in the core of our type theory. Its introduction rules will match
Peano's axioms and its elimination and \beta-rules will provide us with
the notion of induction.

***** Natural numbers: definition                                :ignore:
#+ATTR_LATEX: :options [Natural numbers]
#+BEGIN_definition
The following rules apply for natural numbers:

 * the natural numbers type can be formed without any assumption,
   \begin{prooftree}
   \RightLabel{$\mathbb{N}$\textsc{-form}}
   \AXC{$$}
   \UIC{$\Gamma \vdash \mathbb{N} : {\cal U}_i$}
   \end{prooftree}

 * a natural number can be introduced in two ways, as zero or as the
   successor of a natural number
   \begin{prooftree}
   \RightLabel{$\mathbb{N}$\textsc{-intro1}}
   \AXC{$$}
   \UIC{$\Gamma \vdash 0 : \mathbb{N}$}
   \AXC{$\Gamma \vdash n : \mathbb{N}$}
   \RightLabel{$\mathbb{N}$\textsc{-intro2}}
   \UIC{$\Gamma \vdash  \mathtt{succ}(n) : \mathbb{N}$}
   \noLine
   \BIC{$$}
   \end{prooftree}

 * we can apply induction on natural numbers
   \begin{prooftree}
   \AXC{$\Gamma, x{:} \mathbb{N} \vdash C : {\cal U}_i$}
   \AXC{$\Gamma \vdash c_0 : C[0/x]$}
   \noLine
   \UIC{$\Gamma, x{:} \mathbb{N}, y {:} C \vdash c_s : C[ \mathtt{succ}(x)/x]$}
   \AXC{$\Gamma \vdash n : \mathbb{N}$}
   \RightLabel{$\mathbb{N}$\textsc{-elim}}
   \TIC{$\Gamma \vdash \mathtt{ind}_{\mathbb{N}}([x].C, c_0, [x].[y].c_s, n) : C[n/x]$}
   \end{prooftree}

 * and it must be interpreted recursively for zero or a successor with the
   following two \beta-rules
   \begin{prooftree}
   \AXC{$\Gamma, x{:} \mathbb{N} \vdash C : {\cal U}_i$}
   \AXC{$\Gamma \vdash c_0 : C[0/x]$}
   \noLine
   \UIC{$\Gamma, x{:} \mathbb{N}, y {:} C \vdash c_s : C[ \mathtt{succ}(x)/x]$}
   \RightLabel{$\mathbb{N}$\textsc{-comp1}}
   \BIC{$\Gamma \vdash \mathtt{ind}_{\mathbb{N}}([x].C, c_0, [x].[y].c_s, 0) \equiv c_0 : C[0/x]$}
   \end{prooftree}

   \begin{prooftree}
   \AXC{$\Gamma, x{:} \mathbb{N} \vdash C : {\cal U}_i$}
   \AXC{$\Gamma \vdash c_0 : C[0/x]$}
   \noLine
   \UIC{$\Gamma, x{:} \mathbb{N}, y {:} C \vdash c_s : C[ \mathtt{succ}(x)/x]$}
   \RightLabel{$\mathbb{N}$\textsc{-comp2}}
   \BIC{$\Gamma \vdash \mathtt{ind}_{\mathbb{N}}([x].C, c_0, [x].[y].c_s, \mathtt{succ}\ n) \equiv$}
   \noLine
   \UIC{$c_s[n/x][\mathrm{ind}_{\mathbb{N}}([x].C, c_0, [x].[y].c_s, n)/y] : C[\mathtt{succ}(n)/x]$}
   \end{prooftree}
#+END_definition

***** Pattern matching                                           :ignore:
Any function on natural numbers can be defined in two
equivalent ways, either using the induction principle or its defining
equations.

 * If we use the induction principle, a function from the naturals
   to the type $C$ must be defined as
   \[
   f :\equiv \mathtt{ind}_{\mathbb{N}}(C, c_0, c_s)
   \]
   where $c_s$ can depend on an element of type $C$. Two defining equations
   capturing the definition could be written in this case as
   \[\begin{aligned}
   f(0) :\equiv c_0, \\
   f( \mathtt{succ}(n)) :\equiv c_s,
   \end{aligned}\]
   where $c_s$ would depend on an element of type $C$ that can be interpreted
   as being $f(n)$, that is, a recursive call to the function.

 * Conversely, we could define a function by its two defining
   equations. If we had
   \[\begin{aligned}
   f(0) :\equiv \Phi_0, \\
   f( \mathtt{succ}(n)) :\equiv \Phi_s,
   \end{aligned}\]   
   where $\Phi_s : C$ depends on $f(n)$, we could substitute $f(n)$ by a variable
   $r$ and equivalently write the definition as
   \[
   f :\equiv \mathtt{ind}_{\mathbb{N}}(C,\Phi_0, \lambda n.\lambda r. \Phi_{s}).
   \]

This can be done in general with types whose induction principle can be
split in multiple cases. We will call *pattern matching* to this style
of defining functions and it will be used from now on because of its
simplicity. However, we must be careful when doing this, as it could
create the false impression that arbitrary recursion is allowed in our
definitions. An equation such as $f(\mathtt{succ}(n)) :\equiv f(\mathtt{succ}(\mathtt{succ}(n)))$,
for example, is not valid.

\\

***** Addition                                                   :ignore:
Our first example will be the definition of addition on natural
numbers. It will be an infix function $+ : \mathbb{N} \to \mathbb{N} \to \mathbb{N}$ given by
\[\begin{aligned}
0 + m &:\equiv m, \\
(\mathtt{succ}\ n) + m &:\equiv \mathtt{succ}(n + m),
\end{aligned}\]
where we are applying the induction principle to the first argument.
In other words,
\[
{+} :\equiv \lambda (n{:}\mathbb{N}). \lambda (m{:}\mathbb{N}). \mathtt{ind}_{\mathbb{N}}(\mathbb{N}, m, [s].[r]. \mathtt{succ}\ r, n).
\]

\\

***** Extensional equality of 2+2=4                              :ignore:
Under this definition it can be shown that, for example, $2 + 2 :\equiv 4$.
However, if we wanted to prove the fact that addition is
commutative, we would have no way of expressing this in terms of an
extensional equality. We would need a notion of propositional
equality, that is, an equality $=$ that could be used as a type in an
expression, in order to write something like

\[
\mathtt{comm_{+}} : \prod_{n : \mathbb{N}} \prod_{m : \mathbb{N}} (n + m = m + n).
\]

**** Identity types
***** Identity types: introduction                               :ignore:
Under a /propositions as types/ interpretation, the proposition that
two elements of a type are equal, should correspond to a type; and
therefore, equality should correspond to a family of types,
\[
{=} : \prod_{A : \cal U} A \to A \to {\cal U}.
\]
We will write the equality type between $a,b : A$ interchangeably as
$a =_A b$ or $\mathrm{Id}_A(a,b)$.

***** Identity types: definition                                 :ignore:
#+ATTR_LATEX: :options [Identity types]
#+BEGIN_definition
The following rules apply for identity types:

 * an identity type is defined between any two elements of
   the same type
   \begin{prooftree}
   \RightLabel{$=$\textsc{-form}}
   \AXC{$\Gamma \vdash A : {\cal U}_i$}
   \AXC{$\Gamma \vdash a : A$}
   \AXC{$\Gamma \vdash b : A$}
   \TIC{$\Gamma \vdash a =_A b : {\cal U}_i$}
   \end{prooftree}

 * the only way to introduce an identity is using the principle
   of *reflexivity*, that is, there exists an element $\mathtt{refl}$ of
   type $a =_A a$ for each $a : A$,
   \begin{prooftree}
   \RightLabel{$=$\textsc{-intro}}
   \AXC{$\Gamma \vdash A : {\cal U}_i$}
   \AXC{$\Gamma \vdash a : A$}
   \BIC{$\Gamma \vdash \mathrm{refl} : a =_A a$}
   \end{prooftree}

 * its elimination rule of $p : x =_A y$ allows us to create an instance of a
   particular type, or prove a proposition, simply assuming that $x$ and $y$
   are in fact the same element and $p = \mathrm{refl}_{z}$,
   \begin{prooftree}
   \AXC{$\Gamma, x{:}A, y{:}A, p{:} (x=_A y) \vdash C : {\cal U}_i$}
   \noLine
   \UIC{$\Gamma, z{:}A \vdash c : C[z/x][z/y][ \mathrm{refl} / p ]$}
   \AXC{$\Gamma \vdash a : A$}
   \noLine
   \UIC{$\Gamma \vdash b : A$}
   \AXC{$\Gamma \vdash q : a =_A b$}
   \RightLabel{$=$\textsc{-elim}}
   \TIC{$\Gamma \vdash \mathtt{ind}_{=_A}([x].[y].[p].C, [z].c, a,b,q) : C[a,b,q / x,y,p]$}
   \end{prooftree}

 * and its \beta-rule simply substitutes two equal instances by the same
   one
   \begin{prooftree}
   \AXC{$\Gamma, x {:} A, y {:} A, p {:} x=_A y \vdash C : {\cal U}_i$}
   \noLine
   \UIC{$\Gamma, z {:} A \vdash c : C[z,z, \mathtt{refl}_z / x,y,p]$}
   \AXC{$\Gamma \vdash a : A$}
   \RightLabel{$=$\textsc{-comp}}
   \BIC{$\Gamma \vdash \mathtt{ind}_{=_A}([x].[y].[p].C, [z].c, a, a, \mathtt{refl}_a) \equiv c[a/z] : C[a/x][a/y][\mathtt{refl}_a/p]$}
   \end{prooftree}
#+END_definition

***** Reflexivity                                                :ignore:
Note that the introduction rule on types is a dependent function
called *reflexivity* that provides us with a basic way of constructing
an element of type $(a =_A b) : {\cal U}$,
\[
\mathtt{refl} :
\prod_{a : A} (a =_A a).
\]
In particular, any two definitionally equal terms, such as $2 + 2 :\equiv 4$,
are also propositionally equal. In fact, $\mathtt{refl}_4 : 2 + 2 = 4$ is a well-typed
statement, precisely because of the fact that $2 + 2$ and $4$ are definitionally
equal.

\\

***** Path induction                                             :ignore:
The elimination principle and the \beta-rule for identity types are
usually called the *path induction* principle. It states that, given a
family of types parametrized over the identity type,
\[
C : \prod_{x,y:A} (x =_A y) \to {\cal U},
\]
every function defined over the $\mathtt{refl}$ element, $c : \prod_{z:A} C(z,z, \mathtt{refl}_z)$,
can be extended to any equality term as
\[
f : \prod_{x:A}\prod_{y:A}\prod_{p : x=y} C(x,y,p),
\]
and it follows from the \beta-rule that $f(x,x, \mathtt{refl}_x) :\equiv c(x)$, that is,
that it is in fact an extension.

This *path induction* principle could be wrapped into a function
\[
\mathtt{ind}_{=} :
\prod_{\left(C : \prod_{x:A}\prod_{y:A} (x = y) \to {\cal U}\right)}
\left( \prod_{x:A} C(x,x, \mathtt{refl_x}) \to \prod_{x:A}\prod_{y:A}\prod_{p : x=y} C(x,y,p) \right)
\]
and the \beta-rule could be replaced by $\mathtt{ind}_{=}(C,c,x,x, \mathtt{refl}_x) :\equiv c(x)$.

***** Indiscernability of identicals follows from path induction :ignore:
We will use path induction to prove a the principle of
*indiscernability of identicals*, that is, the fact that,
for every family of types $C : A \to {\cal U}$, there is a function
between the type associated to propositionally equal elements,
that is,
\[
f : \prod_{x:A} \prod_{y:A} \prod_{p : x=y} C(x) \to C(y),
\]
such that, when applied to reflexivity, it outputs the identity
function, $f(x,x, \mathtt{refl}_x) :\equiv \mathtt{id}_{C(x)}$.

We can prove this principle for any $C : A \to {\cal U}$ by defining
\[
f :\equiv
\mathtt{ind}_{=}
\left(\lambda x. \lambda y. \lambda p. C(x) \to C(y), \mathtt{id}_{C(x)}\right),
\]
and the fact that $f(x,x, \mathtt{refl}_x) :\equiv \mathtt{id}_{C(x)}$ follows from the \beta-rule.

# We will later prove that this function is an equivalence

***** TODO Axiom K and Axiom J                                   :ignore:
***** TODO Axiom J from Yoneda Lemma                             :ignore:
**** Inductive types
Inductive types provide the intuitive notion of a free type generated
by a finite set of constructors. That is, the only elements of an
inductive type should be those that can be obtained by applying a
fixed finite set of constructors. Thus, we can define functions over
inductive types using certain induction principles that define a
specific action for each one of the possible constructors.

# Example: naturals

***** W-types                                                    :ignore:
# https://mazzo.li/epilogue/index.html%3Fp=324.html

# Following notes by Muller and Cavallo
# http://www.cs.cmu.edu/~rwh/courses/hott/notes/notes_week10.pdf

The *W-type* (or /Brower ordinal/) $\wtype_{a:A} B(a)$, also written as $\wt (a:A),B(a)$,
can be thought as an inductive type whose set of constructors is
indexed by the type $A$, such that the constructor indexed by the
particular element $a$ has arguments indexed by $B(a)$. In other
words, it is a well-founded tree where every node is labeled by
an element of $a$ and has a set of child nodes indexed by the type
$B(a)$.

***** Rules for W-types                                          :ignore:
\begin{prooftree}
\RightLabel{$\wt$\textsc{-form}}
\AXC{$\Gamma \vdash A : {\cal U}$}
\AXC{$\Gamma, x:A \vdash B : {\cal U}$}
\BIC{$\Gamma \vdash \wtype_{x:A} B : {\cal U}$}
\end{prooftree}

\begin{prooftree}
\RightLabel{$\wt$\textsc{-intro}}
\AXC{$\Gamma \vdash a : A$}
\AXC{$\Gamma, x{:} B(a) \vdash \wtype_{x:A} B$}
\BIC{$\Gamma \vdash \mathtt{sup}[a]([x].w) : \wtype_{x:A} B$}
\end{prooftree}

\begin{prooftree}
\AXC{$\Gamma, z : \wtype_{x:A} B \vdash P : {\cal U} $}
\noLine
\UIC{$\Gamma, a{:}A, p: B(a) \to \wtype_{x:A} B, h : \prod_{b : B(a)} P(p(b)) \vdash M : P( \mathtt{sup}(p) )$}
\RightLabel{$\wt$\textsc{-elim}}
\UIC{$\Gamma, z{:} \wtype_{x:A} B \vdash \mathtt{ind}_{\wt}(a,p,[h].M) : P(z)$}
\end{prooftree}

# Computation rule only holds propositionally.

***** W-types as initial algebras                                :ignore:
The relevant endofunctor must be polynomial.

Not all endofunctors have initial algebras, but all polynomial functors do have
initial algebras.


Each $\wt\mhyphen\mathrm{type}$ determines a functor on types given by
\[
F(X) = \sum_{a:A} B(a) \to X.
\]
Functors of this form are called *polynomial functors*, as they can be
written as $\sum_{a:A} X^{B(a)}$ and thought as a generalized polynomial function.

In fact, this functor is an F-algebra with the function
\[
\lambda (a,w). \mathrm{sup}[a](w) : F(X) \to X.
\]
# It is an equivalence and this is an homotopy-initial algebra.

***** Wellfounded trees in categories
http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.44.6700
***** TODO Two equivalently defined inductive functions are in fact equal
*** TODO Constructive mathematics
**** TODO Axiom of choice implies excluded middle
# In Agda or Coq!?
# Diaconescu's theorem
# https://en.wikipedia.org/wiki/Diaconescu%27s_theorem

**** TODO Type theory as a foundation of mathematics

*** TODO Univalent foundations
*** Homotopy Type Theory I: Univalence
# HoTT is the internal language of (infty,1)-toposes

# TODO: Check the unicode error output!

The basic idea of *Homotopy Type Theory* is to think of types as
\infty-groupoids. Between two elements of a type $a,b:A$ we can define their
identity type $a =_A b$; between two proofs of equality $p,q : a =_A b$ we
can define again a new identity type $p =_{a=b} q$; between any two proofs
of equality between equalities, we could define again a new identity type,
and so on. All of this \infty-groupoid structure arises from the path
induction principle.

Homotopy Type Theory (HoTT) adds the univalence axiom and higher
inductive types to intensional type theory (ITT).

This presentation of Homotopy Type Theory will follow cite:hottbook.

**** Types as groupoids
***** Types as groupoids                                         :ignore:
Types and identity types between their elements are groupoids.
# Higher Identity types give them a structure of higher groupoids.



***** Functions as functors                                      :ignore:
Functions can be seen as functors between groupoids.

#+latex: \ExecuteMetaData[latex/Ctlc.tex]{groupoid-functors}

***** TODO Eckmann-Hilton                                        :ignore:
Given any point $a : A$, we can define its *loop space* $\Omega(A,a)$
as the type of the paths from the point to itself, that is,
\[
\Omega(A,a) :\equiv (a =_A a).
\]
Concatenation of paths provides this type with a structure of
group $\Omega(A,a) \times \Omega(A,a) \to \Omega(A,a)$.

This construction can be generalized to higher dimensions. The
loop space of the loop space is the type of 2-dimensional paths
from the identity path to itself, that is,
\[
\Omega^2(A,a) :\equiv (\refl_a = \refl_a).
\]

#+ATTR_LATEX: :options [Eckmann-Hilton]
#+BEGIN_theorem
Composition in $\Omega^2(A,a) \times \Omega^2(A,a) \to \Omega^2(A,a)$ is commutative.
#+END_theorem
#+BEGIN_proof

#+END_proof


***** Transport                                                  :ignore:
#+begin_quote
Finding a type-theoretic description of
this behavior (that is, introduction, elimination and computation rules which comport
with Gentzen’s Inversion Principle) is an open problem.
#+end_quote

****** Lemma: transport                                         :ignore:
# Indiscernability of identicals
#+ATTR_LATEX: :options [Transport]
#+BEGIN_lemma
Given a parametrized type family $P : A \to {\cal U}$, for every $p : x =_A y$,
there exists a function $p_{\ast} : P(x) \to P(y)$.
#+END_lemma

***** Dependent paths                                            :ignore:

**** Homotopies and quasi-inverses
***** Homotopies                                                 :ignore:
#+ATTR_LATEX: :options [Homotopy]
#+BEGIN_definition
A *homotopy* between two sections of a fibration $f,g \colon \prod_{x:A}P(x)$
is defined as
\[
(f \sim g) :\equiv \prod_{x:A} (f(x) = g(x)).
\]
#+END_definition

***** Quasi-inverses                                             :ignore:
#+ATTR_LATEX: :options [Quasi-inverse]
#+BEGIN_definition
A *quasi-inverse* of a function $f : A \to B$ is a function $g : B \to A$
and two homotopies $\alpha : f \circ g \sim \id$ and $\beta : g \circ f \sim \id$. More formally,
the type of quasi-inverses of $f$ can be described as
\[
\sum_{g : B \to A} (f \circ g \sim \id) \times (g \circ f \sim \id)
\]
#+END_definition

***** Equivalences
****** Type of equivalences
****** Equivalence of types
The type of /equivalences between two types/ is defined as
\[
(A \simeq B) :\equiv \sum_{f : A \to B} \mathrm{isequiv}(f)
\]
****** Equivalence is an equivalence relation

**** Higher-groupoid structure of types
# how type constructors deal with the groupoid structure
# Characterizations in this section are theorems
# except for function extensionality and univalence axiom

The higher-groupoid structure of types manifests itself also in type
constructors and how them relate to equality types. In general, we will
be able to prove that equalities between type constructors can be
characterized by equalities between the arguments of their constructors;
but there are two exceptions

 * the axiom of *function extensionality* will be needed to prove the
   desired theorem for $\Pi\mhyphen\mbox{Types}$, and
 * the *univalence* axiom will be needed to prove the desired theorem
   for ${\cal U}\mhyphen\mbox{Types}$.



***** Function extensionality
#+ATTR_LATEX: :options [Function extensionality]
#+BEGIN_definition
*Function extensionality* states that the function
\[
(f = g) \to \prod_{x:A}\left(f(x) =_{B(x)} g(x)\right)
\]
is an equivalence. In particular, the following function is its
quasi-inverse
\[
\mathrm{funext} : \left( \prod_{x:A} f(x) = g(x) \right) \to (f = g).
\]
#+END_definition

**** Univalence axiom

***** Univalent universes
***** TODO [#C] Naturals and Naturals'
**** n-types
A /type-theoretical set/ will be a type with no associated higher
groupoid structure. That is, it is a discrete groupoid, and any
two parallel paths are equal.

#+ATTR_LATEX: :options [Sets]
#+BEGIN_definition
A type $A$ is a *set* (or *0-type*) when the following type is
inhabited
\[
\mathtt{isSet}(A) :\equiv \prod_{x,y : A} \prod_{p,q : x=y} (p=q).
\]
#+END_definition

We can generalize this definition to higher dimensions
 
 * a *0-type* is a type with no non-trivial paths

 * a *1-type* is a type with no non-trivial paths between paths,
   every two paths $r,s : p = q$ between types $p,q : x = y$ must
   be equal, $r = s$;

 * a *2-type* is a type with no non-trivial paths between paths
   between paths;
 
 * ... and so on.

In particular, it can be proved that every *n-type* is an
*(n+1)-type*.

***** Mere propositions                                          :ignore:
***** Contractible types                                         :ignore:
***** Propositional truncation                                   :ignore:
**** Higher inductive types
# as free \infty-groupoids

*** Homotopy Type Theory II: Mathematics
\begin{tikzcd}[column sep=large]
  \tikz\draw[{[-]},yshift=0.5ex] (0,0)node[below]{$0$} -- (2,0)node[below]{$1$};
  \arrow[r, "\textrm{gluing}"]
& \tikz\draw (0,0) circle (1cm)  (0.8,0) -- (1.2,0) node[right]{$\mathbb Z$};
\end{tikzcd}



**** TODO Categories

*** TODO Cubical type theory
# A hands-on introduction to cubical type theory
*** Programming in Martin-Löf Type theory
# Cite Connor's course in Agda
# Cite Altenkirch's notes on HoTT


**** Martin-Löf type theory in Agda
In this chapter, we will describe how to program in MLTT using Agda as
proof assistant. An Agda file consists of type declarations and
definitions stated with ~=~, as in the following example.

#+latex: \ExecuteMetaData[latex/Ctlc.tex]{example}

This code exemplifies multiple idiosyncratic features of Agda when compared
to our previous presentation of MLTT.

 * The type of types, ${\cal U}$, is written as =Set=; however, it has nothing
   to do with our usual /set-theoretical sets/. The hierarchy of universes
   in Agda is written as
   \[
   \mathtt{Set} :
   \mathtt{Set}_1 :
   \mathtt{Set}_{2} :
   \dots
   \]
   We will see later that it is possible to use compiler flags to
   postulate the collapse of this hierarchy into a single
   $\mathtt{Set} : \mathtt{Set}$ and derive a contradiction from this
   assumption.

   If we want a definition to work at all levels of the universe
   hierarchy, we need to explicitly write =∀{l}...Set l= instead
   of simply write =Set=.

 * Dependent functions are implicitly built into the language.  In
   general, the dependent function type $\prod_{a:A} B$ is written as
   ~(a : A) → B~. In particular, we write the type
   $\mathtt{id} : \prod_{A : {\cal U}} A \to A$ as =(A : Set) → A → A=.

 * Agda allows a shorthand for nested dependent function types of
   the form $\prod_{a:A} \prod_{a':A} B$. We can write them as =(a a' : A) → B=,
   instead of having to write =(a : A) → (a' : A) → B=.

 * Implicit arguments are declared between curly braces, ={ ... }=.
   Whenever we call a function with implicit arguments, the type
   checker will infer them from the context if we decide not to
   overwrite them explicitely.

 * Infix operators can be defined using underscores ~_~.

***** Data and records                                           :ignore:
We have seen that Agda directly provides function types, but
it also provides two mechanisms to define new types:
/*data declarations*/ and /*record types*/.

 * *Data declarations* can be thought as inductive types. They build the
   free type (the initial algebra) over a set of constructors; and
   they are better suited for defining positive types such as the void
   type, coproducts or natural numbers.

 * *Record types* can be thought as generalized dependent n-tuples in
   which every element of the tuple is labeled and depends on the
   previous ones. They are better suited for defining negative
   types such as the unit type or product types. A constructor can
   be provided for them.

The complete type constructors of MLTT and the majority of types that
we will use in this text can be defined in terms of these.

***** Code: types and proofs                                     :ignore:
#+latex: \ExecuteMetaData[latex/Ctlc.tex]{mltt}

Once we have defined these types, we can start profiting from the
propositions as types interpretation to write and check mathematical
proofs in Agda.

Functions can be defined by a (possibly empty) list of declarations
that exhaustively pattern match on all the possible constructors of
the type.

#+latex: \ExecuteMetaData[latex/Ctlc.tex]{mlttproof}

In particular, we can check our previous proof of the Theorem of
Choice defining the two projections from a dependent pair type.

#+latex: \ExecuteMetaData[latex/Ctlc.tex]{theoremchoice}

The path induction principle follows from the definition of equality
as an inductive type and can be used to prove indiscernability of
identicals.

#+latex: \ExecuteMetaData[latex/Ctlc.tex]{indiscernability}

**** Type in type
# Russell's paradox code
# Girard paradox in agda: https://github.com/nzl-nott/PhD-of-nzl/blob/master/Exercise/Ex4/girard.agda
# Hurkens' paradox: https://github.com/agda/agda/blob/master/test/Succeed/Hurkens.agda
# Hurkens: https://www.cs.cmu.edu/~kw/scans/hurkens95tlca.pdf
# Burali-Forti paradox

#+latex: \ExecuteMetaData[latex/Russell.tex]{russell}

**** TODO Programming in extensional Martin-Löf type theory
# Following Conor's course
** TODO T-algebras
# TODO: Algebras para cualquier endofuntor
For a monad $T$, a $T\textbf{-algebra}$ is an object $x$ with an arrow $h \colon Tx \to x$ called 
/structure map/ making this diagram commute.
\[\begin{tikzcd}
T^{2}x \rar{Th}\dar[swap]{\mu} & Tx \dar{h} \\
Tx\rar{h} & x
\end{tikzcd}\]
A *morphism of* $T\textbf{-algebras}$ is an arrow $f\colon x \to x'$ making the following diagram
commute.
\[\begin{tikzcd}
Tx \dar[swap]{Tf}\rar{h} & Tx \dar{f} \\
Tx' \rar[swap]{h'} & Tx'
\end{tikzcd}\]

#+attr_latex: :options [Category of T-algebras]
#+begin_proposition
The set of all $T\text{-algebras}$ and their morphisms form a category $X^{T}$.
#+end_proposition
#+begin_proof
Given $f\colon x \to x'$ and $g\colon x'\to x''$, $T\text{-algebra}$ morphisms, their composition
is also a $T\text{-algebra}$ morphism, due to the fact that this diagram
\[\begin{tikzcd}
Tx \rar{h}\dar[swap]{Tf} & 
x \dar{f}\\
Tx' \dar[swap]{Tg} \rar{h'} &
x' \dar{g}\\
Tx'' \rar{h''}&
x''
\end{tikzcd}\]
commutes.
#+end_proof

# TODO: Initial algebras: Wellfounded trees in categories
** TODO Adjoints and limits
*** Freyd adjoint functor theorem                                  :ignore:
#+ATTR_LATEX: :options [Freyd adjoint functor theorem]
#+BEGIN_theorem
A functor $G \colon {\cal C} \to {\cal D}$ from a small and locally small complete category ${\cal C}$
has a left adjoint if and only if it preserves small limits and satisfies
the solution set condition.
#+END_theorem
** OLD Kleisli categories
#+ATTR_LATEX: :options [Kleisli category]
#+BEGIN_definition
The *Kleisli category* of a monad $T \colon {\cal X} \to {\cal X}$ is written as ${\cal X}_T$ 
and is given by

 * an object $x_T$ for every $x \in {\cal X}$; and

 * an arrow $f^{\flat} \colon x_T \to y_T$ for every $f \colon x \to T y$.

And the composite of two morphisms is defined as
\[
g^{\flat} \circ f^{\flat} = (\mu \circ Tg \circ f)^{\flat}.
\]
#+END_definition

#+ATTR_LATEX: :options [Adjunction on a Kleisli category]
#+BEGIN_theorem
The functors $F_T \colon {\cal X} \to {\cal X}_T$ and $G \colon {\cal X}_T \to {\cal X}$ from and
to the Kleisli category which are defined on objects as $F_T(x) = x_T$ and
$G_T(x_T) = Tx$, and defined on morphisms as

\[\begin{aligned}
F_T \colon& (k \colon x \to y)             &\mapsto&\ (\eta_y \circ k)^{\flat} \colon x_T \to y_T \\
G_T \colon& (f^{\flat} \colon x_T \to y_T) &\mapsto&\ (\eta_y \circ Tf) \colon Tx \to Ty \\
\end{aligned}\]

form an adjunction $\flat \colon \hom(x,Ty) \to \hom(x_T,y_T)$ whose monad
is precisely $T$.
#+END_theorem
#+BEGIN_proof
# TODO
# Theorem 1 pag 147 MacLane
#+END_proof
** TODO Free algebras for a monad
** TODO Beck's theorem
#+ATTR_LATEX: :options [Beck's theorem]
#+BEGIN_theorem

#+END_theorem
** TODO Spans
# This implies that the category of spans of finite sets is equivalent
# to the Lawvere theory of commutative monoids, that is, to the category
# of finitely generated free commutative monoids.
** TODO Continuity
** Type theory (abstract)                                                                  :ignore:
#+LATEX: \ctparttext{\color{black}\begin{center}
Topos theory arises independently with Grothendieck and sheaf theory,
Lawvere and the axiomatization of set theory. It has allowed to
construct new models of ZFC and many different models of constructive
mathematics. Martin-Löf type theory provides a language to study and
to program inside categories with enough structure.
#+LATEX: \end{center}}

# WONTFIX?: Cite Paul Cohen and the forcing technique.
